{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: M3VNBY\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name BinaryAccuracy/ (raw) is illegal; using BinaryAccuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 4\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.082s\n",
      "| SGD | epoch: 001 | loss: 0.00000 - binary_acc: 0.0000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m0.62383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 002 | loss: 0.62383 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m0.68054\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 003 | loss: 0.68054 - binary_acc: 0.2864 -- iter: 4/4\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m0.69000\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 004 | loss: 0.69000 - binary_acc: 0.2591 -- iter: 4/4\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m0.69218\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 005 | loss: 0.69218 - binary_acc: 0.2528 -- iter: 4/4\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m0.69280\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 006 | loss: 0.69280 - binary_acc: 0.2510 -- iter: 4/4\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m0.69301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 007 | loss: 0.69301 - binary_acc: 0.2504 -- iter: 4/4\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m0.69309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 008 | loss: 0.69309 - binary_acc: 0.2502 -- iter: 4/4\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m0.69312\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 009 | loss: 0.69312 - binary_acc: 0.2501 -- iter: 4/4\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 010 | loss: 0.69313 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 011 | loss: 0.69314 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 012 | loss: 0.69314 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 013 | loss: 0.69314 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 014 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 015 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 016 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 017 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 018 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 019 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 020 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 021 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 022 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 023 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 024 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 025 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 026 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 027 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 028 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 029 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 030 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 031 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 032 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 033 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 034 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 035 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 036 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 037 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 038 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 039 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 040 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 041 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 042 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 043 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 044 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 045 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 046 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 047 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 048 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 049 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 050 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 051 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 052 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 053 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 054 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 055 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 056 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 057 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 058 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 059 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 060 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 061 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 062 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 063 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 064 | loss: 0.69315 - binary_acc: 0.2500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 065 | loss: 0.69315 - binary_acc: 0.2808 -- iter: 4/4\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 066 | loss: 0.69315 - binary_acc: 0.3075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 067 | loss: 0.69315 - binary_acc: 0.3306 -- iter: 4/4\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 068 | loss: 0.69315 - binary_acc: 0.3506 -- iter: 4/4\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 069 | loss: 0.69315 - binary_acc: 0.3681 -- iter: 4/4\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 070 | loss: 0.69315 - binary_acc: 0.3833 -- iter: 4/4\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 071 | loss: 0.69315 - binary_acc: 0.3966 -- iter: 4/4\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 072 | loss: 0.69315 - binary_acc: 0.4082 -- iter: 4/4\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 073 | loss: 0.69315 - binary_acc: 0.4184 -- iter: 4/4\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 074 | loss: 0.69315 - binary_acc: 0.4274 -- iter: 4/4\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 075 | loss: 0.69315 - binary_acc: 0.4353 -- iter: 4/4\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 076 | loss: 0.69315 - binary_acc: 0.4422 -- iter: 4/4\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 077 | loss: 0.69315 - binary_acc: 0.4483 -- iter: 4/4\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 078 | loss: 0.69315 - binary_acc: 0.4537 -- iter: 4/4\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 079 | loss: 0.69315 - binary_acc: 0.4585 -- iter: 4/4\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 080 | loss: 0.69315 - binary_acc: 0.4628 -- iter: 4/4\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 081 | loss: 0.69315 - binary_acc: 0.4665 -- iter: 4/4\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 082 | loss: 0.69315 - binary_acc: 0.4699 -- iter: 4/4\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 083 | loss: 0.69315 - binary_acc: 0.4729 -- iter: 4/4\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 084 | loss: 0.69315 - binary_acc: 0.4756 -- iter: 4/4\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 085 | loss: 0.69315 - binary_acc: 0.4780 -- iter: 4/4\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 086 | loss: 0.69315 - binary_acc: 0.4802 -- iter: 4/4\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 087 | loss: 0.69315 - binary_acc: 0.4822 -- iter: 4/4\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 088 | loss: 0.69315 - binary_acc: 0.4840 -- iter: 4/4\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 089 | loss: 0.69315 - binary_acc: 0.4856 -- iter: 4/4\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 090 | loss: 0.69315 - binary_acc: 0.4870 -- iter: 4/4\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 091 | loss: 0.69315 - binary_acc: 0.4883 -- iter: 4/4\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 092 | loss: 0.69315 - binary_acc: 0.4895 -- iter: 4/4\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 093 | loss: 0.69315 - binary_acc: 0.4905 -- iter: 4/4\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 094 | loss: 0.69315 - binary_acc: 0.4915 -- iter: 4/4\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 095 | loss: 0.69315 - binary_acc: 0.4923 -- iter: 4/4\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 096 | loss: 0.69315 - binary_acc: 0.4931 -- iter: 4/4\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 097 | loss: 0.69315 - binary_acc: 0.4938 -- iter: 4/4\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 098 | loss: 0.69315 - binary_acc: 0.4944 -- iter: 4/4\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 099 | loss: 0.69315 - binary_acc: 0.4950 -- iter: 4/4\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 100 | loss: 0.69315 - binary_acc: 0.4955 -- iter: 4/4\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 101 | loss: 0.69315 - binary_acc: 0.4959 -- iter: 4/4\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 102 | loss: 0.69315 - binary_acc: 0.4963 -- iter: 4/4\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 103 | loss: 0.69315 - binary_acc: 0.4967 -- iter: 4/4\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 104 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 105 | loss: 0.69315 - binary_acc: 0.4973 -- iter: 4/4\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 106 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 107 | loss: 0.69315 - binary_acc: 0.4978 -- iter: 4/4\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 108 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 109 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 110 | loss: 0.69315 - binary_acc: 0.4984 -- iter: 4/4\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 111 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 112 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 113 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 114 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 115 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 116 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 117 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 118 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 119 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 120 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 121 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 122 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 123 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 124 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 125 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 126 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 127 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 128 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 129 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 130 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 131 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 132 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 133 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 134 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 135 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 136 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 137 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 138 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 139 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 140 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 141 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 142 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 143 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 144 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 145 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 146 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 147 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 148 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 149 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 150 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 151 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 152 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 153 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 154 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 155 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 156 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 157 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 158 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 159 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 160 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 161 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 162 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 163 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 164 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 165 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 166 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 167 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 168 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 169 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 170 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 171 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 172 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 173 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 174 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 175 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 176 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 177 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 178 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 179 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 180 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 181 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 182 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 183 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 184 | loss: 0.69315 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 185 | loss: 0.69315 - binary_acc: 0.4550 -- iter: 4/4\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 186 | loss: 0.69315 - binary_acc: 0.4595 -- iter: 4/4\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 187 | loss: 0.69315 - binary_acc: 0.4635 -- iter: 4/4\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 188 | loss: 0.69315 - binary_acc: 0.4672 -- iter: 4/4\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 189 | loss: 0.69315 - binary_acc: 0.4705 -- iter: 4/4\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 190 | loss: 0.69315 - binary_acc: 0.4734 -- iter: 4/4\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 191 | loss: 0.69315 - binary_acc: 0.4761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 192 | loss: 0.69315 - binary_acc: 0.4785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 193 | loss: 0.69315 - binary_acc: 0.4806 -- iter: 4/4\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 194 | loss: 0.69315 - binary_acc: 0.4826 -- iter: 4/4\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 195 | loss: 0.69315 - binary_acc: 0.4843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 196 | loss: 0.69315 - binary_acc: 0.4859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 197 | loss: 0.69315 - binary_acc: 0.4873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 198 | loss: 0.69315 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 199 | loss: 0.69315 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 200 | loss: 0.69315 - binary_acc: 0.4907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 201 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 202 | loss: 0.69315 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 203 | loss: 0.69315 - binary_acc: 0.4932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 204 | loss: 0.69315 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 205 | loss: 0.69315 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 206 | loss: 0.69314 - binary_acc: 0.5451 -- iter: 4/4\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 207 | loss: 0.69314 - binary_acc: 0.5406 -- iter: 4/4\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 208 | loss: 0.69314 - binary_acc: 0.5365 -- iter: 4/4\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 209 | loss: 0.69314 - binary_acc: 0.5329 -- iter: 4/4\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 210 | loss: 0.69314 - binary_acc: 0.5296 -- iter: 4/4\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 211 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 212 | loss: 0.69314 - binary_acc: 0.5240 -- iter: 4/4\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 213 | loss: 0.69314 - binary_acc: 0.5216 -- iter: 4/4\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 214 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 215 | loss: 0.69314 - binary_acc: 0.5175 -- iter: 4/4\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 216 | loss: 0.69315 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 217 | loss: 0.69315 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 218 | loss: 0.69315 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 219 | loss: 0.69315 - binary_acc: 0.5115 -- iter: 4/4\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 220 | loss: 0.69314 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 221 | loss: 0.69314 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 222 | loss: 0.69314 - binary_acc: 0.5084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 223 | loss: 0.69314 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 224 | loss: 0.69314 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 225 | loss: 0.69314 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 226 | loss: 0.69314 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 227 | loss: 0.69314 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 228 | loss: 0.69314 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 229 | loss: 0.69314 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 230 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 231 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 232 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 233 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 234 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 235 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 236 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 237 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 238 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 239 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 240 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 241 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 242 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 243 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 244 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 245 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 246 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 247 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 248 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 249 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 250 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 251 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 252 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 253 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 254 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 255 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 256 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 257 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 258 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 259 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 260 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 261 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 262 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 263 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 264 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 265 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 266 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 267 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 268 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 269 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 270 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 271 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 272 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 273 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 274 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 275 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 276 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 277 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 278 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 279 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 280 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 281 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 282 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 283 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 284 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 285 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 286 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 287 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 288 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 289 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 290 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 291 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 292 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 293 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 294 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 295 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 296 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 297 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 298 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 299 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 300 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 301 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 302 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 303 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 304 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 305 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 306 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 307 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 308 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 309 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 310 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 311 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 312 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 313 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 314 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 315 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 316 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 317 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 318 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 319 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 320 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 321 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 322 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 323 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 324 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 325 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 326 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 327 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 328 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 329 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 330 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 331 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 332 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 333 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 334 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 335 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 336 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 337 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 338 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 339 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 340 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 341 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 342 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 343 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 344 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 345 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 346 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 347 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 348 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 349 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 350 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 351 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 352 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 353 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 354 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 355 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 356 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 357 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 358 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 359 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 360 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 361 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 362 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 363 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 364 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 365 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 366 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 367 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 368 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 369 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 370 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 371 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 372 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 373 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 374 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 375 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 376 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 377 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 378 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 379 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 380 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 381 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 382 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 383 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 384 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 385 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 386 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 387 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 388 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 389 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 390 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 391 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 392 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 393 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 394 | loss: 0.69315 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 395 | loss: 0.69315 - binary_acc: 0.4550 -- iter: 4/4\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 396 | loss: 0.69315 - binary_acc: 0.4595 -- iter: 4/4\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 397 | loss: 0.69315 - binary_acc: 0.4636 -- iter: 4/4\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 398 | loss: 0.69315 - binary_acc: 0.4672 -- iter: 4/4\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 399 | loss: 0.69315 - binary_acc: 0.4705 -- iter: 4/4\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 400 | loss: 0.69315 - binary_acc: 0.4734 -- iter: 4/4\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 401 | loss: 0.69315 - binary_acc: 0.4761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 402 | loss: 0.69315 - binary_acc: 0.4785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 403 | loss: 0.69315 - binary_acc: 0.4806 -- iter: 4/4\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 404 | loss: 0.69315 - binary_acc: 0.4826 -- iter: 4/4\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 405 | loss: 0.69315 - binary_acc: 0.4843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 406 | loss: 0.69315 - binary_acc: 0.4859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 407 | loss: 0.69315 - binary_acc: 0.4873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 408 | loss: 0.69315 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 409 | loss: 0.69315 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 410 | loss: 0.69315 - binary_acc: 0.4907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 411 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 412 | loss: 0.69315 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 413 | loss: 0.69315 - binary_acc: 0.4932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 414 | loss: 0.69315 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 415 | loss: 0.69315 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 416 | loss: 0.69315 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 417 | loss: 0.69315 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 418 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 419 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 420 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 421 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 422 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 423 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 424 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 425 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 426 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 427 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 428 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 429 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 430 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 431 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 432 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 433 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 434 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 435 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 436 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 437 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 438 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 439 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 440 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 441 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 442 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 443 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 444 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 445 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 446 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 447 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 448 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 449 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 450 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 451 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 452 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 453 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 454 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 455 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 456 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 457 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 458 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 459 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 460 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 461 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 462 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 463 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 464 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 465 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 466 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 467 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 468 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 469 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 470 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 471 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 472 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 473 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 474 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 475 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 476 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 477 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 478 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 479 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 480 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 481 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 482 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 483 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 484 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 485 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 486 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 487 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 488 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 489 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 490 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 491 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 492 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 493 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 494 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 495 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 496 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 497 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 498 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 499 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 500 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 501 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 502 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 503 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 504 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 505 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 506 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 507 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 508 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 509 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 510 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 511 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 512 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 513 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 514 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 515 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 516 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 517 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 518 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 519 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 520 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 521 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 522 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 523 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 524 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 525 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 526 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 527 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 528 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 529 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 530 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 531 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 532 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 533 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 534 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 535 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 536 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 537 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 538 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 539 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 540 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 541 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 542 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 543 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 544 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 545 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 546 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 547 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 548 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 549 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 550 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 551 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 552 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 553 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 554 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 555 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 556 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 557 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 558 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 559 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 560 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 561 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 562 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 563 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 564 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 565 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 566 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 567 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 568 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 569 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 570 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 571 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 572 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 573 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 574 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 575 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 576 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 577 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 578 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 579 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 580 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 581 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 582 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 583 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 584 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 585 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 586 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 587 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 588 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 589 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 590 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 591 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 592 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 593 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 594 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 595 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 596 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 597 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 598 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 599 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 600 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 601 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 602 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 603 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 604 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 605 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 606 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 607 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 608 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 609 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 610 | loss: 0.69315 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 611 | loss: 0.69315 - binary_acc: 0.4800 -- iter: 4/4\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 612 | loss: 0.69315 - binary_acc: 0.5070 -- iter: 4/4\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 613 | loss: 0.69315 - binary_acc: 0.5313 -- iter: 4/4\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 614 | loss: 0.69315 - binary_acc: 0.5532 -- iter: 4/4\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 615 | loss: 0.69315 - binary_acc: 0.5479 -- iter: 4/4\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 616 | loss: 0.69315 - binary_acc: 0.5431 -- iter: 4/4\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 617 | loss: 0.69315 - binary_acc: 0.5388 -- iter: 4/4\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 618 | loss: 0.69315 - binary_acc: 0.5349 -- iter: 4/4\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 619 | loss: 0.69315 - binary_acc: 0.5314 -- iter: 4/4\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 620 | loss: 0.69314 - binary_acc: 0.5783 -- iter: 4/4\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 621 | loss: 0.69314 - binary_acc: 0.5704 -- iter: 4/4\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 622 | loss: 0.69314 - binary_acc: 0.5634 -- iter: 4/4\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 623 | loss: 0.69314 - binary_acc: 0.5570 -- iter: 4/4\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 624 | loss: 0.69314 - binary_acc: 0.5513 -- iter: 4/4\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 625 | loss: 0.69314 - binary_acc: 0.5462 -- iter: 4/4\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 626 | loss: 0.69314 - binary_acc: 0.5416 -- iter: 4/4\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 627 | loss: 0.69314 - binary_acc: 0.5374 -- iter: 4/4\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 628 | loss: 0.69314 - binary_acc: 0.5337 -- iter: 4/4\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 629 | loss: 0.69314 - binary_acc: 0.5303 -- iter: 4/4\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 630 | loss: 0.69314 - binary_acc: 0.5273 -- iter: 4/4\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 631 | loss: 0.69314 - binary_acc: 0.5246 -- iter: 4/4\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 632 | loss: 0.69315 - binary_acc: 0.5221 -- iter: 4/4\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 633 | loss: 0.69315 - binary_acc: 0.5199 -- iter: 4/4\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 634 | loss: 0.69315 - binary_acc: 0.5179 -- iter: 4/4\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 635 | loss: 0.69315 - binary_acc: 0.5161 -- iter: 4/4\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 636 | loss: 0.69315 - binary_acc: 0.5145 -- iter: 4/4\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 637 | loss: 0.69315 - binary_acc: 0.5131 -- iter: 4/4\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 638 | loss: 0.69315 - binary_acc: 0.5117 -- iter: 4/4\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 639 | loss: 0.69315 - binary_acc: 0.5106 -- iter: 4/4\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 640 | loss: 0.69315 - binary_acc: 0.5095 -- iter: 4/4\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 641 | loss: 0.69315 - binary_acc: 0.5086 -- iter: 4/4\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 642 | loss: 0.69315 - binary_acc: 0.5077 -- iter: 4/4\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 643 | loss: 0.69315 - binary_acc: 0.5069 -- iter: 4/4\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 644 | loss: 0.69315 - binary_acc: 0.5062 -- iter: 4/4\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 645 | loss: 0.69315 - binary_acc: 0.5056 -- iter: 4/4\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 646 | loss: 0.69315 - binary_acc: 0.5051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 647 | loss: 0.69315 - binary_acc: 0.5046 -- iter: 4/4\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 648 | loss: 0.69315 - binary_acc: 0.5041 -- iter: 4/4\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 649 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 650 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 651 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 652 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 653 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 654 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 655 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 656 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 657 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 658 | loss: 0.69314 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 659 | loss: 0.69314 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 660 | loss: 0.69315 - binary_acc: 0.4512 -- iter: 4/4\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 661 | loss: 0.69315 - binary_acc: 0.4560 -- iter: 4/4\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 662 | loss: 0.69315 - binary_acc: 0.4604 -- iter: 4/4\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 663 | loss: 0.69315 - binary_acc: 0.4644 -- iter: 4/4\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 664 | loss: 0.69315 - binary_acc: 0.4680 -- iter: 4/4\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 665 | loss: 0.69315 - binary_acc: 0.4712 -- iter: 4/4\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 666 | loss: 0.69315 - binary_acc: 0.4740 -- iter: 4/4\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 667 | loss: 0.69315 - binary_acc: 0.4766 -- iter: 4/4\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 668 | loss: 0.69315 - binary_acc: 0.4790 -- iter: 4/4\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 669 | loss: 0.69315 - binary_acc: 0.4811 -- iter: 4/4\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 670 | loss: 0.69315 - binary_acc: 0.4830 -- iter: 4/4\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 671 | loss: 0.69315 - binary_acc: 0.4847 -- iter: 4/4\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 672 | loss: 0.69315 - binary_acc: 0.4862 -- iter: 4/4\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 673 | loss: 0.69315 - binary_acc: 0.4876 -- iter: 4/4\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 674 | loss: 0.69315 - binary_acc: 0.4888 -- iter: 4/4\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 675 | loss: 0.69315 - binary_acc: 0.4899 -- iter: 4/4\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 676 | loss: 0.69315 - binary_acc: 0.4909 -- iter: 4/4\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 677 | loss: 0.69315 - binary_acc: 0.4919 -- iter: 4/4\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 678 | loss: 0.69315 - binary_acc: 0.4927 -- iter: 4/4\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 679 | loss: 0.69315 - binary_acc: 0.4934 -- iter: 4/4\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 680 | loss: 0.69315 - binary_acc: 0.4941 -- iter: 4/4\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 681 | loss: 0.69315 - binary_acc: 0.4947 -- iter: 4/4\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 682 | loss: 0.69314 - binary_acc: 0.4952 -- iter: 4/4\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 683 | loss: 0.69314 - binary_acc: 0.4957 -- iter: 4/4\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 684 | loss: 0.69314 - binary_acc: 0.4961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 685 | loss: 0.69314 - binary_acc: 0.4965 -- iter: 4/4\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 686 | loss: 0.69314 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 687 | loss: 0.69314 - binary_acc: 0.4972 -- iter: 4/4\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 688 | loss: 0.69314 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 689 | loss: 0.69314 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 690 | loss: 0.69314 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 691 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 692 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 693 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 694 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 695 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 696 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 697 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 698 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 699 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 700 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 701 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 702 | loss: 0.69314 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 703 | loss: 0.69314 - binary_acc: 0.4745 -- iter: 4/4\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 704 | loss: 0.69314 - binary_acc: 0.4520 -- iter: 4/4\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 705 | loss: 0.69314 - binary_acc: 0.4318 -- iter: 4/4\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 706 | loss: 0.69314 - binary_acc: 0.4136 -- iter: 4/4\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 707 | loss: 0.69314 - binary_acc: 0.3973 -- iter: 4/4\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 708 | loss: 0.69314 - binary_acc: 0.3825 -- iter: 4/4\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 709 | loss: 0.69314 - binary_acc: 0.3693 -- iter: 4/4\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 710 | loss: 0.69314 - binary_acc: 0.3574 -- iter: 4/4\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 711 | loss: 0.69314 - binary_acc: 0.3466 -- iter: 4/4\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 712 | loss: 0.69314 - binary_acc: 0.3370 -- iter: 4/4\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 713 | loss: 0.69315 - binary_acc: 0.3283 -- iter: 4/4\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 714 | loss: 0.69315 - binary_acc: 0.3204 -- iter: 4/4\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 715 | loss: 0.69315 - binary_acc: 0.3134 -- iter: 4/4\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 716 | loss: 0.69314 - binary_acc: 0.3571 -- iter: 4/4\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 717 | loss: 0.69314 - binary_acc: 0.3464 -- iter: 4/4\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 718 | loss: 0.69314 - binary_acc: 0.3367 -- iter: 4/4\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 719 | loss: 0.69314 - binary_acc: 0.3280 -- iter: 4/4\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 720 | loss: 0.69315 - binary_acc: 0.3202 -- iter: 4/4\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 721 | loss: 0.69315 - binary_acc: 0.3132 -- iter: 4/4\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 722 | loss: 0.69315 - binary_acc: 0.3069 -- iter: 4/4\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 723 | loss: 0.69315 - binary_acc: 0.3012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 724 | loss: 0.69315 - binary_acc: 0.2961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 725 | loss: 0.69315 - binary_acc: 0.2915 -- iter: 4/4\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 726 | loss: 0.69315 - binary_acc: 0.2873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 727 | loss: 0.69315 - binary_acc: 0.2836 -- iter: 4/4\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 728 | loss: 0.69315 - binary_acc: 0.2802 -- iter: 4/4\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 729 | loss: 0.69315 - binary_acc: 0.2772 -- iter: 4/4\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 730 | loss: 0.69315 - binary_acc: 0.2745 -- iter: 4/4\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 731 | loss: 0.69315 - binary_acc: 0.2720 -- iter: 4/4\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 732 | loss: 0.69315 - binary_acc: 0.3198 -- iter: 4/4\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 733 | loss: 0.69315 - binary_acc: 0.3129 -- iter: 4/4\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 734 | loss: 0.69315 - binary_acc: 0.3066 -- iter: 4/4\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 735 | loss: 0.69315 - binary_acc: 0.3009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 736 | loss: 0.69315 - binary_acc: 0.2958 -- iter: 4/4\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 737 | loss: 0.69315 - binary_acc: 0.2912 -- iter: 4/4\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 738 | loss: 0.69315 - binary_acc: 0.2871 -- iter: 4/4\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 739 | loss: 0.69315 - binary_acc: 0.2834 -- iter: 4/4\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 740 | loss: 0.69315 - binary_acc: 0.3301 -- iter: 4/4\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 741 | loss: 0.69315 - binary_acc: 0.3221 -- iter: 4/4\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 742 | loss: 0.69315 - binary_acc: 0.3149 -- iter: 4/4\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 743 | loss: 0.69315 - binary_acc: 0.3334 -- iter: 4/4\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 744 | loss: 0.69315 - binary_acc: 0.3500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 745 | loss: 0.69315 - binary_acc: 0.3650 -- iter: 4/4\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 746 | loss: 0.69315 - binary_acc: 0.3785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 747 | loss: 0.69315 - binary_acc: 0.3907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 748 | loss: 0.69315 - binary_acc: 0.4016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 749 | loss: 0.69315 - binary_acc: 0.4114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 750 | loss: 0.69315 - binary_acc: 0.4203 -- iter: 4/4\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 751 | loss: 0.69315 - binary_acc: 0.4283 -- iter: 4/4\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 752 | loss: 0.69315 - binary_acc: 0.4354 -- iter: 4/4\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 753 | loss: 0.69315 - binary_acc: 0.4419 -- iter: 4/4\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 754 | loss: 0.69315 - binary_acc: 0.4477 -- iter: 4/4\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 755 | loss: 0.69315 - binary_acc: 0.4529 -- iter: 4/4\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 756 | loss: 0.69315 - binary_acc: 0.4576 -- iter: 4/4\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 757 | loss: 0.69315 - binary_acc: 0.4619 -- iter: 4/4\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 758 | loss: 0.69315 - binary_acc: 0.4657 -- iter: 4/4\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 759 | loss: 0.69315 - binary_acc: 0.4691 -- iter: 4/4\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 760 | loss: 0.69315 - binary_acc: 0.4722 -- iter: 4/4\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 761 | loss: 0.69315 - binary_acc: 0.4750 -- iter: 4/4\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 762 | loss: 0.69315 - binary_acc: 0.4775 -- iter: 4/4\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 763 | loss: 0.69315 - binary_acc: 0.4797 -- iter: 4/4\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 764 | loss: 0.69315 - binary_acc: 0.4818 -- iter: 4/4\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 765 | loss: 0.69315 - binary_acc: 0.4836 -- iter: 4/4\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 766 | loss: 0.69315 - binary_acc: 0.4852 -- iter: 4/4\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 767 | loss: 0.69315 - binary_acc: 0.4867 -- iter: 4/4\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 768 | loss: 0.69315 - binary_acc: 0.4880 -- iter: 4/4\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 769 | loss: 0.69315 - binary_acc: 0.4892 -- iter: 4/4\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 770 | loss: 0.69315 - binary_acc: 0.4903 -- iter: 4/4\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 771 | loss: 0.69315 - binary_acc: 0.4913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 772 | loss: 0.69315 - binary_acc: 0.4922 -- iter: 4/4\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 773 | loss: 0.69315 - binary_acc: 0.4929 -- iter: 4/4\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 774 | loss: 0.69315 - binary_acc: 0.4936 -- iter: 4/4\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 775 | loss: 0.69315 - binary_acc: 0.4943 -- iter: 4/4\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 776 | loss: 0.69315 - binary_acc: 0.4949 -- iter: 4/4\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 777 | loss: 0.69315 - binary_acc: 0.4954 -- iter: 4/4\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 778 | loss: 0.69315 - binary_acc: 0.4958 -- iter: 4/4\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 779 | loss: 0.69315 - binary_acc: 0.4962 -- iter: 4/4\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 780 | loss: 0.69315 - binary_acc: 0.4966 -- iter: 4/4\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 781 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 782 | loss: 0.69315 - binary_acc: 0.4473 -- iter: 4/4\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 783 | loss: 0.69315 - binary_acc: 0.4775 -- iter: 4/4\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 784 | loss: 0.69315 - binary_acc: 0.5048 -- iter: 4/4\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 785 | loss: 0.69315 - binary_acc: 0.5293 -- iter: 4/4\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 786 | loss: 0.69315 - binary_acc: 0.5514 -- iter: 4/4\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 787 | loss: 0.69315 - binary_acc: 0.5712 -- iter: 4/4\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 788 | loss: 0.69315 - binary_acc: 0.5891 -- iter: 4/4\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 789 | loss: 0.69315 - binary_acc: 0.6052 -- iter: 4/4\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 790 | loss: 0.69315 - binary_acc: 0.6197 -- iter: 4/4\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 791 | loss: 0.69315 - binary_acc: 0.6327 -- iter: 4/4\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 792 | loss: 0.69314 - binary_acc: 0.6444 -- iter: 4/4\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 793 | loss: 0.69314 - binary_acc: 0.6300 -- iter: 4/4\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 794 | loss: 0.69314 - binary_acc: 0.6170 -- iter: 4/4\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 795 | loss: 0.69314 - binary_acc: 0.6053 -- iter: 4/4\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 796 | loss: 0.69314 - binary_acc: 0.5948 -- iter: 4/4\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 797 | loss: 0.69315 - binary_acc: 0.5853 -- iter: 4/4\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 798 | loss: 0.69315 - binary_acc: 0.5768 -- iter: 4/4\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 799 | loss: 0.69315 - binary_acc: 0.5691 -- iter: 4/4\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 800 | loss: 0.69315 - binary_acc: 0.5622 -- iter: 4/4\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 801 | loss: 0.69315 - binary_acc: 0.5560 -- iter: 4/4\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 802 | loss: 0.69315 - binary_acc: 0.5504 -- iter: 4/4\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 803 | loss: 0.69315 - binary_acc: 0.5453 -- iter: 4/4\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 804 | loss: 0.69315 - binary_acc: 0.5408 -- iter: 4/4\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 805 | loss: 0.69315 - binary_acc: 0.5367 -- iter: 4/4\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 806 | loss: 0.69315 - binary_acc: 0.5330 -- iter: 4/4\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 807 | loss: 0.69315 - binary_acc: 0.5297 -- iter: 4/4\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 808 | loss: 0.69315 - binary_acc: 0.5268 -- iter: 4/4\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 809 | loss: 0.69315 - binary_acc: 0.5241 -- iter: 4/4\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 810 | loss: 0.69315 - binary_acc: 0.5217 -- iter: 4/4\n",
      "--\n",
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 811 | loss: 0.69315 - binary_acc: 0.5195 -- iter: 4/4\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 812 | loss: 0.69315 - binary_acc: 0.5176 -- iter: 4/4\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 813 | loss: 0.69315 - binary_acc: 0.5158 -- iter: 4/4\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 814 | loss: 0.69315 - binary_acc: 0.5142 -- iter: 4/4\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 815 | loss: 0.69315 - binary_acc: 0.5128 -- iter: 4/4\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 816 | loss: 0.69315 - binary_acc: 0.5115 -- iter: 4/4\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 817 | loss: 0.69315 - binary_acc: 0.5104 -- iter: 4/4\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 818 | loss: 0.69315 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 819 | loss: 0.69315 - binary_acc: 0.5084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 820 | loss: 0.69315 - binary_acc: 0.5076 -- iter: 4/4\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 821 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 822 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 823 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 824 | loss: 0.69315 - binary_acc: 0.5050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 825 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 826 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 827 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 828 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 829 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 830 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 831 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 832 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 833 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 834 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 835 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 836 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 837 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 838 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 839 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 840 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 841 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 842 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 843 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 844 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 845 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 846 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 847 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 848 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 849 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 850 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 851 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 852 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 853 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 854 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 855 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 856 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 857 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 858 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 859 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 860 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 861 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 862 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 863 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 864 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 865 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 866 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 867 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 868 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 869 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 870 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 871 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 872 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 873 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 874 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 875 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 876 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 877 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 878 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 879 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 880 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 881 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 882 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 883 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 884 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 885 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 886 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 887 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 888 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 889 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 890 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 891 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 892 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 893 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 894 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 895 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 896 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 897 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 898 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 899 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 900 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 901 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 902 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 903 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 904 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 905 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 906 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 907 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 908 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 909 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 910 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 911 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 912 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 913 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 914 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 915 | loss: 0.69314 - binary_acc: 0.4750 -- iter: 4/4\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 916 | loss: 0.69314 - binary_acc: 0.4525 -- iter: 4/4\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 917 | loss: 0.69314 - binary_acc: 0.4323 -- iter: 4/4\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 918 | loss: 0.69314 - binary_acc: 0.4140 -- iter: 4/4\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 919 | loss: 0.69314 - binary_acc: 0.3976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 920 | loss: 0.69315 - binary_acc: 0.3829 -- iter: 4/4\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 921 | loss: 0.69315 - binary_acc: 0.3946 -- iter: 4/4\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 922 | loss: 0.69315 - binary_acc: 0.4051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 923 | loss: 0.69315 - binary_acc: 0.4146 -- iter: 4/4\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 924 | loss: 0.69315 - binary_acc: 0.4231 -- iter: 4/4\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 925 | loss: 0.69315 - binary_acc: 0.4308 -- iter: 4/4\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 926 | loss: 0.69315 - binary_acc: 0.4377 -- iter: 4/4\n",
      "--\n",
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 927 | loss: 0.69315 - binary_acc: 0.4440 -- iter: 4/4\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 928 | loss: 0.69315 - binary_acc: 0.4496 -- iter: 4/4\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 929 | loss: 0.69315 - binary_acc: 0.4546 -- iter: 4/4\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 930 | loss: 0.69315 - binary_acc: 0.4592 -- iter: 4/4\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 931 | loss: 0.69315 - binary_acc: 0.4632 -- iter: 4/4\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 932 | loss: 0.69315 - binary_acc: 0.4669 -- iter: 4/4\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 933 | loss: 0.69315 - binary_acc: 0.4702 -- iter: 4/4\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 934 | loss: 0.69315 - binary_acc: 0.4732 -- iter: 4/4\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 935 | loss: 0.69315 - binary_acc: 0.4759 -- iter: 4/4\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 936 | loss: 0.69315 - binary_acc: 0.4783 -- iter: 4/4\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 937 | loss: 0.69315 - binary_acc: 0.4805 -- iter: 4/4\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 938 | loss: 0.69315 - binary_acc: 0.4824 -- iter: 4/4\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 939 | loss: 0.69315 - binary_acc: 0.4842 -- iter: 4/4\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 940 | loss: 0.69315 - binary_acc: 0.4858 -- iter: 4/4\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 941 | loss: 0.69315 - binary_acc: 0.4872 -- iter: 4/4\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 942 | loss: 0.69315 - binary_acc: 0.4885 -- iter: 4/4\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 943 | loss: 0.69315 - binary_acc: 0.4896 -- iter: 4/4\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 944 | loss: 0.69315 - binary_acc: 0.4907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 945 | loss: 0.69315 - binary_acc: 0.4916 -- iter: 4/4\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 946 | loss: 0.69315 - binary_acc: 0.4924 -- iter: 4/4\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 947 | loss: 0.69315 - binary_acc: 0.4932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 948 | loss: 0.69315 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 949 | loss: 0.69315 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 950 | loss: 0.69315 - binary_acc: 0.4950 -- iter: 4/4\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 951 | loss: 0.69315 - binary_acc: 0.4955 -- iter: 4/4\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 952 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 953 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 954 | loss: 0.69315 - binary_acc: 0.4967 -- iter: 4/4\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 955 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 956 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 957 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 958 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 959 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 960 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 961 | loss: 0.69315 - binary_acc: 0.4984 -- iter: 4/4\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 962 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 963 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 964 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 965 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 966 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 967 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 968 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 969 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 970 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 971 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 972 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 973 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 974 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 975 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 976 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 977 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 978 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 979 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 980 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 981 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 982 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 983 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 984 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 985 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 986 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 987 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 988 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 989 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 990 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 991 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 992 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 993 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 994 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 995 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 996 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 997 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 998 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 999 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1000 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1001  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1001 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1002  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1002 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1003  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1003 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1004  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1004 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1005  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1005 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1006  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1006 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1007  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1007 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1008  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1008 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1009  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1009 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1010  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1010 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1011  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1011 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1012  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1012 | loss: 0.69315 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1013  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1013 | loss: 0.69315 - binary_acc: 0.4800 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1014  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1014 | loss: 0.69315 - binary_acc: 0.5070 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1015  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1015 | loss: 0.69315 - binary_acc: 0.5313 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1016  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1016 | loss: 0.69315 - binary_acc: 0.5532 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1017  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1017 | loss: 0.69315 - binary_acc: 0.5728 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1018  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1018 | loss: 0.69315 - binary_acc: 0.5906 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1019  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1019 | loss: 0.69315 - binary_acc: 0.6065 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1020  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1020 | loss: 0.69315 - binary_acc: 0.6209 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1021  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1021 | loss: 0.69315 - binary_acc: 0.6338 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1022  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1022 | loss: 0.69315 - binary_acc: 0.6454 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1023  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1023 | loss: 0.69315 - binary_acc: 0.6559 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1024  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1024 | loss: 0.69315 - binary_acc: 0.6653 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1025  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1025 | loss: 0.69315 - binary_acc: 0.6737 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1026  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1026 | loss: 0.69315 - binary_acc: 0.6814 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1027  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1027 | loss: 0.69315 - binary_acc: 0.6882 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1028  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1028 | loss: 0.69315 - binary_acc: 0.6944 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1029  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1029 | loss: 0.69315 - binary_acc: 0.7000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1030  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1030 | loss: 0.69315 - binary_acc: 0.7050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1031  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1031 | loss: 0.69315 - binary_acc: 0.7095 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1032  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1032 | loss: 0.69315 - binary_acc: 0.7135 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1033  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1033 | loss: 0.69315 - binary_acc: 0.7172 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1034  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1034 | loss: 0.69315 - binary_acc: 0.7205 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1035  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1035 | loss: 0.69315 - binary_acc: 0.7234 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1036  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1036 | loss: 0.69315 - binary_acc: 0.7261 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1037  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1037 | loss: 0.69315 - binary_acc: 0.7285 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1038  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1038 | loss: 0.69315 - binary_acc: 0.7306 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1039  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1039 | loss: 0.69315 - binary_acc: 0.7326 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1040  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1040 | loss: 0.69315 - binary_acc: 0.7343 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1041  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1041 | loss: 0.69315 - binary_acc: 0.7359 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1042  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1042 | loss: 0.69315 - binary_acc: 0.7373 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1043  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1043 | loss: 0.69315 - binary_acc: 0.7386 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1044  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1044 | loss: 0.69315 - binary_acc: 0.7397 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1045  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1045 | loss: 0.69315 - binary_acc: 0.7407 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1046  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1046 | loss: 0.69315 - binary_acc: 0.7417 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1047  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1047 | loss: 0.69315 - binary_acc: 0.7425 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1048  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1048 | loss: 0.69315 - binary_acc: 0.7432 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1049  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1049 | loss: 0.69315 - binary_acc: 0.7439 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1050  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1050 | loss: 0.69315 - binary_acc: 0.7445 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1051  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1051 | loss: 0.69315 - binary_acc: 0.7451 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1052  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1052 | loss: 0.69315 - binary_acc: 0.7456 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1053  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1053 | loss: 0.69315 - binary_acc: 0.7460 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1054  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1054 | loss: 0.69315 - binary_acc: 0.7464 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1055  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1055 | loss: 0.69315 - binary_acc: 0.7468 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1056  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1056 | loss: 0.69315 - binary_acc: 0.7471 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1057  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1057 | loss: 0.69315 - binary_acc: 0.7474 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1058  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1058 | loss: 0.69315 - binary_acc: 0.7476 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1059  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1059 | loss: 0.69315 - binary_acc: 0.7479 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1060  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1060 | loss: 0.69315 - binary_acc: 0.7481 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1061  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1061 | loss: 0.69315 - binary_acc: 0.7483 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1062  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1062 | loss: 0.69315 - binary_acc: 0.7485 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1063  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1063 | loss: 0.69315 - binary_acc: 0.7486 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1064  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1064 | loss: 0.69315 - binary_acc: 0.7487 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1065  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1065 | loss: 0.69315 - binary_acc: 0.7489 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1066  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1066 | loss: 0.69315 - binary_acc: 0.7490 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1067  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1067 | loss: 0.69315 - binary_acc: 0.7491 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1068  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1068 | loss: 0.69315 - binary_acc: 0.7492 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1069  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1069 | loss: 0.69315 - binary_acc: 0.7493 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1070  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1070 | loss: 0.69315 - binary_acc: 0.7493 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1071  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1071 | loss: 0.69315 - binary_acc: 0.7244 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1072  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1072 | loss: 0.69315 - binary_acc: 0.7020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1073  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1073 | loss: 0.69315 - binary_acc: 0.6818 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1074  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1074 | loss: 0.69315 - binary_acc: 0.6636 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1075  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1075 | loss: 0.69315 - binary_acc: 0.6472 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1076  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1076 | loss: 0.69315 - binary_acc: 0.6325 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1077  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1077 | loss: 0.69315 - binary_acc: 0.6193 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1078  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1078 | loss: 0.69315 - binary_acc: 0.6073 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1079  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1079 | loss: 0.69315 - binary_acc: 0.5966 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1080  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1080 | loss: 0.69315 - binary_acc: 0.5869 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1081  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1081 | loss: 0.69315 - binary_acc: 0.5782 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1082  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1082 | loss: 0.69315 - binary_acc: 0.5704 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1083  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1083 | loss: 0.69315 - binary_acc: 0.5634 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1084  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1084 | loss: 0.69315 - binary_acc: 0.5570 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1085  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1085 | loss: 0.69315 - binary_acc: 0.5513 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1086  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1086 | loss: 0.69315 - binary_acc: 0.5462 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1087  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1087 | loss: 0.69315 - binary_acc: 0.5416 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1088  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1088 | loss: 0.69315 - binary_acc: 0.5374 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1089  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1089 | loss: 0.69315 - binary_acc: 0.5337 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1090  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1090 | loss: 0.69315 - binary_acc: 0.5303 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1091  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1091 | loss: 0.69315 - binary_acc: 0.5273 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1092  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1092 | loss: 0.69315 - binary_acc: 0.5246 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1093  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1093 | loss: 0.69315 - binary_acc: 0.5221 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1094  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1094 | loss: 0.69315 - binary_acc: 0.5199 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1095  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1095 | loss: 0.69315 - binary_acc: 0.5179 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1096  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1096 | loss: 0.69315 - binary_acc: 0.5161 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1097  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1097 | loss: 0.69315 - binary_acc: 0.5145 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1098  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1098 | loss: 0.69315 - binary_acc: 0.5130 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1099  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1099 | loss: 0.69315 - binary_acc: 0.5117 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1100  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1100 | loss: 0.69315 - binary_acc: 0.5106 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1101  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1101 | loss: 0.69315 - binary_acc: 0.5095 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1102  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1102 | loss: 0.69315 - binary_acc: 0.5086 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1103  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1103 | loss: 0.69315 - binary_acc: 0.5077 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1104  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1104 | loss: 0.69315 - binary_acc: 0.5069 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1105  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1105 | loss: 0.69315 - binary_acc: 0.5062 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1106  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1106 | loss: 0.69315 - binary_acc: 0.5056 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1107  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1107 | loss: 0.69315 - binary_acc: 0.5051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1108  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1108 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1109  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1109 | loss: 0.69315 - binary_acc: 0.5041 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1110  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1110 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1111  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1111 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1112  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1112 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1113  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1113 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1114  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1114 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1115  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1115 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1116  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1116 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1117  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1117 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1118  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1118 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1119  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1119 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1120  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1120 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1121  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1121 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1122  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1122 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1123  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1123 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1124  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1124 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1125  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1125 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1126  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1126 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1127  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1127 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1128  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1128 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1129  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1129 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1130  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1130 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1131  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1131 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1132  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1132 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1133  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1133 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1134  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1134 | loss: 0.69314 - binary_acc: 0.5503 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1135  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1135 | loss: 0.69314 - binary_acc: 0.5453 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1136  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1136 | loss: 0.69314 - binary_acc: 0.5407 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1137  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1137 | loss: 0.69314 - binary_acc: 0.5367 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1138  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1138 | loss: 0.69314 - binary_acc: 0.5330 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1139  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1139 | loss: 0.69314 - binary_acc: 0.5297 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1140  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1140 | loss: 0.69314 - binary_acc: 0.5267 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1141  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1141 | loss: 0.69314 - binary_acc: 0.5241 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1142  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1142 | loss: 0.69314 - binary_acc: 0.5216 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1143  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1143 | loss: 0.69314 - binary_acc: 0.5195 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1144  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1144 | loss: 0.69315 - binary_acc: 0.5175 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1145  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1145 | loss: 0.69315 - binary_acc: 0.5158 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1146  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1146 | loss: 0.69315 - binary_acc: 0.5142 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1147  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1147 | loss: 0.69315 - binary_acc: 0.5128 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1148  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1148 | loss: 0.69315 - binary_acc: 0.5115 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1149  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1149 | loss: 0.69315 - binary_acc: 0.5104 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1150  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1150 | loss: 0.69315 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1151  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1151 | loss: 0.69315 - binary_acc: 0.5084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1152  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1152 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1153  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1153 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1154  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1154 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1155  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1155 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1156  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1156 | loss: 0.69315 - binary_acc: 0.5050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1157  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1157 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1158  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1158 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1159  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1159 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1160  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1160 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1161  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1161 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1162  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1162 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1163  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1163 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1164  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1164 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1165  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1165 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1166  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1166 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1167  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1167 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1168  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1168 | loss: 0.69314 - binary_acc: 0.5514 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1169  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1169 | loss: 0.69314 - binary_acc: 0.5463 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1170  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1170 | loss: 0.69314 - binary_acc: 0.5416 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1171  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1171 | loss: 0.69314 - binary_acc: 0.5375 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1172  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1172 | loss: 0.69314 - binary_acc: 0.5337 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1173  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1173 | loss: 0.69314 - binary_acc: 0.5304 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1174  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1174 | loss: 0.69314 - binary_acc: 0.5273 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1175  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1175 | loss: 0.69314 - binary_acc: 0.5246 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1176  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1176 | loss: 0.69314 - binary_acc: 0.5221 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1177  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1177 | loss: 0.69314 - binary_acc: 0.5199 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1178  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1178 | loss: 0.69314 - binary_acc: 0.5179 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1179  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1179 | loss: 0.69315 - binary_acc: 0.5161 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1180  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1180 | loss: 0.69315 - binary_acc: 0.5145 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1181  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1181 | loss: 0.69315 - binary_acc: 0.5131 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1182  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1182 | loss: 0.69315 - binary_acc: 0.5118 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1183  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1183 | loss: 0.69315 - binary_acc: 0.5106 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1184  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1184 | loss: 0.69315 - binary_acc: 0.5095 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1185  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1185 | loss: 0.69315 - binary_acc: 0.5086 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1186  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1186 | loss: 0.69315 - binary_acc: 0.5077 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1187  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1187 | loss: 0.69315 - binary_acc: 0.5069 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1188  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1188 | loss: 0.69315 - binary_acc: 0.5062 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1189  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1189 | loss: 0.69315 - binary_acc: 0.5056 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1190  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1190 | loss: 0.69315 - binary_acc: 0.5051 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1191  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1191 | loss: 0.69315 - binary_acc: 0.5046 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1192  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1192 | loss: 0.69315 - binary_acc: 0.5041 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1193  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1193 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1194  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1194 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1195  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1195 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1196  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1196 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1197  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1197 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1198  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1198 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1199  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1199 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1200  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1200 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1201  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1201 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1202  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1202 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1203  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1203 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1204  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1204 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1205  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1205 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1206  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1206 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1207  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1207 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1208  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1208 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1209  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1209 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1210  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1210 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1211  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1211 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1212  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1212 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1213  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1213 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1214  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1214 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1215  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1215 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1216  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1216 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1217  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1217 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1218  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1218 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1219  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1219 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1220  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1220 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1221  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1221 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1222  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1222 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1223  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1223 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1224  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1224 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1225  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1225 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1226  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1226 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1227  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1227 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1228  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1228 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1229  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1229 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1230  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1230 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1231  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1231 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1232  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1232 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1233  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1233 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1234  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1234 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1235  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1235 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1236  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1236 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1237  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1237 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1238  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1238 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1239  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1239 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1240  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1240 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1241  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1241 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1242  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1242 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1243  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1243 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1244  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1244 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1245  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1245 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1246  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1246 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1247  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1247 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1248  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1248 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1249  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1249 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1250  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1250 | loss: 0.69314 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1251  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1251 | loss: 0.69314 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1252  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1252 | loss: 0.69314 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1253  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1253 | loss: 0.69314 - binary_acc: 0.5365 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1254  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1254 | loss: 0.69314 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1255  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1255 | loss: 0.69314 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1256  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1256 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1257  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1257 | loss: 0.69314 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1258  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1258 | loss: 0.69314 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1259  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1259 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1260  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1260 | loss: 0.69314 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1261  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1261 | loss: 0.69315 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1262  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1262 | loss: 0.69315 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1263  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1263 | loss: 0.69315 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1264  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1264 | loss: 0.69315 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1265  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1265 | loss: 0.69315 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1266  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1266 | loss: 0.69315 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1267  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1267 | loss: 0.69315 - binary_acc: 0.5083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1268  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1268 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1269  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1269 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1270  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1270 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1271  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1271 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1272  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1272 | loss: 0.69315 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1273  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1273 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1274  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1274 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1275  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1275 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1276  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1276 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1277  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1277 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1278  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1278 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1279  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 1279 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1280  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1280 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1281  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1281 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1282  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1282 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1283  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1283 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1284  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1284 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1285  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1285 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1286  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1286 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1287  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1287 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1288  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1288 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1289  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1289 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1290  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1290 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1291  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1291 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1292  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1292 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1293  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1293 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1294  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1294 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1295  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1295 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1296  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1296 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1297  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1297 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1298  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1298 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1299  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1299 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1300  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1300 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1301  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1301 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1302  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1302 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1303  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1303 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1304  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1304 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1305  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1305 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1306  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1306 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1307  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1307 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1308  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1308 | loss: 0.69315 - binary_acc: 0.4501 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1309  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1309 | loss: 0.69315 - binary_acc: 0.4551 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1310  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1310 | loss: 0.69315 - binary_acc: 0.4596 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1311  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1311 | loss: 0.69315 - binary_acc: 0.4636 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1312  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1312 | loss: 0.69315 - binary_acc: 0.4673 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1313  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1313 | loss: 0.69315 - binary_acc: 0.4705 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1314  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1314 | loss: 0.69315 - binary_acc: 0.4735 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1315  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1315 | loss: 0.69315 - binary_acc: 0.4761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1316  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1316 | loss: 0.69315 - binary_acc: 0.4785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1317  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1317 | loss: 0.69315 - binary_acc: 0.4807 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1318  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1318 | loss: 0.69315 - binary_acc: 0.4826 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1319  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1319 | loss: 0.69315 - binary_acc: 0.4843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1320  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1320 | loss: 0.69315 - binary_acc: 0.4859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1321  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1321 | loss: 0.69315 - binary_acc: 0.4873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1322  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1322 | loss: 0.69315 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1323  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1323 | loss: 0.69315 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1324  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1324 | loss: 0.69315 - binary_acc: 0.4908 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1325  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1325 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1326  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1326 | loss: 0.69315 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1327  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1327 | loss: 0.69315 - binary_acc: 0.4933 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1328  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1328 | loss: 0.69315 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1329  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1329 | loss: 0.69315 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1330  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1330 | loss: 0.69315 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1331  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1331 | loss: 0.69315 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1332  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1332 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1333  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1333 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1334  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1334 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1335  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1335 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1336  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1336 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1337  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1337 | loss: 0.69315 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1338  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1338 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1339  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1339 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1340  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1340 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1341  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1341 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1342  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1342 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1343  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1343 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1344  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1344 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1345  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1345 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1346  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1346 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1347  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1347 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1348  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1348 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1349  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1349 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1350  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1350 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1351  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1351 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1352  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1352 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1353  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1353 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1354  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1354 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1355  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1355 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1356  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1356 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1357  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1357 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1358  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1358 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1359  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1359 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1360  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1360 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1361  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1361 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1362  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1362 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1363  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1363 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1364  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1364 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1365  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1365 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1366  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1366 | loss: 0.69315 - binary_acc: 0.4499 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1367  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1367 | loss: 0.69315 - binary_acc: 0.4799 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1368  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1368 | loss: 0.69315 - binary_acc: 0.5069 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1369  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1369 | loss: 0.69315 - binary_acc: 0.5062 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1370  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1370 | loss: 0.69315 - binary_acc: 0.5056 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1371  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1371 | loss: 0.69315 - binary_acc: 0.5050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1372  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1372 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1373  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1373 | loss: 0.69315 - binary_acc: 0.5041 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1374  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1374 | loss: 0.69315 - binary_acc: 0.5037 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1375  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1375 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1376  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1376 | loss: 0.69315 - binary_acc: 0.5030 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1377  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1377 | loss: 0.69315 - binary_acc: 0.5027 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1378  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1378 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1379  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1379 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1380  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1380 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1381  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1381 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1382  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1382 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1383  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1383 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1384  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1384 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1385  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1385 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1386  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1386 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1387  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1387 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1388  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1388 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1389  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 1389 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1390  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1390 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1391  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1391 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1392  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1392 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1393  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1393 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1394  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1394 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1395  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1395 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1396  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1396 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1397  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1397 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1398  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1398 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1399  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1399 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1400  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1400 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1401  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1401 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1402  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1402 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1403  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1403 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1404  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1404 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1405  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1405 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1406  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1406 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1407  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1407 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1408 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1409 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1410 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1411 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1412  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1412 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1413  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1413 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1414  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1414 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1415  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1415 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1416  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1416 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1417  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1417 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1418  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1418 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1419  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1419 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1420  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1420 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1421  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1421 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1422  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1422 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1423  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1423 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1424  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1424 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1425  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1425 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1426  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1426 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1427 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1428 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1429 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1430 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1431 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1432 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1433 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1434 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1435 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1436 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1437 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1438  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1438 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1439  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1439 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1440  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1440 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1441  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1441 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1442  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1442 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1443  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1443 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1444  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1444 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1445  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1445 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1446  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1446 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1447  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1447 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1448  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1448 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1449  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1449 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1450  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1450 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1451  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1451 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1452  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1452 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1453  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1453 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1454  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1454 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1455  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1455 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1456  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1456 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1457  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1457 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1458  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1458 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1459  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1459 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1460  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1460 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1461  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1461 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1462  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1462 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1463  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1463 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1464  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1464 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1465  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1465 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1466  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1466 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1467  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1467 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1468  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1468 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1469  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1469 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1470  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1470 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1471  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1471 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1472  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1472 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1473  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1473 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1474  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1474 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1475  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1475 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1476  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1476 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1477  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1477 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1478  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1478 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1479  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1479 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1480  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1480 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1481  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1481 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1482  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1482 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1483  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1483 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1484  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1484 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1485  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1485 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1486  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1486 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1487  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1487 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1488  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1488 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1489  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1489 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1490  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1490 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1491  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1491 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1492  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1492 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1493  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1493 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1494  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1494 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1495  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1495 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1496  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1496 | loss: 0.69314 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1497  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1497 | loss: 0.69314 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1498  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1498 | loss: 0.69314 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1499  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1499 | loss: 0.69314 - binary_acc: 0.5365 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1500  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1500 | loss: 0.69314 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1501  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1501 | loss: 0.69314 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1502  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1502 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1503  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1503 | loss: 0.69314 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1504  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1504 | loss: 0.69314 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1505  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1505 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1506  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1506 | loss: 0.69314 - binary_acc: 0.5674 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1507  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1507 | loss: 0.69314 - binary_acc: 0.5607 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1508  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1508 | loss: 0.69314 - binary_acc: 0.5546 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1509  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1509 | loss: 0.69314 - binary_acc: 0.5492 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1510  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1510 | loss: 0.69314 - binary_acc: 0.5442 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1511  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1511 | loss: 0.69314 - binary_acc: 0.5398 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1512  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1512 | loss: 0.69314 - binary_acc: 0.5358 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1513  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1513 | loss: 0.69314 - binary_acc: 0.5323 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1514  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1514 | loss: 0.69314 - binary_acc: 0.5290 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1515  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1515 | loss: 0.69314 - binary_acc: 0.5261 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1516  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1516 | loss: 0.69314 - binary_acc: 0.5235 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1517  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1517 | loss: 0.69314 - binary_acc: 0.5212 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1518  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1518 | loss: 0.69314 - binary_acc: 0.5190 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1519  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1519 | loss: 0.69314 - binary_acc: 0.5171 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1520  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1520 | loss: 0.69315 - binary_acc: 0.5154 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1521  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1521 | loss: 0.69315 - binary_acc: 0.5139 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1522  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1522 | loss: 0.69315 - binary_acc: 0.5125 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1523  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1523 | loss: 0.69315 - binary_acc: 0.5112 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1524  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1524 | loss: 0.69315 - binary_acc: 0.5101 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1525  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1525 | loss: 0.69315 - binary_acc: 0.5091 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1526  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1526 | loss: 0.69315 - binary_acc: 0.5082 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1527  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1527 | loss: 0.69315 - binary_acc: 0.5074 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1528  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1528 | loss: 0.69315 - binary_acc: 0.5066 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1529  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1529 | loss: 0.69315 - binary_acc: 0.5060 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1530  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1530 | loss: 0.69315 - binary_acc: 0.5054 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1531  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1531 | loss: 0.69315 - binary_acc: 0.5048 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1532  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1532 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1533  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1533 | loss: 0.69315 - binary_acc: 0.5039 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1534  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1534 | loss: 0.69315 - binary_acc: 0.5035 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1535  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1535 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1536  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1536 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1537  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1537 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1538  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1538 | loss: 0.69315 - binary_acc: 0.5023 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1539  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1539 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1540  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1540 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1541  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1541 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1542  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1542 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1543  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1543 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1544  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1544 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1545  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1545 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1546  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1546 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1547  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1547 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1548  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1548 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1549  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1549 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1550  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1550 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1551  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1551 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1552  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1552 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1553  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1553 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1554  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1554 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1555  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1555 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1556  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1556 | loss: 0.69315 - binary_acc: 0.4503 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1557  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1557 | loss: 0.69315 - binary_acc: 0.4553 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1558  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1558 | loss: 0.69315 - binary_acc: 0.4598 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1559  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1559 | loss: 0.69315 - binary_acc: 0.4638 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1560  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1560 | loss: 0.69315 - binary_acc: 0.4674 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1561  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1561 | loss: 0.69315 - binary_acc: 0.4707 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1562  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1562 | loss: 0.69315 - binary_acc: 0.4736 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1563  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1563 | loss: 0.69315 - binary_acc: 0.4763 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1564  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1564 | loss: 0.69315 - binary_acc: 0.4786 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1565  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1565 | loss: 0.69315 - binary_acc: 0.4808 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1566  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1566 | loss: 0.69315 - binary_acc: 0.4827 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1567  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1567 | loss: 0.69315 - binary_acc: 0.4844 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1568  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1568 | loss: 0.69315 - binary_acc: 0.4860 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1569  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 1569 | loss: 0.69315 - binary_acc: 0.4874 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1570  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1570 | loss: 0.69315 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1571  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1571 | loss: 0.69315 - binary_acc: 0.4898 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1572  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1572 | loss: 0.69315 - binary_acc: 0.4908 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1573  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1573 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1574  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1574 | loss: 0.69315 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1575  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1575 | loss: 0.69315 - binary_acc: 0.4933 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1576  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1576 | loss: 0.69315 - binary_acc: 0.4940 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1577  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1577 | loss: 0.69315 - binary_acc: 0.4946 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1578  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1578 | loss: 0.69314 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1579  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1579 | loss: 0.69314 - binary_acc: 0.4706 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1580  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1580 | loss: 0.69314 - binary_acc: 0.4485 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1581  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1581 | loss: 0.69314 - binary_acc: 0.4287 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1582  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1582 | loss: 0.69315 - binary_acc: 0.4108 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1583  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1583 | loss: 0.69315 - binary_acc: 0.4197 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1584  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1584 | loss: 0.69315 - binary_acc: 0.4278 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1585  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1585 | loss: 0.69315 - binary_acc: 0.4350 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1586  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1586 | loss: 0.69315 - binary_acc: 0.4415 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1587  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1587 | loss: 0.69315 - binary_acc: 0.4473 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1588  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1588 | loss: 0.69315 - binary_acc: 0.4526 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1589  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1589 | loss: 0.69315 - binary_acc: 0.4573 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1590  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1590 | loss: 0.69315 - binary_acc: 0.4616 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1591  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.015s\n",
      "| SGD | epoch: 1591 | loss: 0.69315 - binary_acc: 0.4654 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1592  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1592 | loss: 0.69315 - binary_acc: 0.4689 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1593  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1593 | loss: 0.69315 - binary_acc: 0.4720 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1594  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1594 | loss: 0.69315 - binary_acc: 0.4248 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1595  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1595 | loss: 0.69315 - binary_acc: 0.4573 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1596  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1596 | loss: 0.69315 - binary_acc: 0.4866 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1597  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1597 | loss: 0.69315 - binary_acc: 0.4879 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1598  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1598 | loss: 0.69315 - binary_acc: 0.4891 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1599  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1599 | loss: 0.69315 - binary_acc: 0.4902 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1600  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1600 | loss: 0.69314 - binary_acc: 0.4912 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1601  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1601 | loss: 0.69314 - binary_acc: 0.4671 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1602  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1602 | loss: 0.69314 - binary_acc: 0.4454 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1603  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1603 | loss: 0.69314 - binary_acc: 0.4258 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1604  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1604 | loss: 0.69314 - binary_acc: 0.4083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1605  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1605 | loss: 0.69314 - binary_acc: 0.3924 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1606  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1606 | loss: 0.69314 - binary_acc: 0.4282 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1607  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1607 | loss: 0.69314 - binary_acc: 0.4104 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1608  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1608 | loss: 0.69314 - binary_acc: 0.3943 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1609  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1609 | loss: 0.69314 - binary_acc: 0.3799 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1610  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1610 | loss: 0.69315 - binary_acc: 0.3669 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1611  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1611 | loss: 0.69315 - binary_acc: 0.3552 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1612  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1612 | loss: 0.69315 - binary_acc: 0.3447 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1613  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1613 | loss: 0.69315 - binary_acc: 0.3352 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1614  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1614 | loss: 0.69315 - binary_acc: 0.3767 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1615  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1615 | loss: 0.69315 - binary_acc: 0.3640 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1616  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1616 | loss: 0.69315 - binary_acc: 0.3526 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1617  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1617 | loss: 0.69315 - binary_acc: 0.3424 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1618  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1618 | loss: 0.69315 - binary_acc: 0.3331 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1619  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1619 | loss: 0.69315 - binary_acc: 0.3248 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1620  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1620 | loss: 0.69315 - binary_acc: 0.3173 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1621  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1621 | loss: 0.69315 - binary_acc: 0.3106 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1622  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1622 | loss: 0.69315 - binary_acc: 0.3045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1623  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1623 | loss: 0.69315 - binary_acc: 0.2991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1624  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1624 | loss: 0.69315 - binary_acc: 0.2942 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1625  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1625 | loss: 0.69315 - binary_acc: 0.2898 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1626  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1626 | loss: 0.69315 - binary_acc: 0.2858 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1627  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1627 | loss: 0.69315 - binary_acc: 0.2822 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1628  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1628 | loss: 0.69315 - binary_acc: 0.2790 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1629  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1629 | loss: 0.69315 - binary_acc: 0.2761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1630  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1630 | loss: 0.69315 - binary_acc: 0.2735 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1631  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1631 | loss: 0.69315 - binary_acc: 0.2711 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1632  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1632 | loss: 0.69315 - binary_acc: 0.2690 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1633  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1633 | loss: 0.69315 - binary_acc: 0.2671 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1634  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1634 | loss: 0.69315 - binary_acc: 0.2654 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1635  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1635 | loss: 0.69315 - binary_acc: 0.2639 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1636  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1636 | loss: 0.69315 - binary_acc: 0.2625 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1637  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1637 | loss: 0.69315 - binary_acc: 0.2612 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1638  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1638 | loss: 0.69315 - binary_acc: 0.2601 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1639  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1639 | loss: 0.69315 - binary_acc: 0.2591 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1640  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1640 | loss: 0.69315 - binary_acc: 0.2582 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1641  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1641 | loss: 0.69315 - binary_acc: 0.2574 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1642  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1642 | loss: 0.69314 - binary_acc: 0.3066 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1643  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1643 | loss: 0.69314 - binary_acc: 0.3010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1644  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1644 | loss: 0.69314 - binary_acc: 0.2959 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1645  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1645 | loss: 0.69314 - binary_acc: 0.2913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1646  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1646 | loss: 0.69314 - binary_acc: 0.2872 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1647  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1647 | loss: 0.69314 - binary_acc: 0.2834 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1648  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1648 | loss: 0.69314 - binary_acc: 0.2801 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1649  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1649 | loss: 0.69314 - binary_acc: 0.2771 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1650  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1650 | loss: 0.69314 - binary_acc: 0.2744 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1651  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1651 | loss: 0.69314 - binary_acc: 0.2719 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1652  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1652 | loss: 0.69314 - binary_acc: 0.2697 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1653  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1653 | loss: 0.69315 - binary_acc: 0.2678 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1654  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1654 | loss: 0.69315 - binary_acc: 0.2660 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1655  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 1655 | loss: 0.69315 - binary_acc: 0.2644 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1656  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1656 | loss: 0.69315 - binary_acc: 0.2630 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1657  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1657 | loss: 0.69315 - binary_acc: 0.2867 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1658  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1658 | loss: 0.69315 - binary_acc: 0.2580 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1659  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1659 | loss: 0.69315 - binary_acc: 0.3072 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1660  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1660 | loss: 0.69315 - binary_acc: 0.3515 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1661  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1661 | loss: 0.69315 - binary_acc: 0.3913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1662  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1662 | loss: 0.69315 - binary_acc: 0.4272 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1663  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1663 | loss: 0.69315 - binary_acc: 0.4595 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1664  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1664 | loss: 0.69315 - binary_acc: 0.4885 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1665  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1665 | loss: 0.69315 - binary_acc: 0.5147 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1666  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 1666 | loss: 0.69315 - binary_acc: 0.4882 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1667  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1667 | loss: 0.69315 - binary_acc: 0.5144 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1668  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1668 | loss: 0.69315 - binary_acc: 0.5379 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1669  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1669 | loss: 0.69315 - binary_acc: 0.5592 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1670  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1670 | loss: 0.69315 - binary_acc: 0.5782 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1671  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 1671 | loss: 0.69315 - binary_acc: 0.5954 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1672  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1672 | loss: 0.69315 - binary_acc: 0.6109 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1673  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.018s\n",
      "| SGD | epoch: 1673 | loss: 0.69315 - binary_acc: 0.6248 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1674  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1674 | loss: 0.69315 - binary_acc: 0.6373 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1675  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1675 | loss: 0.69315 - binary_acc: 0.6486 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1676  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1676 | loss: 0.69315 - binary_acc: 0.6587 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1677  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1677 | loss: 0.69315 - binary_acc: 0.6678 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1678  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1678 | loss: 0.69315 - binary_acc: 0.6761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1679  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1679 | loss: 0.69315 - binary_acc: 0.6835 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1680  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1680 | loss: 0.69315 - binary_acc: 0.6901 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1681  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1681 | loss: 0.69315 - binary_acc: 0.6961 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1682  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.016s\n",
      "| SGD | epoch: 1682 | loss: 0.69315 - binary_acc: 0.7015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1683  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1683 | loss: 0.69315 - binary_acc: 0.7063 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1684  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1684 | loss: 0.69315 - binary_acc: 0.7107 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1685  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1685 | loss: 0.69315 - binary_acc: 0.7146 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1686  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1686 | loss: 0.69315 - binary_acc: 0.7182 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1687  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1687 | loss: 0.69315 - binary_acc: 0.7214 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1688  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1688 | loss: 0.69315 - binary_acc: 0.7242 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1689  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1689 | loss: 0.69315 - binary_acc: 0.7268 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1690  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 1690 | loss: 0.69315 - binary_acc: 0.7291 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1691  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1691 | loss: 0.69315 - binary_acc: 0.7312 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1692  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1692 | loss: 0.69315 - binary_acc: 0.7331 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1693  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1693 | loss: 0.69315 - binary_acc: 0.7348 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1694  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1694 | loss: 0.69315 - binary_acc: 0.7363 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1695  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1695 | loss: 0.69315 - binary_acc: 0.7377 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1696  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1696 | loss: 0.69315 - binary_acc: 0.7389 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1697  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1697 | loss: 0.69315 - binary_acc: 0.7400 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1698  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1698 | loss: 0.69315 - binary_acc: 0.7410 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1699  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1699 | loss: 0.69315 - binary_acc: 0.7419 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1700  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1700 | loss: 0.69315 - binary_acc: 0.7427 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1701  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1701 | loss: 0.69315 - binary_acc: 0.7434 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1702  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1702 | loss: 0.69315 - binary_acc: 0.7441 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1703  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1703 | loss: 0.69315 - binary_acc: 0.7447 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1704  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1704 | loss: 0.69315 - binary_acc: 0.7452 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1705  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1705 | loss: 0.69315 - binary_acc: 0.7457 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1706  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1706 | loss: 0.69315 - binary_acc: 0.7461 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1707  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1707 | loss: 0.69315 - binary_acc: 0.7465 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1708  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1708 | loss: 0.69315 - binary_acc: 0.7469 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1709  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1709 | loss: 0.69315 - binary_acc: 0.7472 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1710  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1710 | loss: 0.69315 - binary_acc: 0.7475 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1711  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1711 | loss: 0.69315 - binary_acc: 0.7477 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1712  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1712 | loss: 0.69315 - binary_acc: 0.7479 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1713  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1713 | loss: 0.69315 - binary_acc: 0.7481 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1714  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1714 | loss: 0.69315 - binary_acc: 0.7483 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1715  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1715 | loss: 0.69315 - binary_acc: 0.7485 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1716  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1716 | loss: 0.69315 - binary_acc: 0.7487 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1717  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1717 | loss: 0.69315 - binary_acc: 0.7488 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1718  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1718 | loss: 0.69315 - binary_acc: 0.7489 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1719  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1719 | loss: 0.69315 - binary_acc: 0.7490 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1720  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1720 | loss: 0.69315 - binary_acc: 0.7491 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1721  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1721 | loss: 0.69315 - binary_acc: 0.7492 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1722  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1722 | loss: 0.69315 - binary_acc: 0.7493 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1723  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1723 | loss: 0.69315 - binary_acc: 0.7494 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1724  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1724 | loss: 0.69315 - binary_acc: 0.7494 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1725  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1725 | loss: 0.69315 - binary_acc: 0.7495 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1726  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1726 | loss: 0.69315 - binary_acc: 0.6995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1727  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1727 | loss: 0.69315 - binary_acc: 0.7046 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1728  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1728 | loss: 0.69315 - binary_acc: 0.7091 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1729  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1729 | loss: 0.69315 - binary_acc: 0.7132 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1730  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1730 | loss: 0.69315 - binary_acc: 0.7169 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1731  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1731 | loss: 0.69315 - binary_acc: 0.7202 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1732  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1732 | loss: 0.69315 - binary_acc: 0.6982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1733  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1733 | loss: 0.69315 - binary_acc: 0.6784 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1734  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1734 | loss: 0.69315 - binary_acc: 0.6605 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1735  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1735 | loss: 0.69315 - binary_acc: 0.6445 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1736  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1736 | loss: 0.69315 - binary_acc: 0.6300 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1737  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1737 | loss: 0.69315 - binary_acc: 0.6170 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1738  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1738 | loss: 0.69315 - binary_acc: 0.6053 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1739  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1739 | loss: 0.69315 - binary_acc: 0.5948 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1740  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1740 | loss: 0.69315 - binary_acc: 0.5853 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1741  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1741 | loss: 0.69315 - binary_acc: 0.5768 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1742  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1742 | loss: 0.69315 - binary_acc: 0.5691 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1743  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1743 | loss: 0.69315 - binary_acc: 0.5622 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1744  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1744 | loss: 0.69315 - binary_acc: 0.5560 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1745  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1745 | loss: 0.69315 - binary_acc: 0.5504 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1746  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1746 | loss: 0.69315 - binary_acc: 0.5453 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1747  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1747 | loss: 0.69315 - binary_acc: 0.5408 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1748  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1748 | loss: 0.69315 - binary_acc: 0.5367 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1749  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1749 | loss: 0.69315 - binary_acc: 0.5331 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1750  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1750 | loss: 0.69315 - binary_acc: 0.5297 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1751  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1751 | loss: 0.69315 - binary_acc: 0.5268 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1752  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1752 | loss: 0.69315 - binary_acc: 0.5241 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1753  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1753 | loss: 0.69315 - binary_acc: 0.5217 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1754  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1754 | loss: 0.69315 - binary_acc: 0.5195 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1755  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1755 | loss: 0.69315 - binary_acc: 0.5176 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1756  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1756 | loss: 0.69315 - binary_acc: 0.5158 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1757  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1757 | loss: 0.69315 - binary_acc: 0.5142 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1758  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1758 | loss: 0.69315 - binary_acc: 0.5128 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1759  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1759 | loss: 0.69315 - binary_acc: 0.5115 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1760  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1760 | loss: 0.69315 - binary_acc: 0.5104 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1761  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1761 | loss: 0.69315 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1762  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1762 | loss: 0.69315 - binary_acc: 0.5084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1763  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1763 | loss: 0.69315 - binary_acc: 0.5076 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1764  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1764 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1765  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1765 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1766  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1766 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1767  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1767 | loss: 0.69315 - binary_acc: 0.5050 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1768  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1768 | loss: 0.69315 - binary_acc: 0.5045 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1769  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1769 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1770  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1770 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1771  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1771 | loss: 0.69315 - binary_acc: 0.5033 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1772  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1772 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1773  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1773 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1774  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1774 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1775  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1775 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1776  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1776 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1777  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1777 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1778  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1778 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1779  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1779 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1780  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1780 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1781  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1781 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1782  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1782 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1783  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1783 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1784  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1784 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1785  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1785 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1786  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1786 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1787  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1787 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1788  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1788 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1789  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1789 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1790  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1790 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1791  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1791 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1792  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1792 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1793  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 1793 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1794  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1794 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1795  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1795 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1796  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1796 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1797  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1797 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1798  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1798 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1799  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1799 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1800  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1800 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1801  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1801 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1802  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1802 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1803  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1803 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1804  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1804 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1805  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1805 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1806  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1806 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1807  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1807 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1808  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1808 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1809  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1809 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1810  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1810 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1811  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1811 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1812  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1812 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1813  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1813 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1814  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1814 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1815  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1815 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1816  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1816 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1817  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1817 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1818  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1818 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1819  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1819 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1820  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1820 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1821  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1821 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1822  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1822 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1823  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1823 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1824  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1824 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1825  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1825 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1826  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1826 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1827  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1827 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1828  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1828 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1829  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1829 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1830  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1830 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1831  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1831 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1832  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1832 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1833  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1833 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1834  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1834 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1835  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1835 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1836  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1836 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1837  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1837 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1838  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1838 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1839  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1839 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1840  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1840 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1841  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1841 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1842  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1842 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1843  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1843 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1844  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1844 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1845  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1845 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1846  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1846 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1847  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1847 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1848  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1848 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1849  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1849 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1850  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1850 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1851  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1851 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1852  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1852 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1853  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1853 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1854  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1854 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1855  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1855 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1856  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1856 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1857  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1857 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1858  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1858 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1859  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1859 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1860  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1860 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1861  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1861 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1862  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1862 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1863  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1863 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1864  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1864 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1865  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1865 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1866  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1866 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1867  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1867 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1868  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1868 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1869  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1869 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1870  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1870 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1871  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1871 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1872  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1872 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1873  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1873 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1874  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1874 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1875  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1875 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1876  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1876 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1877  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1877 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1878  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1878 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1879  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1879 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1880  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1880 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1881  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1881 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1882  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1882 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1883  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1883 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1884  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1884 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1885  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1885 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1886  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1886 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1887  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1887 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1888  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1888 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1889  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1889 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1890  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1890 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1891  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1891 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1892  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1892 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1893  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1893 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1894  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1894 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1895  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1895 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1896  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1896 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1897  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1897 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1898  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1898 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1899  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1899 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1900  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1900 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1901  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1901 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1902  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1902 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1903  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1903 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1904  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1904 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1905  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1905 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1906  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1906 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1907  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1907 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1908  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1908 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1909  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1909 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1910  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1910 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1911  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1911 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1912  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.020s\n",
      "| SGD | epoch: 1912 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1913  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1913 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1914  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1914 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1915  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1915 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1916  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1916 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1917  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1917 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1918  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1918 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1919  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1919 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1920  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1920 | loss: 0.69314 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1921  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1921 | loss: 0.69314 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1922  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1922 | loss: 0.69314 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1923  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1923 | loss: 0.69314 - binary_acc: 0.5365 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1924  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1924 | loss: 0.69314 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1925  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1925 | loss: 0.69314 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1926  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1926 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1927  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1927 | loss: 0.69314 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1928  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1928 | loss: 0.69314 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1929  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1929 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1930  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1930 | loss: 0.69314 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1931  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1931 | loss: 0.69315 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1932  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1932 | loss: 0.69315 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1933  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1933 | loss: 0.69315 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1934  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1934 | loss: 0.69315 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1935  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1935 | loss: 0.69315 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1936  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1936 | loss: 0.69315 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1937  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1937 | loss: 0.69315 - binary_acc: 0.5083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1938  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1938 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1939  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1939 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1940  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1940 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1941  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1941 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1942  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1942 | loss: 0.69315 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1943  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1943 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1944  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1944 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1945  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1945 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1946  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1946 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1947  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1947 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1948  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1948 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1949  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1949 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1950  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1950 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1951  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1951 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1952  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1952 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1953  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1953 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1954  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1954 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1955  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1955 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1956  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1956 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1957  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1957 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1958  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1958 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1959  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1959 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1960  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1960 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1961  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1961 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1962  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1962 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1963  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1963 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1964  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 1964 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1965  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1965 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1966  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1966 | loss: 0.69314 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1967  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1967 | loss: 0.69314 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1968  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1968 | loss: 0.69314 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1969  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1969 | loss: 0.69314 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1970  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1970 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1971  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1971 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1972  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1972 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1973  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1973 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1974  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1974 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1975  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1975 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1976  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1976 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1977  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1977 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1978  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1978 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1979  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1979 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1980  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1980 | loss: 0.69314 - binary_acc: 0.5501 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1981  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1981 | loss: 0.69314 - binary_acc: 0.5451 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1982  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1982 | loss: 0.69314 - binary_acc: 0.5406 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1983  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1983 | loss: 0.69314 - binary_acc: 0.5365 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1984  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 1984 | loss: 0.69314 - binary_acc: 0.5329 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1985  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 1985 | loss: 0.69314 - binary_acc: 0.5296 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1986  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1986 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1987  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1987 | loss: 0.69314 - binary_acc: 0.5240 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1988  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 1988 | loss: 0.69314 - binary_acc: 0.5216 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1989  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 1989 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1990  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 1990 | loss: 0.69314 - binary_acc: 0.5175 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1991  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1991 | loss: 0.69314 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1992  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1992 | loss: 0.69315 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1993  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1993 | loss: 0.69315 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1994  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 1994 | loss: 0.69315 - binary_acc: 0.5115 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1995  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 1995 | loss: 0.69315 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1996  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 1996 | loss: 0.69315 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1997  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 1997 | loss: 0.69315 - binary_acc: 0.5084 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1998  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 1998 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 1999  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 1999 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2000  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2000 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2001  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2001 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2002  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2002 | loss: 0.69315 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2003  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2003 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2004  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2004 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2005  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2005 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2006  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2006 | loss: 0.69315 - binary_acc: 0.5032 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2007  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2007 | loss: 0.69315 - binary_acc: 0.5029 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2008  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2008 | loss: 0.69315 - binary_acc: 0.5026 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2009  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2009 | loss: 0.69315 - binary_acc: 0.5024 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2010  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2010 | loss: 0.69315 - binary_acc: 0.5021 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2011  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2011 | loss: 0.69315 - binary_acc: 0.5019 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2012  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2012 | loss: 0.69315 - binary_acc: 0.5017 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2013  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2013 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2014  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2014 | loss: 0.69315 - binary_acc: 0.5014 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2015  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2015 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2016  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2016 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2017  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2017 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2018  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2018 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2019  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2019 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2020  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2020 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2021  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2021 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2022  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2022 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2023  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2023 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2024  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2024 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2025  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2025 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2026  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2026 | loss: 0.69316 - binary_acc: 0.4504 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2027  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2027 | loss: 0.69316 - binary_acc: 0.4554 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2028  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2028 | loss: 0.69316 - binary_acc: 0.4598 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2029  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2029 | loss: 0.69316 - binary_acc: 0.4638 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2030  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2030 | loss: 0.69315 - binary_acc: 0.4675 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2031  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2031 | loss: 0.69315 - binary_acc: 0.4707 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2032  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2032 | loss: 0.69315 - binary_acc: 0.4736 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2033  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2033 | loss: 0.69315 - binary_acc: 0.4763 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2034  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2034 | loss: 0.69315 - binary_acc: 0.4786 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2035  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2035 | loss: 0.69315 - binary_acc: 0.4808 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2036  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2036 | loss: 0.69315 - binary_acc: 0.4827 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2037  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2037 | loss: 0.69315 - binary_acc: 0.4844 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2038  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2038 | loss: 0.69315 - binary_acc: 0.4860 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2039  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2039 | loss: 0.69315 - binary_acc: 0.4874 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2040  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2040 | loss: 0.69315 - binary_acc: 0.4887 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2041  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2041 | loss: 0.69315 - binary_acc: 0.4898 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2042  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2042 | loss: 0.69315 - binary_acc: 0.4908 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2043  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2043 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2044  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2044 | loss: 0.69315 - binary_acc: 0.4926 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2045  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2045 | loss: 0.69315 - binary_acc: 0.4933 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2046  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2046 | loss: 0.69315 - binary_acc: 0.4940 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2047  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2047 | loss: 0.69315 - binary_acc: 0.4946 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2048  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2048 | loss: 0.69315 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2049  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2049 | loss: 0.69315 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2050  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2050 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2051  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2051 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2052  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2052 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2053  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2053 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2054  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2054 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2055  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2055 | loss: 0.69315 - binary_acc: 0.4977 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2056  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2056 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2057  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2057 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2058  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2058 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2059  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2059 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2060  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2060 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2061  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2061 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2062  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2062 | loss: 0.69315 - binary_acc: 0.4489 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2063  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2063 | loss: 0.69315 - binary_acc: 0.4540 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2064  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2064 | loss: 0.69315 - binary_acc: 0.4586 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2065  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2065 | loss: 0.69315 - binary_acc: 0.4627 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2066  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2066 | loss: 0.69315 - binary_acc: 0.4665 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2067  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2067 | loss: 0.69315 - binary_acc: 0.4698 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2068  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2068 | loss: 0.69315 - binary_acc: 0.4728 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2069  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2069 | loss: 0.69315 - binary_acc: 0.4756 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2070  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2070 | loss: 0.69315 - binary_acc: 0.4780 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2071  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2071 | loss: 0.69315 - binary_acc: 0.4802 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2072  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2072 | loss: 0.69315 - binary_acc: 0.4822 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2073  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2073 | loss: 0.69315 - binary_acc: 0.4840 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2074  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2074 | loss: 0.69315 - binary_acc: 0.4856 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2075  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2075 | loss: 0.69315 - binary_acc: 0.4870 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2076  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2076 | loss: 0.69315 - binary_acc: 0.4883 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2077  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2077 | loss: 0.69315 - binary_acc: 0.4895 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2078  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2078 | loss: 0.69315 - binary_acc: 0.4905 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2079  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2079 | loss: 0.69315 - binary_acc: 0.4915 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2080  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2080 | loss: 0.69315 - binary_acc: 0.4923 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2081  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2081 | loss: 0.69315 - binary_acc: 0.4931 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2082  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2082 | loss: 0.69315 - binary_acc: 0.4938 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2083  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2083 | loss: 0.69315 - binary_acc: 0.4944 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2084  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2084 | loss: 0.69315 - binary_acc: 0.4950 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2085  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2085 | loss: 0.69315 - binary_acc: 0.4955 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2086  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2086 | loss: 0.69315 - binary_acc: 0.4959 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2087  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2087 | loss: 0.69315 - binary_acc: 0.4963 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2088  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2088 | loss: 0.69315 - binary_acc: 0.4967 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2089  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2089 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2090  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2090 | loss: 0.69314 - binary_acc: 0.5473 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2091  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2091 | loss: 0.69314 - binary_acc: 0.5426 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2092  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2092 | loss: 0.69314 - binary_acc: 0.5383 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2093  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2093 | loss: 0.69314 - binary_acc: 0.5345 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2094  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2094 | loss: 0.69314 - binary_acc: 0.5310 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2095  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2095 | loss: 0.69314 - binary_acc: 0.5279 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2096  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2096 | loss: 0.69314 - binary_acc: 0.5252 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2097  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2097 | loss: 0.69314 - binary_acc: 0.5226 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2098  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2098 | loss: 0.69314 - binary_acc: 0.5204 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2099  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2099 | loss: 0.69314 - binary_acc: 0.5183 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2100  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2100 | loss: 0.69315 - binary_acc: 0.5165 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2101  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2101 | loss: 0.69315 - binary_acc: 0.5149 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2102  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2102 | loss: 0.69315 - binary_acc: 0.5134 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2103  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2103 | loss: 0.69315 - binary_acc: 0.5120 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2104  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2104 | loss: 0.69315 - binary_acc: 0.5108 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2105  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2105 | loss: 0.69315 - binary_acc: 0.5097 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2106  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2106 | loss: 0.69315 - binary_acc: 0.5088 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2107  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2107 | loss: 0.69315 - binary_acc: 0.5079 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2108  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2108 | loss: 0.69315 - binary_acc: 0.5071 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2109  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2109 | loss: 0.69315 - binary_acc: 0.5064 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2110  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2110 | loss: 0.69315 - binary_acc: 0.5058 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2111  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2111 | loss: 0.69315 - binary_acc: 0.5052 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2112  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2112 | loss: 0.69315 - binary_acc: 0.5047 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2113  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2113 | loss: 0.69315 - binary_acc: 0.5042 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2114  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2114 | loss: 0.69315 - binary_acc: 0.5038 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2115  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2115 | loss: 0.69315 - binary_acc: 0.5034 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2116  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2116 | loss: 0.69315 - binary_acc: 0.5031 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2117  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2117 | loss: 0.69315 - binary_acc: 0.5028 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2118  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.016s\n",
      "| SGD | epoch: 2118 | loss: 0.69315 - binary_acc: 0.5025 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2119  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2119 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2120  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2120 | loss: 0.69314 - binary_acc: 0.5520 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2121  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2121 | loss: 0.69314 - binary_acc: 0.5468 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2122  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2122 | loss: 0.69313 - binary_acc: 0.5921 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2123  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2123 | loss: 0.69313 - binary_acc: 0.5829 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2124  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2124 | loss: 0.69314 - binary_acc: 0.5746 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2125  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2125 | loss: 0.69314 - binary_acc: 0.5672 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2126  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2126 | loss: 0.69314 - binary_acc: 0.5604 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2127  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2127 | loss: 0.69314 - binary_acc: 0.5544 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2128  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2128 | loss: 0.69313 - binary_acc: 0.5990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2129  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2129 | loss: 0.69313 - binary_acc: 0.5891 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2130  | total loss: \u001b[1m\u001b[32m0.69313\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2130 | loss: 0.69313 - binary_acc: 0.5802 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2131  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2131 | loss: 0.69314 - binary_acc: 0.5721 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2132  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2132 | loss: 0.69314 - binary_acc: 0.5649 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2133  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2133 | loss: 0.69314 - binary_acc: 0.5584 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2134  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2134 | loss: 0.69314 - binary_acc: 0.5526 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2135  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2135 | loss: 0.69314 - binary_acc: 0.5473 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2136  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2136 | loss: 0.69314 - binary_acc: 0.5426 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2137  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2137 | loss: 0.69314 - binary_acc: 0.5383 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2138  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2138 | loss: 0.69314 - binary_acc: 0.5345 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2139  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2139 | loss: 0.69314 - binary_acc: 0.5311 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2140  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2140 | loss: 0.69314 - binary_acc: 0.5279 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2141  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2141 | loss: 0.69314 - binary_acc: 0.5252 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2142  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2142 | loss: 0.69314 - binary_acc: 0.5226 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2143  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2143 | loss: 0.69314 - binary_acc: 0.5204 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2144  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2144 | loss: 0.69314 - binary_acc: 0.5183 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2145  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2145 | loss: 0.69314 - binary_acc: 0.5165 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2146  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2146 | loss: 0.69314 - binary_acc: 0.5149 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2147  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2147 | loss: 0.69315 - binary_acc: 0.5134 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2148  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2148 | loss: 0.69315 - binary_acc: 0.5120 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2149  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2149 | loss: 0.69315 - binary_acc: 0.5108 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2150  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2150 | loss: 0.69315 - binary_acc: 0.5097 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2151  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.015s\n",
      "| SGD | epoch: 2151 | loss: 0.69315 - binary_acc: 0.5088 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2152  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2152 | loss: 0.69315 - binary_acc: 0.5079 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2153  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2153 | loss: 0.69315 - binary_acc: 0.5071 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2154  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2154 | loss: 0.69315 - binary_acc: 0.5064 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2155  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2155 | loss: 0.69315 - binary_acc: 0.5058 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2156  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2156 | loss: 0.69315 - binary_acc: 0.5052 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2157  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2157 | loss: 0.69315 - binary_acc: 0.5047 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2158  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2158 | loss: 0.69315 - binary_acc: 0.5042 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2159  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2159 | loss: 0.69315 - binary_acc: 0.5038 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2160  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2160 | loss: 0.69315 - binary_acc: 0.5034 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2161  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2161 | loss: 0.69315 - binary_acc: 0.5031 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2162  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2162 | loss: 0.69315 - binary_acc: 0.5028 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2163  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2163 | loss: 0.69315 - binary_acc: 0.5025 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2164  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2164 | loss: 0.69315 - binary_acc: 0.5022 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2165  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2165 | loss: 0.69315 - binary_acc: 0.5020 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2166  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2166 | loss: 0.69315 - binary_acc: 0.5018 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2167  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2167 | loss: 0.69315 - binary_acc: 0.5016 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2168  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2168 | loss: 0.69315 - binary_acc: 0.5015 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2169  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2169 | loss: 0.69315 - binary_acc: 0.5013 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2170  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2170 | loss: 0.69315 - binary_acc: 0.5012 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2171  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2171 | loss: 0.69315 - binary_acc: 0.5011 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2172  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2172 | loss: 0.69315 - binary_acc: 0.5010 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2173  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2173 | loss: 0.69315 - binary_acc: 0.5009 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2174  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2174 | loss: 0.69315 - binary_acc: 0.5008 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2175  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2175 | loss: 0.69315 - binary_acc: 0.5007 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2176  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2176 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2177  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2177 | loss: 0.69315 - binary_acc: 0.5006 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2178  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2178 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2179  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2179 | loss: 0.69315 - binary_acc: 0.5005 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2180  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2180 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2181  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2181 | loss: 0.69315 - binary_acc: 0.5004 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2182  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2182 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2183  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2183 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2184  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2184 | loss: 0.69315 - binary_acc: 0.5003 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2185  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2185 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2186  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2186 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2187  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2187 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2188  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2188 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2189  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2189 | loss: 0.69315 - binary_acc: 0.5002 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2190  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2190 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2191  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2191 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2192  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2192 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2193  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2193 | loss: 0.69315 - binary_acc: 0.5001 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2194  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2194 | loss: 0.69316 - binary_acc: 0.4501 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2195  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2195 | loss: 0.69315 - binary_acc: 0.4551 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2196  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2196 | loss: 0.69315 - binary_acc: 0.4596 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2197  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2197 | loss: 0.69315 - binary_acc: 0.4636 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2198  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2198 | loss: 0.69315 - binary_acc: 0.4673 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2199  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2199 | loss: 0.69315 - binary_acc: 0.4705 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2200  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2200 | loss: 0.69315 - binary_acc: 0.4735 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2201  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2201 | loss: 0.69315 - binary_acc: 0.4761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2202  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2202 | loss: 0.69315 - binary_acc: 0.4785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2203  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2203 | loss: 0.69315 - binary_acc: 0.4807 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2204  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2204 | loss: 0.69315 - binary_acc: 0.4826 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2205  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2205 | loss: 0.69315 - binary_acc: 0.4843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2206  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.017s\n",
      "| SGD | epoch: 2206 | loss: 0.69315 - binary_acc: 0.4859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2207  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2207 | loss: 0.69315 - binary_acc: 0.4873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2208  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2208 | loss: 0.69315 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2209  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2209 | loss: 0.69315 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2210  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2210 | loss: 0.69315 - binary_acc: 0.4908 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2211  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2211 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2212  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2212 | loss: 0.69315 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2213  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2213 | loss: 0.69315 - binary_acc: 0.4933 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2214  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2214 | loss: 0.69315 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2215  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2215 | loss: 0.69315 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2216  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2216 | loss: 0.69315 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2217  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2217 | loss: 0.69315 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2218  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2218 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2219  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2219 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2220  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2220 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2221  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2221 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2222  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2222 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2223  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2223 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2224  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2224 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2225  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2225 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2226  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2226 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2227  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2227 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2228  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2228 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2229  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2229 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2230  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2230 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2231  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2231 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2232  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2232 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2233  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2233 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2234  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2234 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2235  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2235 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2236  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2236 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2237  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2237 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2238  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2238 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2239  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2239 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2240  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.015s\n",
      "| SGD | epoch: 2240 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2241  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2241 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2242  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2242 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2243  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2243 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2244  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2244 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2245  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2245 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2246  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2246 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2247  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2247 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2248  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2248 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2249  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2249 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2250  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2250 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2251  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2251 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2252  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2252 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2253  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2253 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2254  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2254 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2255  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2255 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2256  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.016s\n",
      "| SGD | epoch: 2256 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2257  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2257 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2258  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2258 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2259  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2259 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2260  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2260 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2261  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2261 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2262  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2262 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2263  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2263 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2264  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2264 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2265  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2265 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2266  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2266 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2267  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2267 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2268  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2268 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2269  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2269 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2270  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2270 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2271  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2271 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2272  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2272 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2273  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2273 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2274  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2274 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2275  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2275 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2276  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2276 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2277  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2277 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2278  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2278 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2279  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2279 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2280  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2280 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2281  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2281 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2282  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2282 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2283  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2283 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2284  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2284 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2285  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2285 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2286  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2286 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2287  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2287 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2288  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2288 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2289  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2289 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2290  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2290 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2291  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2291 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2292  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2292 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2293  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2293 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2294  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2294 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2295  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2295 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2296  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2296 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2297  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2297 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2298  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2298 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2299  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2299 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2300  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2300 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2301  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2301 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2302  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2302 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2303  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2303 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2304  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2304 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2305  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2305 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2306  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2306 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2307  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2307 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2308  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2308 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2309  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2309 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2310  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2310 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2311  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2311 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2312  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2312 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2313  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2313 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2314  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2314 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2315  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2315 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2316  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2316 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2317  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2317 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2318  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2318 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2319  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2319 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2320  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2320 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2321  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2321 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2322  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2322 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2323  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2323 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2324  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2324 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2325  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2325 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2326  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2326 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2327  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2327 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2328  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2328 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2329  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2329 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2330  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2330 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2331  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2331 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2332  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2332 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2333  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2333 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2334  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2334 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2335  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2335 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2336  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2336 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2337  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2337 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2338  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2338 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2339  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2339 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2340  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2340 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2341  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2341 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2342  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2342 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2343  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2343 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2344  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2344 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2345  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2345 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2346  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2346 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2347  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2347 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2348  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2348 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2349  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2349 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2350  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2350 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2351  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2351 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2352  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2352 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2353  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2353 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2354  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2354 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2355  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2355 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2356  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2356 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2357  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2357 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2358  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2358 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2359  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2359 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2360  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2360 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2361  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2361 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2362  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2362 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2363  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2363 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2364  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2364 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2365  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2365 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2366  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2366 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2367  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2367 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2368  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2368 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2369  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2369 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2370  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2370 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2371  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2371 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2372  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2372 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2373  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2373 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2374  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2374 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2375  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2375 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2376  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2376 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2377  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2377 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2378  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2378 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2379  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2379 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2380  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2380 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2381  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2381 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2382  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2382 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2383  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2383 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2384  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2384 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2385  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2385 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2386  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2386 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2387  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2387 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2388  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2388 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2389  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2389 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2390  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2390 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2391  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2391 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2392  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2392 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2393  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2393 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2394  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2394 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2395  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2395 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2396  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2396 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2397  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2397 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2398  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2398 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2399  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2399 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2400  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2400 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2401  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2401 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2402  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2402 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2403  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2403 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2404  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2404 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2405  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2405 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2406  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2406 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2407  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2407 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2408  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2408 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2409  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2409 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2410  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2410 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2411  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2411 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2412  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2412 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2413  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2413 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2414  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2414 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2415  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2415 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2416  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2416 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2417  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2417 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2418  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2418 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2419  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2419 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2420  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2420 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2421  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2421 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2422  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2422 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2423  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2423 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2424  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2424 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2425  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2425 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2426  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2426 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2427  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2427 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2428  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2428 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2429  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2429 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2430  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2430 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2431  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2431 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2432  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2432 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2433  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2433 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2434  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2434 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2435  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2435 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2436  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2436 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2437  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2437 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2438  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2438 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2439  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2439 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2440  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2440 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2441  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2441 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2442  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2442 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2443  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2443 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2444  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2444 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2445  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2445 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2446  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2446 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2447  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2447 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2448  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2448 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2449  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2449 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2450  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2450 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2451  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2451 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2452  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2452 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2453  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2453 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2454  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2454 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2455  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2455 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2456  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2456 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2457  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2457 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2458  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2458 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2459  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2459 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2460  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2460 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2461  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2461 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2462  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2462 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2463  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2463 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2464  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2464 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2465  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2465 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2466  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2466 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2467  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2467 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2468  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2468 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2469  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2469 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2470  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2470 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2471  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2471 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2472  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2472 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2473  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2473 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2474  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2474 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2475  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2475 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2476  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2476 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2477  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2477 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2478  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2478 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2479  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2479 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2480  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2480 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2481  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2481 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2482  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2482 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2483  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2483 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2484  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2484 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2485  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2485 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2486  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2486 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2487  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2487 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2488  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2488 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2489  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2489 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2490  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2490 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2491  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2491 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2492  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2492 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2493  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2493 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2494  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2494 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2495  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2495 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2496  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2496 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2497  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2497 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2498  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2498 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2499  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2499 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2500  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2500 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2501  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2501 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2502  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2502 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2503  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2503 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2504  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2504 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2505  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2505 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2506  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2506 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2507  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2507 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2508  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2508 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2509  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2509 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2510  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2510 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2511  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2511 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2512  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2512 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2513  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2513 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2514  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2514 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2515  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2515 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2516  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2516 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2517  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2517 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2518  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2518 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2519  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2519 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2520  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2520 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2521  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2521 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2522  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2522 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2523  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2523 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2524  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2524 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2525  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2525 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2526  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2526 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2527  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2527 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2528  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2528 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2529  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2529 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2530  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2530 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2531  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2531 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2532  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2532 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2533  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2533 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2534  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2534 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2535  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2535 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2536  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2536 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2537  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2537 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2538  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2538 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2539  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2539 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2540  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2540 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2541  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2541 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2542  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2542 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2543  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2543 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2544  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2544 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2545  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2545 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2546  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2546 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2547  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2547 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2548  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2548 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2549  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2549 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2550  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2550 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2551  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2551 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2552  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2552 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2553  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2553 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2554  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2554 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2555  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2555 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2556  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2556 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2557  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2557 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2558  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2558 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2559  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2559 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2560  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2560 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2561  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2561 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2562  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2562 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2563  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2563 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2564  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2564 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2565  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2565 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2566  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2566 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2567  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2567 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2568  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2568 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2569  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2569 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2570  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2570 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2571  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2571 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2572  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2572 | loss: 0.69316 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2573  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2573 | loss: 0.69315 - binary_acc: 0.4550 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2574  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2574 | loss: 0.69315 - binary_acc: 0.4595 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2575  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2575 | loss: 0.69315 - binary_acc: 0.4635 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2576  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2576 | loss: 0.69315 - binary_acc: 0.4672 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2577  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2577 | loss: 0.69315 - binary_acc: 0.4705 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2578  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2578 | loss: 0.69315 - binary_acc: 0.4734 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2579  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2579 | loss: 0.69315 - binary_acc: 0.4761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2580  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2580 | loss: 0.69315 - binary_acc: 0.4785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2581  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2581 | loss: 0.69315 - binary_acc: 0.4806 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2582  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2582 | loss: 0.69315 - binary_acc: 0.4826 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2583  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2583 | loss: 0.69315 - binary_acc: 0.4843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2584  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2584 | loss: 0.69315 - binary_acc: 0.4859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2585  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2585 | loss: 0.69315 - binary_acc: 0.4873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2586  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2586 | loss: 0.69315 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2587  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2587 | loss: 0.69315 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2588  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2588 | loss: 0.69315 - binary_acc: 0.4907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2589  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2589 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2590  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2590 | loss: 0.69315 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2591  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2591 | loss: 0.69315 - binary_acc: 0.4932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2592  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2592 | loss: 0.69315 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2593  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2593 | loss: 0.69315 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2594  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2594 | loss: 0.69315 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2595  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2595 | loss: 0.69315 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2596  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2596 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2597  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2597 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2598  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2598 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2599  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2599 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2600  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2600 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2601  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2601 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2602  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2602 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2603  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2603 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2604  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2604 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2605  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2605 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2606  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2606 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2607  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2607 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2608  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2608 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2609  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2609 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2610  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2610 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2611  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2611 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2612  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2612 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2613  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2613 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2614  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2614 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2615  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2615 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2616  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2616 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2617  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2617 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2618  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2618 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2619  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2619 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2620  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2620 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2621  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2621 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2622  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2622 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2623  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2623 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2624  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2624 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2625  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2625 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2626  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2626 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2627  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2627 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2628  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2628 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2629  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2629 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2630  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2630 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2631  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2631 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2632  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2632 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2633  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2633 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2634  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2634 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2635  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2635 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2636  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2636 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2637  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2637 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2638  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2638 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2639  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2639 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2640  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2640 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2641  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2641 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2642  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2642 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2643  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2643 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2644  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2644 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2645  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2645 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2646  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2646 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2647  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2647 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2648  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2648 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2649  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2649 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2650  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2650 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2651  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2651 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2652  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2652 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2653  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2653 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2654  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2654 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2655  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2655 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2656  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2656 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2657  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2657 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2658  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2658 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2659  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2659 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2660  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2660 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2661  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2661 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2662  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2662 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2663  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2663 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2664  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2664 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2665  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2665 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2666  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2666 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2667  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2667 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2668  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2668 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2669  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2669 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2670  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2670 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2671  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2671 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2672  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2672 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2673  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2673 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2674  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2674 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2675  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2675 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2676  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2676 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2677  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2677 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2678  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2678 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2679  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2679 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2680  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2680 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2681  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2681 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2682  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2682 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2683  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2683 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2684  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2684 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2685  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2685 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2686  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2686 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2687  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2687 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2688  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2688 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2689  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2689 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2690  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2690 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2691  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2691 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2692  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2692 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2693  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2693 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2694  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2694 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2695  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2695 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2696  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2696 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2697  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2697 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2698  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2698 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2699  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2699 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2700  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2700 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2701  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2701 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2702  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2702 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2703  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2703 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2704  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2704 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2705  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2705 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2706  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2706 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2707  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2707 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2708  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2708 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2709  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2709 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2710  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2710 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2711  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2711 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2712  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2712 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2713  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2713 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2714  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2714 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2715  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2715 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2716  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2716 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2717  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2717 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2718  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2718 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2719  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2719 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2720  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2720 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2721  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2721 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2722  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2722 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2723  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2723 | loss: 0.69314 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2724  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2724 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2725  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2725 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2726  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2726 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2727  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2727 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2728  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2728 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2729  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2729 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2730  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2730 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2731  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2731 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2732  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2732 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2733  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2733 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2734  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2734 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2735  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2735 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2736  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2736 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2737  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2737 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2738  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2738 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2739  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2739 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2740  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2740 | loss: 0.69314 - binary_acc: 0.5500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2741  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2741 | loss: 0.69314 - binary_acc: 0.5450 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2742  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2742 | loss: 0.69314 - binary_acc: 0.5405 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2743  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2743 | loss: 0.69314 - binary_acc: 0.5364 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2744  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2744 | loss: 0.69314 - binary_acc: 0.5328 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2745  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2745 | loss: 0.69314 - binary_acc: 0.5295 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2746  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2746 | loss: 0.69314 - binary_acc: 0.5266 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2747  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2747 | loss: 0.69314 - binary_acc: 0.5239 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2748  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2748 | loss: 0.69314 - binary_acc: 0.5215 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2749  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2749 | loss: 0.69314 - binary_acc: 0.5194 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2750  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2750 | loss: 0.69314 - binary_acc: 0.5174 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2751  | total loss: \u001b[1m\u001b[32m0.69314\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2751 | loss: 0.69314 - binary_acc: 0.5157 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2752  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2752 | loss: 0.69315 - binary_acc: 0.5141 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2753  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2753 | loss: 0.69315 - binary_acc: 0.5127 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2754  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2754 | loss: 0.69315 - binary_acc: 0.5114 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2755  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2755 | loss: 0.69315 - binary_acc: 0.5103 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2756  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2756 | loss: 0.69315 - binary_acc: 0.5093 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2757  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2757 | loss: 0.69315 - binary_acc: 0.5083 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2758  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2758 | loss: 0.69315 - binary_acc: 0.5075 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2759  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2759 | loss: 0.69315 - binary_acc: 0.5068 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2760  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2760 | loss: 0.69315 - binary_acc: 0.5061 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2761  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2761 | loss: 0.69315 - binary_acc: 0.5055 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2762  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2762 | loss: 0.69315 - binary_acc: 0.5049 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2763  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2763 | loss: 0.69315 - binary_acc: 0.5044 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2764  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2764 | loss: 0.69315 - binary_acc: 0.5040 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2765  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2765 | loss: 0.69315 - binary_acc: 0.5036 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2766  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2766 | loss: 0.69316 - binary_acc: 0.4532 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2767  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2767 | loss: 0.69316 - binary_acc: 0.4579 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2768  | total loss: \u001b[1m\u001b[32m0.69316\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2768 | loss: 0.69316 - binary_acc: 0.4621 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2769  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.016s\n",
      "| SGD | epoch: 2769 | loss: 0.69315 - binary_acc: 0.4659 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2770  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2770 | loss: 0.69315 - binary_acc: 0.4693 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2771  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2771 | loss: 0.69315 - binary_acc: 0.4724 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2772  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2772 | loss: 0.69315 - binary_acc: 0.4751 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2773  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2773 | loss: 0.69315 - binary_acc: 0.4776 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2774  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2774 | loss: 0.69315 - binary_acc: 0.4799 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2775  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2775 | loss: 0.69315 - binary_acc: 0.4819 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2776  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2776 | loss: 0.69315 - binary_acc: 0.4837 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2777  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2777 | loss: 0.69315 - binary_acc: 0.4853 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2778  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2778 | loss: 0.69315 - binary_acc: 0.4868 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2779  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2779 | loss: 0.69315 - binary_acc: 0.4881 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2780  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2780 | loss: 0.69315 - binary_acc: 0.4893 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2781  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2781 | loss: 0.69315 - binary_acc: 0.4904 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2782  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2782 | loss: 0.69315 - binary_acc: 0.4913 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2783  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2783 | loss: 0.69315 - binary_acc: 0.4922 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2784  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2784 | loss: 0.69315 - binary_acc: 0.4930 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2785  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2785 | loss: 0.69315 - binary_acc: 0.4937 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2786  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2786 | loss: 0.69315 - binary_acc: 0.4943 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2787  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2787 | loss: 0.69315 - binary_acc: 0.4949 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2788  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.016s\n",
      "| SGD | epoch: 2788 | loss: 0.69315 - binary_acc: 0.4954 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2789  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.018s\n",
      "| SGD | epoch: 2789 | loss: 0.69315 - binary_acc: 0.4959 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2790  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2790 | loss: 0.69315 - binary_acc: 0.4963 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2791  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.015s\n",
      "| SGD | epoch: 2791 | loss: 0.69315 - binary_acc: 0.4966 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2792  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2792 | loss: 0.69315 - binary_acc: 0.4970 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2793  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2793 | loss: 0.69315 - binary_acc: 0.4973 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2794  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2794 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2795  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2795 | loss: 0.69315 - binary_acc: 0.4978 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2796  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2796 | loss: 0.69315 - binary_acc: 0.4980 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2797  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2797 | loss: 0.69315 - binary_acc: 0.4982 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2798  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2798 | loss: 0.69315 - binary_acc: 0.4984 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2799  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2799 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2800  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2800 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2801  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2801 | loss: 0.69315 - binary_acc: 0.4988 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2802  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2802 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2803  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2803 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2804  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2804 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2805  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2805 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2806  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2806 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2807  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2807 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2808  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2808 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2809  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2809 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2810  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2810 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2811  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2811 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2812  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2812 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2813  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2813 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2814  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2814 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2815  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2815 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2816  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2816 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2817  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2817 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2818  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2818 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2819  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2819 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2820  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2820 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2821  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2821 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2822  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2822 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2823  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.002s\n",
      "| SGD | epoch: 2823 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2824  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2824 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2825  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2825 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2826  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2826 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2827  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2827 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2828  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2828 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2829  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2829 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2830  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2830 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2831  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2831 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2832  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2832 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2833  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2833 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2834  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2834 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2835  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2835 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2836  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2836 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2837  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2837 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2838  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2838 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2839  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2839 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2840  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2840 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2841  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2841 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2842  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2842 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2843  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2843 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2844  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2844 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2845  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2845 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2846  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2846 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2847  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2847 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2848  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2848 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2849  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2849 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2850  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2850 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2851  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2851 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2852  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2852 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2853  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2853 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2854  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2854 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2855  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2855 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2856  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2856 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2857  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2857 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2858  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2858 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2859  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2859 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2860  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2860 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2861  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2861 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2862  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2862 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2863  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m\n",
      "| SGD | epoch: 2863 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2864  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2864 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2865  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2865 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2866  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2866 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2867  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2867 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2868  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2868 | loss: 0.69315 - binary_acc: 0.4500 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2869  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2869 | loss: 0.69315 - binary_acc: 0.4550 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2870  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2870 | loss: 0.69315 - binary_acc: 0.4595 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2871  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2871 | loss: 0.69315 - binary_acc: 0.4635 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2872  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2872 | loss: 0.69315 - binary_acc: 0.4672 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2873  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2873 | loss: 0.69315 - binary_acc: 0.4705 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2874  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2874 | loss: 0.69315 - binary_acc: 0.4734 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2875  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2875 | loss: 0.69315 - binary_acc: 0.4761 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2876  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2876 | loss: 0.69315 - binary_acc: 0.4785 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2877  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2877 | loss: 0.69315 - binary_acc: 0.4806 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2878  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2878 | loss: 0.69315 - binary_acc: 0.4826 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2879  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2879 | loss: 0.69315 - binary_acc: 0.4843 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2880  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2880 | loss: 0.69315 - binary_acc: 0.4859 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2881  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2881 | loss: 0.69315 - binary_acc: 0.4873 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2882  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2882 | loss: 0.69315 - binary_acc: 0.4886 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2883  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2883 | loss: 0.69315 - binary_acc: 0.4897 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2884  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2884 | loss: 0.69315 - binary_acc: 0.4907 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2885  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2885 | loss: 0.69315 - binary_acc: 0.4917 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2886  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2886 | loss: 0.69315 - binary_acc: 0.4925 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2887  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.015s\n",
      "| SGD | epoch: 2887 | loss: 0.69315 - binary_acc: 0.4932 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2888  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2888 | loss: 0.69315 - binary_acc: 0.4939 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2889  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2889 | loss: 0.69315 - binary_acc: 0.4945 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2890  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2890 | loss: 0.69315 - binary_acc: 0.4951 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2891  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2891 | loss: 0.69315 - binary_acc: 0.4956 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2892  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2892 | loss: 0.69315 - binary_acc: 0.4960 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2893  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2893 | loss: 0.69315 - binary_acc: 0.4964 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2894  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2894 | loss: 0.69315 - binary_acc: 0.4968 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2895  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2895 | loss: 0.69315 - binary_acc: 0.4971 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2896  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2896 | loss: 0.69315 - binary_acc: 0.4974 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2897  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2897 | loss: 0.69315 - binary_acc: 0.4976 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2898  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.003s\n",
      "| SGD | epoch: 2898 | loss: 0.69315 - binary_acc: 0.4979 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2899  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2899 | loss: 0.69315 - binary_acc: 0.4981 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2900  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2900 | loss: 0.69315 - binary_acc: 0.4983 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2901  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2901 | loss: 0.69315 - binary_acc: 0.4985 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2902  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2902 | loss: 0.69315 - binary_acc: 0.4986 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2903  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2903 | loss: 0.69315 - binary_acc: 0.4987 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2904  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2904 | loss: 0.69315 - binary_acc: 0.4989 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2905  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| SGD | epoch: 2905 | loss: 0.69315 - binary_acc: 0.4990 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2906  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2906 | loss: 0.69315 - binary_acc: 0.4991 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2907  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2907 | loss: 0.69315 - binary_acc: 0.4992 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2908  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2908 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2909  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2909 | loss: 0.69315 - binary_acc: 0.4993 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2910  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2910 | loss: 0.69315 - binary_acc: 0.4994 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2911  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2911 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2912  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2912 | loss: 0.69315 - binary_acc: 0.4995 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2913  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2913 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2914  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2914 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2915  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2915 | loss: 0.69315 - binary_acc: 0.4996 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2916  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2916 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2917  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2917 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2918  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2918 | loss: 0.69315 - binary_acc: 0.4997 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2919  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 2919 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2920  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2920 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2921  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2921 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2922  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2922 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2923  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2923 | loss: 0.69315 - binary_acc: 0.4998 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2924  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2924 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2925  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2925 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2926  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2926 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2927  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2927 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2928  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 2928 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2929  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2929 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2930  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.009s\n",
      "| SGD | epoch: 2930 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2931  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2931 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2932  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2932 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2933  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.019s\n",
      "| SGD | epoch: 2933 | loss: 0.69315 - binary_acc: 0.4999 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2934  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2934 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2935  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.014s\n",
      "| SGD | epoch: 2935 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2936  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.011s\n",
      "| SGD | epoch: 2936 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2937  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.012s\n",
      "| SGD | epoch: 2937 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2938  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.010s\n",
      "| SGD | epoch: 2938 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2939  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.018s\n",
      "| SGD | epoch: 2939 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2940  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.013s\n",
      "| SGD | epoch: 2940 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2941  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.006s\n",
      "| SGD | epoch: 2941 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2942  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2942 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2943  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2943 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2944  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2944 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2945  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2945 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2946  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.008s\n",
      "| SGD | epoch: 2946 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n",
      "Training Step: 2947  | total loss: \u001b[1m\u001b[32m0.69315\u001b[0m\u001b[0m | time: 0.007s\n",
      "| SGD | epoch: 2947 | loss: 0.69315 - binary_acc: 0.5000 -- iter: 4/4\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tflearn import DNN\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "#Training examples\n",
    "X = [[0,0], [0,1], [1,0], [1,1]]\n",
    "Y = [[0], [1], [1], [0]]\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    input_layer = input_data(shape=[None, 2]) #input layer of size 2\n",
    "    hidden_layer = fully_connected(input_layer , 2, activation='tanh') #hidden layer of size 2\n",
    "    output_layer = fully_connected(hidden_layer, 1, activation='tanh') #output layer of size 1\n",
    "\n",
    "    #use Stohastic Gradient Descent and Binary Crossentropy as loss function\n",
    "    r = regression(output_layer , optimizer='sgd', loss='binary_crossentropy', learning_rate=0.1)\n",
    "    model = DNN(r)\n",
    "\n",
    "#fit the model\n",
    "model.fit(X, Y, n_epoch=10000, show_metric=True);\n",
    "\n",
    "#predict all examples\n",
    "print ('Expected:  ', [i[0] > 0 for i in Y])\n",
    "print ('Predicted: ', [i[0] > 0 for i in model.predict(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "bakalarka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
