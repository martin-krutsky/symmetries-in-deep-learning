{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool, global_add_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle_array = np.array([[0, 1, 0, 2, 1, 2],\n",
    "                           [1, 0, 2, 0, 2, 1]])\n",
    "edge_index_triangle = torch.tensor(triangle_array, dtype=torch.long)\n",
    "x_triangle = torch.tensor([[1], [1], [1]], dtype=torch.float)\n",
    "data_triangle = Data(x=x_triangle, edge_index=edge_index_triangle)\n",
    "\n",
    "square_array = np.array([[0, 1, 0, 3, 1, 2, 2, 3],\n",
    "                         [1, 0, 3, 0, 2, 1, 3, 2]])\n",
    "edge_index_square = torch.tensor(square_array, dtype=torch.long)\n",
    "x_square = torch.tensor([[1], [1], [1], [1]], dtype=torch.float)\n",
    "data_square = Data(x=x_square, edge_index=edge_index_square)\n",
    "\n",
    "penta_array = np.array([[0, 1, 0, 4, 1, 2, 2, 3, 3, 4],\n",
    "                        [1, 0, 4, 0, 2, 1, 3, 2, 4, 3]])\n",
    "edge_index_penta = torch.tensor(penta_array, dtype=torch.long)\n",
    "x_penta = torch.tensor([[1], [1], [1], [1], [1]], dtype=torch.float)\n",
    "data_penta = Data(x=x_penta, edge_index=edge_index_penta)\n",
    "\n",
    "\n",
    "star4_array = np.array([[0, 1, 1, 2, 1, 3],\n",
    "                        [1, 0, 2, 1, 3, 1]])\n",
    "edge_index_star4 = torch.tensor(star4_array, dtype=torch.long)\n",
    "x_star4 = torch.tensor([[1], [1], [1], [1]], dtype=torch.float)\n",
    "data_star = Data(x=x_star4, edge_index=edge_index_star4)\n",
    "\n",
    "star5_array = np.array([[0, 1, 1, 2, 1, 3, 1, 4],\n",
    "                        [1, 0, 2, 1, 3, 1, 4, 1]])\n",
    "edge_index_star5 = torch.tensor(star4_array, dtype=torch.long)\n",
    "x_star5 = torch.tensor([[1], [1], [1], [1], [1]], dtype=torch.float)\n",
    "data_star5 = Data(x=x_star5, edge_index=edge_index_star5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_renamings(vertex_ls, graph_arr):\n",
    "    all_renamed = []\n",
    "    renames = itertools.permutations(vertex_ls)\n",
    "    for rename in renames:\n",
    "        renaming_dict = {i: j for i, j in zip(vertex_ls, rename)}\n",
    "        renamed = np.zeros(graph_arr.shape)\n",
    "        for i, row in enumerate(graph_arr):\n",
    "            renamed[i] = np.array([renaming_dict.get(number) for number in row])\n",
    "        all_renamed.append(renamed)\n",
    "    return all_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "24\n",
      "120\n",
      "24\n",
      "120\n",
      "length of dataset: 294\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "labels = []\n",
    "\n",
    "print(len(generate_renamings([0,1,2], triangle_array)))\n",
    "for renaming in generate_renamings([0,1,2], triangle_array):\n",
    "    edge_index_triangle = torch.tensor(renaming, dtype=torch.long)\n",
    "    data_triangle = Data(x=x_triangle, edge_index=edge_index_triangle, y=0)\n",
    "    dataset.append(data_triangle)\n",
    "    \n",
    "print(len(generate_renamings([0,1,2,3], square_array)))\n",
    "for renaming in generate_renamings([0,1,2,3], square_array):\n",
    "    edge_index_square = torch.tensor(renaming, dtype=torch.long)\n",
    "    data_square = Data(x=x_square, edge_index=edge_index_square, y=0)\n",
    "    dataset.append(data_square)\n",
    "\n",
    "print(len(generate_renamings([0,1,2,3,4], penta_array)))\n",
    "for renaming in generate_renamings([0,1,2,3,4], penta_array):\n",
    "    edge_index_penta = torch.tensor(renaming, dtype=torch.long)\n",
    "    data_penta = Data(x=x_penta, edge_index=edge_index_penta, y=0)\n",
    "    dataset.append(data_penta)    \n",
    "    \n",
    "print(len(generate_renamings([0,1,2,3], star4_array)))\n",
    "for renaming in generate_renamings([0,1,2,3], star4_array):\n",
    "    edge_index_star4 = torch.tensor(renaming, dtype=torch.long)\n",
    "    data_star4 = Data(x=x_star4, edge_index=edge_index_star4, y=0)\n",
    "    dataset.append(data_star4)\n",
    "\n",
    "print(len(generate_renamings([0,1,2,3,4], star5_array)))\n",
    "for renaming in generate_renamings([0,1,2,3,4], star5_array):\n",
    "    edge_index_star5 = torch.tensor(renaming, dtype=torch.long)\n",
    "    data_star5 = Data(x=x_star5, edge_index=edge_index_star5, y=1)\n",
    "    dataset.append(data_star5)\n",
    "\n",
    "print('length of dataset:', len(dataset))\n",
    "train_size = round(0.8*len(dataset))\n",
    "dataset = random.sample(dataset, len(dataset))\n",
    "# random.shuffle(dataset)\n",
    "\n",
    "train_data = dataset[:train_size]\n",
    "test_data = dataset[train_size:]\n",
    "# loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIN(\n",
      "  (conv1): GINConv(nn=Linear(in_features=1, out_features=64, bias=True))\n",
      "  (conv2): GINConv(nn=Linear(in_features=64, out_features=64, bias=True))\n",
      "  (conv3): GINConv(nn=Linear(in_features=64, out_features=64, bias=True))\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GIN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GINConv(Linear(1, hidden_channels))\n",
    "        self.conv2 = GINConv(Linear(hidden_channels, hidden_channels))\n",
    "        self.conv3 = GINConv(Linear(hidden_channels, hidden_channels))\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GIN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1974271535873413\n",
      "Epoch: 001, Train Acc: 0.6043, Test Acc: 0.5424\n",
      "0.7413402199745178\n",
      "Epoch: 002, Train Acc: 0.3957, Test Acc: 0.4576\n",
      "0.636299192905426\n",
      "Epoch: 003, Train Acc: 0.6043, Test Acc: 0.5424\n",
      "0.6534236669540405\n",
      "Epoch: 004, Train Acc: 0.6043, Test Acc: 0.5424\n",
      "0.6590278148651123\n",
      "Epoch: 005, Train Acc: 0.6043, Test Acc: 0.5424\n",
      "0.6384422183036804\n",
      "Epoch: 006, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.6053441166877747\n",
      "Epoch: 007, Train Acc: 0.6043, Test Acc: 0.5424\n",
      "0.6027304530143738\n",
      "Epoch: 008, Train Acc: 0.6043, Test Acc: 0.5424\n",
      "0.43549609184265137\n",
      "Epoch: 009, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.44496798515319824\n",
      "Epoch: 010, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.3796491324901581\n",
      "Epoch: 011, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.3043319880962372\n",
      "Epoch: 012, Train Acc: 0.9191, Test Acc: 0.9153\n",
      "0.2521142363548279\n",
      "Epoch: 013, Train Acc: 0.9191, Test Acc: 0.9153\n",
      "0.1712341010570526\n",
      "Epoch: 014, Train Acc: 0.9191, Test Acc: 0.9153\n",
      "0.16135990619659424\n",
      "Epoch: 015, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.16315583884716034\n",
      "Epoch: 016, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.12183593213558197\n",
      "Epoch: 017, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.07620885968208313\n",
      "Epoch: 018, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.07217007875442505\n",
      "Epoch: 019, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.04756493493914604\n",
      "Epoch: 020, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.052507877349853516\n",
      "Epoch: 021, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.08067232370376587\n",
      "Epoch: 022, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.054328348487615585\n",
      "Epoch: 023, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.050930462777614594\n",
      "Epoch: 024, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.04383904114365578\n",
      "Epoch: 025, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.04388756677508354\n",
      "Epoch: 026, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.03467021882534027\n",
      "Epoch: 027, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.05672196298837662\n",
      "Epoch: 028, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.031031763181090355\n",
      "Epoch: 029, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.017592499032616615\n",
      "Epoch: 030, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.020795775577425957\n",
      "Epoch: 031, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.02007196471095085\n",
      "Epoch: 032, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.019614119082689285\n",
      "Epoch: 033, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.024546073749661446\n",
      "Epoch: 034, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0207495279610157\n",
      "Epoch: 035, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.009376940317451954\n",
      "Epoch: 036, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.007599126547574997\n",
      "Epoch: 037, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.01639633998274803\n",
      "Epoch: 038, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.011394303292036057\n",
      "Epoch: 039, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.005498181097209454\n",
      "Epoch: 040, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.03145433962345123\n",
      "Epoch: 041, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.013471120037138462\n",
      "Epoch: 042, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.00918513908982277\n",
      "Epoch: 043, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.01375555619597435\n",
      "Epoch: 044, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.017132265493273735\n",
      "Epoch: 045, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.010165718384087086\n",
      "Epoch: 046, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.013076783157885075\n",
      "Epoch: 047, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0065676551312208176\n",
      "Epoch: 048, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.008604278787970543\n",
      "Epoch: 049, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.005172325298190117\n",
      "Epoch: 050, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.006013303995132446\n",
      "Epoch: 051, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.010635017417371273\n",
      "Epoch: 052, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004941422026604414\n",
      "Epoch: 053, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0021150135435163975\n",
      "Epoch: 054, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0067983209155499935\n",
      "Epoch: 055, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.005979631561785936\n",
      "Epoch: 056, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0036732363514602184\n",
      "Epoch: 057, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.007974273525178432\n",
      "Epoch: 058, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0026897448115050793\n",
      "Epoch: 059, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.00751608656719327\n",
      "Epoch: 060, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0034096285235136747\n",
      "Epoch: 061, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.005472216755151749\n",
      "Epoch: 062, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004904534202069044\n",
      "Epoch: 063, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0029915180057287216\n",
      "Epoch: 064, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.00369639927521348\n",
      "Epoch: 065, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.003514990210533142\n",
      "Epoch: 066, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004898161627352238\n",
      "Epoch: 067, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.003219696693122387\n",
      "Epoch: 068, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0016084725502878428\n",
      "Epoch: 069, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0039718057960271835\n",
      "Epoch: 070, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0031148239504545927\n",
      "Epoch: 071, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.003477415768429637\n",
      "Epoch: 072, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.00200001522898674\n",
      "Epoch: 073, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0019125558901578188\n",
      "Epoch: 074, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.001448885421268642\n",
      "Epoch: 075, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0016667769523337483\n",
      "Epoch: 076, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0026277387514710426\n",
      "Epoch: 077, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004498536232858896\n",
      "Epoch: 078, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0012377582024782896\n",
      "Epoch: 079, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0010595798958092928\n",
      "Epoch: 080, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0014735414879396558\n",
      "Epoch: 081, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0016843534540385008\n",
      "Epoch: 082, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.002957119606435299\n",
      "Epoch: 083, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.003506935201585293\n",
      "Epoch: 084, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0017727367812767625\n",
      "Epoch: 085, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.001603451557457447\n",
      "Epoch: 086, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0014963186113163829\n",
      "Epoch: 087, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0015011441428214312\n",
      "Epoch: 088, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.001567735569551587\n",
      "Epoch: 089, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004044265020638704\n",
      "Epoch: 090, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0015033859526738524\n",
      "Epoch: 091, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.002234044251963496\n",
      "Epoch: 092, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0014346616808325052\n",
      "Epoch: 093, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0022370938677340746\n",
      "Epoch: 094, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0024104341864585876\n",
      "Epoch: 095, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0011446562130004168\n",
      "Epoch: 096, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.001358592533506453\n",
      "Epoch: 097, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0011324674123898149\n",
      "Epoch: 098, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0034620920196175575\n",
      "Epoch: 099, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0016650070901960135\n",
      "Epoch: 100, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "model = GIN(hidden_channels=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    print(loss.item())\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    misclass = []\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        misclass += list(data[pred != data.y])\n",
    "    return correct / len(loader.dataset), misclass  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    train()\n",
    "    train_acc, trM = test(train_loader)\n",
    "    test_acc, testM = test(test_loader)\n",
    "#     print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(len(trM))\n",
    "for datapoint in trM:\n",
    "    print(datapoint.edge_index)\n",
    "    print(datapoint.y)\n",
    "        \n",
    "print(len(testM))\n",
    "for datapoint in testM:\n",
    "    print(datapoint.edge_index)\n",
    "    print(datapoint.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(1, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "#         x = x.relu()\n",
    "#         x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "#         x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        x = global_add_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6450372934341431\n",
      "Epoch: 001, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6301229596138\n",
      "Epoch: 002, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.8484597206115723\n",
      "Epoch: 003, Train Acc: 0.4255, Test Acc: 0.3390\n",
      "0.7093400955200195\n",
      "Epoch: 004, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.7700427770614624\n",
      "Epoch: 005, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6686123013496399\n",
      "Epoch: 006, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6830257177352905\n",
      "Epoch: 007, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6735721826553345\n",
      "Epoch: 008, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.7066959142684937\n",
      "Epoch: 009, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6703315377235413\n",
      "Epoch: 010, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.7121647000312805\n",
      "Epoch: 011, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6695734262466431\n",
      "Epoch: 012, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6574337482452393\n",
      "Epoch: 013, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.633428156375885\n",
      "Epoch: 014, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6236926913261414\n",
      "Epoch: 015, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.5936384201049805\n",
      "Epoch: 016, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6545533537864685\n",
      "Epoch: 017, Train Acc: 0.5745, Test Acc: 0.6610\n",
      "0.6076120734214783\n",
      "Epoch: 018, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.5574672222137451\n",
      "Epoch: 019, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.5687131285667419\n",
      "Epoch: 020, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.5219153761863708\n",
      "Epoch: 021, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.4085274040699005\n",
      "Epoch: 022, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.344213604927063\n",
      "Epoch: 023, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.27469319105148315\n",
      "Epoch: 024, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.2151072770357132\n",
      "Epoch: 025, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.17190994322299957\n",
      "Epoch: 026, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.12693125009536743\n",
      "Epoch: 027, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.08403418213129044\n",
      "Epoch: 028, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.09502651542425156\n",
      "Epoch: 029, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.10224650800228119\n",
      "Epoch: 030, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.09263617545366287\n",
      "Epoch: 031, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.04121283069252968\n",
      "Epoch: 032, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.055649757385253906\n",
      "Epoch: 033, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0394824780523777\n",
      "Epoch: 034, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.06490333378314972\n",
      "Epoch: 035, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.1193545013666153\n",
      "Epoch: 036, Train Acc: 0.9234, Test Acc: 0.8983\n",
      "0.10210613906383514\n",
      "Epoch: 037, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.04041619598865509\n",
      "Epoch: 038, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.060875725001096725\n",
      "Epoch: 039, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.07367713749408722\n",
      "Epoch: 040, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.028188996016979218\n",
      "Epoch: 041, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.03500574082136154\n",
      "Epoch: 042, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.047990866005420685\n",
      "Epoch: 043, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.057109590619802475\n",
      "Epoch: 044, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.030746066942811012\n",
      "Epoch: 045, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.03230256587266922\n",
      "Epoch: 046, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.03201676160097122\n",
      "Epoch: 047, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.029191210865974426\n",
      "Epoch: 048, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.032546091824769974\n",
      "Epoch: 049, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0251163300126791\n",
      "Epoch: 050, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.03689004108309746\n",
      "Epoch: 051, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.026203524321317673\n",
      "Epoch: 052, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.03283069282770157\n",
      "Epoch: 053, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.015186422504484653\n",
      "Epoch: 054, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.01834258623421192\n",
      "Epoch: 055, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.011522593908011913\n",
      "Epoch: 056, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.01165398582816124\n",
      "Epoch: 057, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.008372072130441666\n",
      "Epoch: 058, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004344262648373842\n",
      "Epoch: 059, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.006956629920750856\n",
      "Epoch: 060, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.010074039921164513\n",
      "Epoch: 061, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.014104724861681461\n",
      "Epoch: 062, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.009864691644906998\n",
      "Epoch: 063, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.014780665747821331\n",
      "Epoch: 064, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.009611333720386028\n",
      "Epoch: 065, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.010550026781857014\n",
      "Epoch: 066, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.006049870979040861\n",
      "Epoch: 067, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0045158774591982365\n",
      "Epoch: 068, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.016554662957787514\n",
      "Epoch: 069, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.01294755283743143\n",
      "Epoch: 070, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004769267980009317\n",
      "Epoch: 071, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.007415728643536568\n",
      "Epoch: 072, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004441745579242706\n",
      "Epoch: 073, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.007230804301798344\n",
      "Epoch: 074, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.00535771157592535\n",
      "Epoch: 075, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.005453704856336117\n",
      "Epoch: 076, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0042354348115623\n",
      "Epoch: 077, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.003855712478980422\n",
      "Epoch: 078, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004325058776885271\n",
      "Epoch: 079, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.008065319620072842\n",
      "Epoch: 080, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.00482809217646718\n",
      "Epoch: 081, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004656817764043808\n",
      "Epoch: 082, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.005782882682979107\n",
      "Epoch: 083, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.006129480432718992\n",
      "Epoch: 084, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004704120568931103\n",
      "Epoch: 085, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004196146037429571\n",
      "Epoch: 086, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0024770027957856655\n",
      "Epoch: 087, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0034073947463184595\n",
      "Epoch: 088, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0017650790978223085\n",
      "Epoch: 089, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004906969610601664\n",
      "Epoch: 090, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.006544071715325117\n",
      "Epoch: 091, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0029339094180613756\n",
      "Epoch: 092, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.002336692763492465\n",
      "Epoch: 093, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0054621389135718346\n",
      "Epoch: 094, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.006195830646902323\n",
      "Epoch: 095, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.004117892123758793\n",
      "Epoch: 096, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0016201623948290944\n",
      "Epoch: 097, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.000846239912789315\n",
      "Epoch: 098, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.002873677760362625\n",
      "Epoch: 099, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0.0033739868085831404\n",
      "Epoch: 100, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    print(loss.item())\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    misclass = []\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        misclass += list(data[pred != data.y])\n",
    "    return correct / len(loader.dataset), misclass  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    train()\n",
    "    train_acc, trM = test(train_loader)\n",
    "    test_acc, testM = test(test_loader)\n",
    "#     print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(len(trM))\n",
    "for datapoint in trM:\n",
    "    print(datapoint.edge_index)\n",
    "    print(datapoint.y)\n",
    "        \n",
    "print(len(testM))\n",
    "for datapoint in testM:\n",
    "    print(datapoint.edge_index)\n",
    "    print(datapoint.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN(\n",
      "  (lin1): Linear(in_features=1, out_features=64, bias=True)\n",
      "  (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (lin3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(NN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = Linear(1, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "model = NN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   0,   2,  ..., 308, 307, 306],\n",
      "        [  0,   2,   4,  ..., 307, 306, 307]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x552 and 1x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-94f29e29f535>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m201\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-94f29e29f535>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Iterate in batches over the training dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Perform a single forward pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Compute the loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Derive gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-23b29f6cba07>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x552 and 1x64)"
     ]
    }
   ],
   "source": [
    "model = NN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        print(data.edge_index)\n",
    "        out = model(data.edge_index)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    print(loss.item())\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    misclass = []\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.edge_index)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        misclass += list(data[pred != data.y])\n",
    "    return correct / len(loader.dataset), misclass  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    train_acc, trM = test(train_loader)\n",
    "    test_acc, testM = test(test_loader)\n",
    "#     print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(len(trM))\n",
    "for datapoint in trM:\n",
    "    print(datapoint.edge_index)\n",
    "    print(datapoint.y)\n",
    "        \n",
    "print(len(testM))\n",
    "for datapoint in testM:\n",
    "    print(datapoint.edge_index)\n",
    "    print(datapoint.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "bakalarka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
