{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Embedding, Activation, Lambda\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tqdm import tqdm,trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = 150000\n",
    "max_train_length = 10\n",
    "\n",
    "num_test_examples = 10000\n",
    "min_test_length=5\n",
    "max_test_length=55\n",
    "step_test_length=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(pack=0):\n",
    "    with open('/data/mnist/mnist8m_{0}_features.bin'.format(pack), 'r') as f:\n",
    "        v = np.fromfile(f, dtype='int32', count=1)\n",
    "        D = np.asscalar( np.fromfile(f, dtype='int32', count=1) )\n",
    "        N = np.asscalar( np.fromfile(f, dtype='int32', count=1) )\n",
    "        arr = np.fromfile(f).astype('float32')\n",
    "    img = np.reshape(arr, (N,D))\n",
    "    \n",
    "    with open('/data/mnist/mnist8m_{0}_labels.bin'.format(pack), 'r') as f:\n",
    "        v = np.fromfile(f, dtype='int32', count=1)\n",
    "        D = np.asscalar( np.fromfile(f, dtype='int32', count=1) )\n",
    "        N = np.asscalar( np.fromfile(f, dtype='int32', count=1) )\n",
    "        arr = np.fromfile(f).astype('float32')\n",
    "    label = np.reshape(arr, (N,D))\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/skottur/florainritter/code/data/mnist/mnist8m_0_features.bin'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-b6d3fd7bc5ae>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_mnist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# Random shuffle of data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mrng_state\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_state\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-6-c1496ff6cb8b>\u001B[0m in \u001B[0;36mload_mnist\u001B[1;34m(pack)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mload_mnist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpack\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'/home/skottur/florainritter/code/data/mnist/mnist8m_{0}_features.bin'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpack\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m         \u001B[0mv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'int32'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0mD\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masscalar\u001B[0m\u001B[1;33m(\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'int32'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0mN\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masscalar\u001B[0m\u001B[1;33m(\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'int32'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcount\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/skottur/florainritter/code/data/mnist/mnist8m_0_features.bin'"
     ]
    }
   ],
   "source": [
    "img, label = load_mnist(0)\n",
    "\n",
    "# Random shuffle of data\n",
    "rng_state = np.random.get_state()\n",
    "np.random.shuffle(img)\n",
    "np.random.set_state(rng_state)\n",
    "np.random.shuffle(label) \n",
    "\n",
    "X = np.zeros((num_train_examples,max_train_length))\n",
    "sum_X = np.zeros((num_train_examples))\n",
    "m = 0\n",
    "for i in tqdm(range(num_train_examples), desc='Generating train examples: '):\n",
    "    n = np.random.randint(1,max_train_length)\n",
    "    for j in range(1,n+1):\n",
    "        while label[m]==0.:\n",
    "            m += 1\n",
    "        X[i,-j] = m\n",
    "        sum_X[i] += label[m]\n",
    "        m += 1\n",
    "img = img[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(X[0:10])\n",
    "print(sum_X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_data(num_examples, length):\n",
    "    img, label = load_mnist(np.random.randint(1,8))\n",
    "    Y = np.zeros((num_examples, length))\n",
    "    sum_Y = np.zeros((num_examples))\n",
    "    m = 0\n",
    "    for i in range(num_examples):\n",
    "        for j in range(1,length+1):\n",
    "            while label[m]==0.:\n",
    "                m += 1\n",
    "            Y[i,-j] = m\n",
    "            sum_Y[i] += label[m]\n",
    "            m += 1\n",
    "    return img[:m], Y, sum_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deepset_model(images, max_length):\n",
    "    input_img = Input(shape=(max_length,))\n",
    "    x = Embedding(images.shape[0], images.shape[1], mask_zero=True, trainable=False)(input_img)\n",
    "    x = Dense(300, activation='tanh')(x)\n",
    "    x = Dense(100, activation='tanh')(x)\n",
    "    x = Dense(30, activation='tanh')(x)\n",
    "    Adder = Lambda(lambda x: K.sum(x, axis=1), output_shape=(lambda shape: (shape[0], shape[2])))\n",
    "    x = Adder(x)\n",
    "    encoded = Dense(1)(x)\n",
    "    summer = Model(input_img, encoded)\n",
    "    adam = Adam(lr=1e-3, epsilon=1e-3)\n",
    "    summer.compile(optimizer=adam, loss='mae')\n",
    "    summer.get_layer(index=1).set_weights([images])\n",
    "    return summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(images, max_length):\n",
    "    input_img = Input(shape=(max_length,))\n",
    "    x = Embedding(images.shape[0], images.shape[1], mask_zero=True, trainable=False)(input_img)\n",
    "    x = Dense(300, activation='tanh')(x) #One can try relu as well which results in similar performance\n",
    "    x = Dense(100, activation='tanh')(x)\n",
    "    x = LSTM(50)(x)\n",
    "    x = Dense(30, activation='tanh')(x)\n",
    "    encoded = Dense(1)(x)\n",
    "    summer = Model(input_img, encoded)\n",
    "    adam = Adam(lr=1e-3)\n",
    "    summer.compile(optimizer=adam, loss='mae') #One can try mse as well which results in similar performance\n",
    "    summer.get_layer(index=1).set_weights([images])\n",
    "    return summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru_model(images, max_length):\n",
    "    input_img = Input(shape=(max_length,))\n",
    "    x = Embedding(images.shape[0], images.shape[1], mask_zero=True, trainable=False)(input_img)\n",
    "    x = Dense(300, activation='tanh')(x) #One can try relu as well which results in similar performance\n",
    "    x = Dense(100, activation='tanh')(x)\n",
    "    x = GRU(50)(x)\n",
    "    x = Dense(30, activation='tanh')(x)\n",
    "    encoded = Dense(1)(x)\n",
    "    summer = Model(input_img, encoded)\n",
    "    adam = Adam(lr=1e-3)\n",
    "    summer.compile(optimizer=adam, loss='mae') #One can try mse as well which results in similar performance\n",
    "    summer.get_layer(index=1).set_weights([images])\n",
    "    return summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DeepSet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"560pt\" viewBox=\"0.00 0.00 328.00 560.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 556)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-556 324,-556 324,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140711259370720 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140711259370720</title>\n",
       "<polygon fill=\"none\" points=\"32,-505 32,-551 288,-551 288,-505 32,-505\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-524.3\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"157,-505 157,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-535.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157,-528 212,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-512.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"212,-505 212,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-535.8\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"212,-528 288,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-512.8\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 140710142340232 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140710142340232</title>\n",
       "<polygon fill=\"none\" points=\"0,-421 0,-467 320,-467 320,-421 0,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-440.3\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-421 161,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-444 216,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-421 216,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-451.8\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"216,-444 320,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-428.8\">(None, 10, 784)</text>\n",
       "</g>\n",
       "<!-- 140711259370720&#45;&gt;140710142340232 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140711259370720-&gt;140710142340232</title>\n",
       "<path d=\"M160,-504.593C160,-496.118 160,-486.297 160,-477.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-477.096 160,-467.096 156.5,-477.096 163.5,-477.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710142337880 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140710142337880</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-337 29.5,-383 290.5,-383 290.5,-337 29.5,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-356.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-337 131.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-360 186.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-337 186.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-367.8\">(None, 10, 784)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-360 290.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-344.8\">(None, 10, 300)</text>\n",
       "</g>\n",
       "<!-- 140710142340232&#45;&gt;140710142337880 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140710142340232-&gt;140710142337880</title>\n",
       "<path d=\"M160,-420.593C160,-412.118 160,-402.297 160,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-393.096 160,-383.096 156.5,-393.096 163.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710142366888 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140710142366888</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-253 29.5,-299 290.5,-299 290.5,-253 29.5,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-272.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-253 131.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-276 186.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-253 186.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-283.8\">(None, 10, 300)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-276 290.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-260.8\">(None, 10, 100)</text>\n",
       "</g>\n",
       "<!-- 140710142337880&#45;&gt;140710142366888 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140710142337880-&gt;140710142366888</title>\n",
       "<path d=\"M160,-336.593C160,-328.118 160,-318.297 160,-309.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-309.096 160,-299.096 156.5,-309.096 163.5,-309.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710142078144 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140710142078144</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-169 29.5,-215 290.5,-215 290.5,-169 29.5,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-188.3\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-169 131.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-192 186.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-169 186.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-199.8\">(None, 10, 100)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-192 290.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-176.8\">(None, 10, 30)</text>\n",
       "</g>\n",
       "<!-- 140710142366888&#45;&gt;140710142078144 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140710142366888-&gt;140710142078144</title>\n",
       "<path d=\"M160,-252.593C160,-244.118 160,-234.297 160,-225.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-225.096 160,-215.096 156.5,-225.096 163.5,-225.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710141717864 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140710141717864</title>\n",
       "<polygon fill=\"none\" points=\"22.5,-85 22.5,-131 297.5,-131 297.5,-85 22.5,-85\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84\" y=\"-104.3\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-85 145.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-115.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-108 200.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-92.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-85 200.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-115.8\">(None, 10, 30)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-108 297.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-92.8\">(None, 30)</text>\n",
       "</g>\n",
       "<!-- 140710142078144&#45;&gt;140710141717864 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140710142078144-&gt;140710141717864</title>\n",
       "<path d=\"M160,-168.593C160,-160.118 160,-150.297 160,-141.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-141.096 160,-131.096 156.5,-141.096 163.5,-141.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710141718312 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140710141718312</title>\n",
       "<polygon fill=\"none\" points=\"43.5,-1 43.5,-47 276.5,-47 276.5,-1 43.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-20.3\">dense_4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-1 145.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-31.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-24 200.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-8.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-1 200.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-31.8\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-24 276.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-8.8\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140710141717864&#45;&gt;140710141718312 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140710141717864-&gt;140710141718312</title>\n",
       "<path d=\"M160,-84.5931C160,-76.1177 160,-66.2974 160,-57.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-57.0958 160,-47.0959 156.5,-57.0959 163.5,-57.0958\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "K.clear_session()\n",
    "model = get_deepset_model(img, max_train_length)\n",
    "\n",
    "# visualize\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148148 samples, validate on 1852 samples\n",
      "Epoch 1/500\n",
      "148148/148148 [==============================] - 8s 53us/step - loss: 2.3590 - val_loss: 1.4361\n",
      "Epoch 2/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 1.1923 - val_loss: 1.0133\n",
      "Epoch 3/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.8825 - val_loss: 0.7935\n",
      "Epoch 4/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.6810 - val_loss: 0.5835\n",
      "Epoch 5/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.5477 - val_loss: 0.5706\n",
      "Epoch 6/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.4518 - val_loss: 0.4390\n",
      "Epoch 7/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.3803 - val_loss: 0.3630\n",
      "Epoch 8/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.3256 - val_loss: 0.3185\n",
      "Epoch 9/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.2782 - val_loss: 0.2839\n",
      "Epoch 10/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.2434 - val_loss: 0.2757\n",
      "Epoch 11/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.2150 - val_loss: 0.2558\n",
      "Epoch 12/500\n",
      "148148/148148 [==============================] - 8s 51us/step - loss: 0.1918 - val_loss: 0.2206\n",
      "Epoch 13/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.1738 - val_loss: 0.2267\n",
      "Epoch 14/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.1568 - val_loss: 0.2163\n",
      "Epoch 15/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.1453 - val_loss: 0.2048\n",
      "Epoch 16/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.1331 - val_loss: 0.1736\n",
      "Epoch 17/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.1246 - val_loss: 0.1838\n",
      "Epoch 18/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.1170 - val_loss: 0.1598\n",
      "Epoch 19/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.1085 - val_loss: 0.1670\n",
      "Epoch 20/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.1014 - val_loss: 0.1303\n",
      "Epoch 21/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0978 - val_loss: 0.1316\n",
      "Epoch 22/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0911 - val_loss: 0.1391\n",
      "Epoch 23/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0885 - val_loss: 0.1515\n",
      "Epoch 24/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0833 - val_loss: 0.1184\n",
      "Epoch 25/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0807 - val_loss: 0.1433\n",
      "Epoch 26/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0785 - val_loss: 0.1505\n",
      "Epoch 27/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0757 - val_loss: 0.1012\n",
      "Epoch 28/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0714 - val_loss: 0.1164\n",
      "Epoch 29/500\n",
      "148148/148148 [==============================] - 7s 47us/step - loss: 0.0683 - val_loss: 0.1109\n",
      "Epoch 30/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0669 - val_loss: 0.1259\n",
      "Epoch 31/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0663 - val_loss: 0.1154\n",
      "Epoch 32/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0623 - val_loss: 0.1184\n",
      "Epoch 33/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0609 - val_loss: 0.1180\n",
      "Epoch 34/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0610 - val_loss: 0.1079\n",
      "Epoch 35/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0587 - val_loss: 0.1060\n",
      "Epoch 36/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0568 - val_loss: 0.0989\n",
      "Epoch 37/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.0565 - val_loss: 0.1202\n",
      "Epoch 38/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0555 - val_loss: 0.0938\n",
      "Epoch 39/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0517 - val_loss: 0.0916\n",
      "Epoch 40/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0531 - val_loss: 0.1007\n",
      "Epoch 41/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0511 - val_loss: 0.0926\n",
      "Epoch 42/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.0491 - val_loss: 0.0955\n",
      "Epoch 43/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0492 - val_loss: 0.0865\n",
      "Epoch 44/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0484 - val_loss: 0.0929\n",
      "Epoch 45/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0487 - val_loss: 0.0902\n",
      "Epoch 46/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.0444 - val_loss: 0.1097\n",
      "Epoch 47/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0463 - val_loss: 0.0988\n",
      "Epoch 48/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0453 - val_loss: 0.0864\n",
      "Epoch 49/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0451 - val_loss: 0.1026\n",
      "Epoch 50/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0433 - val_loss: 0.0817\n",
      "Epoch 51/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0428 - val_loss: 0.0934\n",
      "Epoch 52/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0421 - val_loss: 0.0824\n",
      "Epoch 53/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0433 - val_loss: 0.0991\n",
      "Epoch 54/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0400 - val_loss: 0.0988\n",
      "Epoch 55/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0399 - val_loss: 0.1083\n",
      "Epoch 56/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0401 - val_loss: 0.1096\n",
      "Epoch 57/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0401 - val_loss: 0.0899\n",
      "Epoch 58/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0388 - val_loss: 0.0886\n",
      "Epoch 59/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0382 - val_loss: 0.0932\n",
      "Epoch 60/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0396 - val_loss: 0.0814\n",
      "Epoch 61/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0372 - val_loss: 0.0878\n",
      "Epoch 62/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0359 - val_loss: 0.1051\n",
      "Epoch 63/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0373 - val_loss: 0.0966\n",
      "Epoch 64/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0378 - val_loss: 0.0756\n",
      "Epoch 65/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0359 - val_loss: 0.0894\n",
      "Epoch 66/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0378 - val_loss: 0.0828\n",
      "Epoch 67/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0343 - val_loss: 0.0848\n",
      "Epoch 68/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0370 - val_loss: 0.0732\n",
      "Epoch 69/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0333 - val_loss: 0.0846\n",
      "Epoch 70/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0349 - val_loss: 0.0634\n",
      "Epoch 71/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0353 - val_loss: 0.0724\n",
      "Epoch 72/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0350 - val_loss: 0.0674\n",
      "Epoch 73/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0321 - val_loss: 0.0833\n",
      "Epoch 74/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0317 - val_loss: 0.0877\n",
      "Epoch 75/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0328 - val_loss: 0.1011\n",
      "Epoch 76/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0335 - val_loss: 0.0920\n",
      "Epoch 77/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0313 - val_loss: 0.0978\n",
      "Epoch 78/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0313 - val_loss: 0.0777\n",
      "Epoch 79/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0328 - val_loss: 0.0875\n",
      "Epoch 80/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0311 - val_loss: 0.0853\n",
      "Epoch 81/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0319 - val_loss: 0.0718\n",
      "Epoch 82/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0296 - val_loss: 0.0826\n",
      "Epoch 83/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0299 - val_loss: 0.0618\n",
      "Epoch 84/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0316 - val_loss: 0.0817\n",
      "Epoch 85/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0320 - val_loss: 0.0944\n",
      "Epoch 86/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0308 - val_loss: 0.0883\n",
      "Epoch 87/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0304 - val_loss: 0.0835\n",
      "Epoch 88/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0301 - val_loss: 0.0762\n",
      "Epoch 89/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0299 - val_loss: 0.0905\n",
      "Epoch 90/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0284 - val_loss: 0.0857\n",
      "Epoch 91/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0310 - val_loss: 0.0766\n",
      "Epoch 92/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0299 - val_loss: 0.0801\n",
      "Epoch 93/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0278 - val_loss: 0.0900\n",
      "Epoch 94/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.0287 - val_loss: 0.0706\n",
      "Epoch 95/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0290 - val_loss: 0.0837\n",
      "Epoch 96/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0289 - val_loss: 0.0812\n",
      "Epoch 97/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0291 - val_loss: 0.0778\n",
      "Epoch 98/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0282 - val_loss: 0.0726\n",
      "Epoch 99/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0293 - val_loss: 0.0756\n",
      "Epoch 100/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0277 - val_loss: 0.0783\n",
      "Epoch 101/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0278 - val_loss: 0.0733\n",
      "Epoch 102/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0276 - val_loss: 0.0908\n",
      "Epoch 103/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0267 - val_loss: 0.0897\n",
      "Epoch 104/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0273 - val_loss: 0.0768\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 105/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0190 - val_loss: 0.0732\n",
      "Epoch 106/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0187 - val_loss: 0.0745\n",
      "Epoch 107/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0179 - val_loss: 0.0722\n",
      "Epoch 108/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0173 - val_loss: 0.0620\n",
      "Epoch 109/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0177 - val_loss: 0.0618\n",
      "Epoch 110/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0182 - val_loss: 0.0679\n",
      "Epoch 111/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0179 - val_loss: 0.0647\n",
      "Epoch 112/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0176 - val_loss: 0.0644\n",
      "Epoch 113/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0172 - val_loss: 0.0616\n",
      "Epoch 114/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0179 - val_loss: 0.0673\n",
      "Epoch 115/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.0177 - val_loss: 0.0719\n",
      "Epoch 116/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0177 - val_loss: 0.0699\n",
      "Epoch 117/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0172 - val_loss: 0.0683\n",
      "Epoch 118/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0169 - val_loss: 0.0634\n",
      "Epoch 119/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0173 - val_loss: 0.0764\n",
      "Epoch 120/500\n",
      "148148/148148 [==============================] - 7s 50us/step - loss: 0.0170 - val_loss: 0.0609\n",
      "Epoch 121/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0174 - val_loss: 0.0667\n",
      "Epoch 122/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0174 - val_loss: 0.0715\n",
      "Epoch 123/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0171 - val_loss: 0.0721\n",
      "Epoch 124/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0174 - val_loss: 0.0745\n",
      "Epoch 125/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0170 - val_loss: 0.0641\n",
      "Epoch 126/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0170 - val_loss: 0.0626\n",
      "Epoch 127/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0175 - val_loss: 0.0705\n",
      "Epoch 128/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0174 - val_loss: 0.0653\n",
      "Epoch 129/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0169 - val_loss: 0.0620\n",
      "Epoch 130/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0174 - val_loss: 0.0625\n",
      "Epoch 131/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0166 - val_loss: 0.0643\n",
      "Epoch 132/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0167 - val_loss: 0.0675\n",
      "Epoch 133/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0177 - val_loss: 0.0638\n",
      "Epoch 134/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0172 - val_loss: 0.0651\n",
      "Epoch 135/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0161 - val_loss: 0.0705\n",
      "Epoch 136/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0172 - val_loss: 0.0745\n",
      "Epoch 137/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0167 - val_loss: 0.0694\n",
      "Epoch 138/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0172 - val_loss: 0.0773\n",
      "Epoch 139/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0170 - val_loss: 0.0639\n",
      "Epoch 140/500\n",
      "148148/148148 [==============================] - 7s 46us/step - loss: 0.0171 - val_loss: 0.0628\n",
      "Epoch 141/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0160 - val_loss: 0.0661\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 142/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0136 - val_loss: 0.0623\n",
      "Epoch 143/500\n",
      "148148/148148 [==============================] - 7s 47us/step - loss: 0.0137 - val_loss: 0.0640\n",
      "Epoch 144/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0137 - val_loss: 0.0668\n",
      "Epoch 145/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0136 - val_loss: 0.0645\n",
      "Epoch 146/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0130 - val_loss: 0.0657\n",
      "Epoch 147/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0134 - val_loss: 0.0684\n",
      "Epoch 148/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0133 - val_loss: 0.0651\n",
      "Epoch 149/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0132 - val_loss: 0.0635\n",
      "Epoch 150/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0133 - val_loss: 0.0619\n",
      "Epoch 151/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0133 - val_loss: 0.0661\n",
      "Epoch 152/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0135 - val_loss: 0.0649\n",
      "Epoch 153/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0134 - val_loss: 0.0664\n",
      "Epoch 154/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0133 - val_loss: 0.0641\n",
      "Epoch 155/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0132 - val_loss: 0.0634\n",
      "Epoch 156/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0134 - val_loss: 0.0648\n",
      "Epoch 157/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0132 - val_loss: 0.0645\n",
      "Epoch 158/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0133 - val_loss: 0.0633\n",
      "Epoch 159/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0133 - val_loss: 0.0660\n",
      "Epoch 160/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0135 - val_loss: 0.0654\n",
      "Epoch 161/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0131 - val_loss: 0.0650\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 162/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0633\n",
      "Epoch 163/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0652\n",
      "Epoch 164/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0638\n",
      "Epoch 165/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0118 - val_loss: 0.0632\n",
      "Epoch 166/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0629\n",
      "Epoch 167/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0634\n",
      "Epoch 168/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0644\n",
      "Epoch 169/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0118 - val_loss: 0.0678\n",
      "Epoch 170/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0118 - val_loss: 0.0654\n",
      "Epoch 171/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0645\n",
      "Epoch 172/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0637\n",
      "Epoch 173/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0637\n",
      "Epoch 174/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0118 - val_loss: 0.0629\n",
      "Epoch 175/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0626\n",
      "Epoch 176/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0626\n",
      "Epoch 177/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0116 - val_loss: 0.0624\n",
      "Epoch 178/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0654\n",
      "Epoch 179/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0118 - val_loss: 0.0630\n",
      "Epoch 180/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0643\n",
      "Epoch 181/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0117 - val_loss: 0.0638\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 182/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0109 - val_loss: 0.0623\n",
      "Epoch 183/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0628\n",
      "Epoch 184/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0634\n",
      "Epoch 185/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0109 - val_loss: 0.0630\n",
      "Epoch 186/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0621\n",
      "Epoch 187/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0623\n",
      "Epoch 188/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0627\n",
      "Epoch 189/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0625\n",
      "Epoch 190/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0617\n",
      "Epoch 191/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0631\n",
      "Epoch 192/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0108 - val_loss: 0.0612\n",
      "Epoch 193/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0108 - val_loss: 0.0624\n",
      "Epoch 194/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0623\n",
      "Epoch 195/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0108 - val_loss: 0.0630\n",
      "Epoch 196/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0621\n",
      "Epoch 197/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0108 - val_loss: 0.0630\n",
      "Epoch 198/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0622\n",
      "Epoch 199/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0631\n",
      "Epoch 200/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0627\n",
      "Epoch 201/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0109 - val_loss: 0.0623\n",
      "\n",
      "Epoch 00201: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 202/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0620\n",
      "Epoch 203/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0620\n",
      "Epoch 204/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0616\n",
      "Epoch 205/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0616\n",
      "Epoch 206/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0620\n",
      "Epoch 207/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0617\n",
      "Epoch 208/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0615\n",
      "Epoch 209/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0621\n",
      "Epoch 210/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0615\n",
      "Epoch 211/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0104 - val_loss: 0.0612\n",
      "Epoch 212/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0616\n",
      "Epoch 213/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0612\n",
      "Epoch 214/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0617\n",
      "Epoch 215/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0104 - val_loss: 0.0616\n",
      "Epoch 216/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0619\n",
      "Epoch 217/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0104 - val_loss: 0.0616\n",
      "Epoch 218/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0620\n",
      "Epoch 219/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0104 - val_loss: 0.0612\n",
      "Epoch 220/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0612\n",
      "Epoch 221/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0105 - val_loss: 0.0615\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 222/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0616\n",
      "Epoch 223/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0611\n",
      "Epoch 224/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0613\n",
      "Epoch 225/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0614\n",
      "Epoch 226/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0613\n",
      "Epoch 227/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0612\n",
      "Epoch 228/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0613\n",
      "Epoch 229/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0614\n",
      "Epoch 230/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0612\n",
      "Epoch 231/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0614\n",
      "Epoch 232/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0614\n",
      "Epoch 233/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0615\n",
      "Epoch 234/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0612\n",
      "Epoch 235/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0103 - val_loss: 0.0615\n",
      "Epoch 236/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0611\n",
      "Epoch 237/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0613\n",
      "Epoch 238/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0617\n",
      "Epoch 239/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0103 - val_loss: 0.0613\n",
      "Epoch 240/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 241/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0103 - val_loss: 0.0612\n",
      "\n",
      "Epoch 00241: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 242/500\n",
      "148148/148148 [==============================] - 7s 46us/step - loss: 0.0102 - val_loss: 0.0612\n",
      "Epoch 243/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 244/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0612\n",
      "Epoch 245/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 246/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 247/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 248/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 249/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 250/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0102 - val_loss: 0.0612\n",
      "Epoch 251/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 252/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 253/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0614\n",
      "Epoch 254/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 255/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0614\n",
      "Epoch 256/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0612\n",
      "Epoch 257/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 258/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 259/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0612\n",
      "Epoch 260/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "Epoch 261/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0102 - val_loss: 0.0613\n",
      "\n",
      "Epoch 00261: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 262/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 263/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 264/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 265/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 266/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 267/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 268/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0612\n",
      "Epoch 269/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 270/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 271/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0614\n",
      "Epoch 272/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 273/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 274/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0612\n",
      "Epoch 275/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 276/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 277/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 278/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0612\n",
      "Epoch 279/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 280/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 281/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 282/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 283/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 284/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0614\n",
      "Epoch 285/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 286/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 287/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 288/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 289/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 290/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 291/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 292/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 293/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 294/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 295/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 296/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 297/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 298/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 299/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 300/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 301/500\n",
      "148148/148148 [==============================] - 7s 47us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "\n",
      "Epoch 00301: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 302/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 303/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 304/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 305/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 306/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 307/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 308/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 309/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 310/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 311/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 312/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 313/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 314/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 315/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 316/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 317/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 318/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 319/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 320/500\n",
      "148148/148148 [==============================] - 7s 46us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 321/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 322/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 323/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 324/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 325/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 326/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 327/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 328/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 329/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 330/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 331/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 332/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 333/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 334/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 335/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 336/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 337/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 338/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 339/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 340/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 341/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 342/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 343/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 344/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 345/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 346/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 347/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 348/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 349/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 350/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 351/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 352/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 353/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 354/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 355/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 356/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 357/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 358/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 359/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 360/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 361/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 362/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 363/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 364/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 365/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 366/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 367/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 368/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 369/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 370/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 371/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 372/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 373/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 374/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 375/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 376/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 377/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 378/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 379/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 380/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 381/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 382/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 383/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 384/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 385/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 386/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 387/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 388/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 389/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 390/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 391/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 392/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 393/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 394/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 395/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 396/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 397/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 398/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 399/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 400/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 401/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 402/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 403/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 404/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 405/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 406/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 407/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 408/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 409/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 410/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 411/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 412/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 413/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 414/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 415/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 416/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 417/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 418/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 419/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 420/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 421/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 422/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 423/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 424/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 425/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 426/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 427/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 428/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 429/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 430/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 431/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 432/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 433/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 434/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 435/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 436/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 437/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 438/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 439/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 440/500\n",
      "148148/148148 [==============================] - 7s 48us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 441/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 442/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 443/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 444/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 445/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 446/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 447/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 448/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 449/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 450/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 451/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 452/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 453/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 454/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 455/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 456/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 457/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 458/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 459/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 460/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 461/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 462/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 463/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 464/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 465/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 466/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 467/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 468/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 469/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 470/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 471/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 472/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 473/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 474/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 475/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 476/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 477/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 478/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 479/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 480/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 481/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 482/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 483/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 484/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 485/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 486/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 487/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 488/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 489/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 490/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 491/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 492/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 493/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 494/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 495/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 496/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 497/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 498/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 499/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n",
      "Epoch 500/500\n",
      "148148/148148 [==============================] - 7s 49us/step - loss: 0.0101 - val_loss: 0.0613\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, verbose=1, patience=20, min_lr=0.000001)\n",
    "\n",
    "model.fit(X, sum_X, epochs=500, batch_size=128,\n",
    "        shuffle=True, validation_split=0.0123456789,\n",
    "        callbacks=[reduce_lr])\n",
    "\n",
    "# save weights\n",
    "deep_we = []\n",
    "for i in [2,3,4,6]:\n",
    "    w = model.get_layer(index=i).get_weights()\n",
    "    deep_we.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"560pt\" viewBox=\"0.00 0.00 328.00 560.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 556)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-556 324,-556 324,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140714156161680 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140714156161680</title>\n",
       "<polygon fill=\"none\" points=\"32,-505 32,-551 288,-551 288,-505 32,-505\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-524.3\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"157,-505 157,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-535.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157,-528 212,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-512.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"212,-505 212,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-535.8\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"212,-528 288,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-512.8\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 140714160465232 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140714160465232</title>\n",
       "<polygon fill=\"none\" points=\"0,-421 0,-467 320,-467 320,-421 0,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-440.3\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-421 161,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-444 216,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-421 216,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-451.8\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"216,-444 320,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-428.8\">(None, 10, 784)</text>\n",
       "</g>\n",
       "<!-- 140714156161680&#45;&gt;140714160465232 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140714156161680-&gt;140714160465232</title>\n",
       "<path d=\"M160,-504.593C160,-496.118 160,-486.297 160,-477.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-477.096 160,-467.096 156.5,-477.096 163.5,-477.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140714156157640 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140714156157640</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-337 29.5,-383 290.5,-383 290.5,-337 29.5,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-356.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-337 131.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-360 186.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-337 186.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-367.8\">(None, 10, 784)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-360 290.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-344.8\">(None, 10, 300)</text>\n",
       "</g>\n",
       "<!-- 140714160465232&#45;&gt;140714156157640 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140714160465232-&gt;140714156157640</title>\n",
       "<path d=\"M160,-420.593C160,-412.118 160,-402.297 160,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-393.096 160,-383.096 156.5,-393.096 163.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140714155799384 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140714155799384</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-253 29.5,-299 290.5,-299 290.5,-253 29.5,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-272.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-253 131.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-276 186.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-253 186.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-283.8\">(None, 10, 300)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-276 290.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-260.8\">(None, 10, 100)</text>\n",
       "</g>\n",
       "<!-- 140714156157640&#45;&gt;140714155799384 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140714156157640-&gt;140714155799384</title>\n",
       "<path d=\"M160,-336.593C160,-328.118 160,-318.297 160,-309.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-309.096 160,-299.096 156.5,-309.096 163.5,-309.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140714158062168 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140714158062168</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-169 31.5,-215 288.5,-215 288.5,-169 31.5,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-188.3\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-169 129.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-192 184.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-169 184.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-199.8\">(None, 10, 100)</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-192 288.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-176.8\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 140714155799384&#45;&gt;140714158062168 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140714155799384-&gt;140714158062168</title>\n",
       "<path d=\"M160,-252.593C160,-244.118 160,-234.297 160,-225.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-225.096 160,-215.096 156.5,-225.096 163.5,-225.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710137848944 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140710137848944</title>\n",
       "<polygon fill=\"none\" points=\"43.5,-85 43.5,-131 276.5,-131 276.5,-85 43.5,-85\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-104.3\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-85 145.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-115.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-108 200.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-92.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-85 200.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-115.8\">(None, 50)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-108 276.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-92.8\">(None, 30)</text>\n",
       "</g>\n",
       "<!-- 140714158062168&#45;&gt;140710137848944 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140714158062168-&gt;140710137848944</title>\n",
       "<path d=\"M160,-168.593C160,-160.118 160,-150.297 160,-141.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-141.096 160,-131.096 156.5,-141.096 163.5,-141.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710137982872 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140710137982872</title>\n",
       "<polygon fill=\"none\" points=\"43.5,-1 43.5,-47 276.5,-47 276.5,-1 43.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-20.3\">dense_4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-1 145.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-31.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-24 200.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-8.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-1 200.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-31.8\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-24 276.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-8.8\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140710137848944&#45;&gt;140710137982872 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140710137848944-&gt;140710137982872</title>\n",
       "<path d=\"M160,-84.5931C160,-76.1177 160,-66.2974 160,-57.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-57.0958 160,-47.0959 156.5,-57.0959 163.5,-57.0958\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "K.clear_session()\n",
    "model = get_lstm_model(img, max_train_length)\n",
    "\n",
    "# visualize\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148148 samples, validate on 1852 samples\n",
      "Epoch 1/100\n",
      "148148/148148 [==============================] - 58s 392us/step - loss: 8.4869 - val_loss: 3.1563\n",
      "Epoch 2/100\n",
      "148148/148148 [==============================] - 56s 377us/step - loss: 1.8508 - val_loss: 1.2662\n",
      "Epoch 3/100\n",
      "148148/148148 [==============================] - 57s 386us/step - loss: 0.9561 - val_loss: 0.8358\n",
      "Epoch 4/100\n",
      "148148/148148 [==============================] - 58s 390us/step - loss: 0.7147 - val_loss: 0.8012\n",
      "Epoch 5/100\n",
      "148148/148148 [==============================] - 57s 385us/step - loss: 0.5719 - val_loss: 0.6335\n",
      "Epoch 6/100\n",
      "148148/148148 [==============================] - 57s 385us/step - loss: 0.4920 - val_loss: 0.5452\n",
      "Epoch 7/100\n",
      "148148/148148 [==============================] - 57s 387us/step - loss: 0.4328 - val_loss: 0.4658\n",
      "Epoch 8/100\n",
      "148148/148148 [==============================] - 55s 368us/step - loss: 0.3870 - val_loss: 0.6349\n",
      "Epoch 9/100\n",
      "148148/148148 [==============================] - 58s 391us/step - loss: 0.3644 - val_loss: 0.4706\n",
      "Epoch 10/100\n",
      "148148/148148 [==============================] - 56s 379us/step - loss: 0.3310 - val_loss: 0.5263\n",
      "Epoch 11/100\n",
      "148148/148148 [==============================] - 58s 388us/step - loss: 0.3095 - val_loss: 0.3112\n",
      "Epoch 12/100\n",
      "148148/148148 [==============================] - 57s 384us/step - loss: 0.2922 - val_loss: 0.3336\n",
      "Epoch 13/100\n",
      "148148/148148 [==============================] - 57s 382us/step - loss: 0.2859 - val_loss: 0.2892\n",
      "Epoch 14/100\n",
      "148148/148148 [==============================] - 57s 385us/step - loss: 0.2614 - val_loss: 0.3363\n",
      "Epoch 15/100\n",
      "148148/148148 [==============================] - 57s 383us/step - loss: 0.2560 - val_loss: 0.3432\n",
      "Epoch 16/100\n",
      "148148/148148 [==============================] - 58s 388us/step - loss: 0.2388 - val_loss: 0.2867\n",
      "Epoch 17/100\n",
      "148148/148148 [==============================] - 56s 378us/step - loss: 0.2346 - val_loss: 0.2894\n",
      "Epoch 18/100\n",
      "148148/148148 [==============================] - 57s 381us/step - loss: 0.2248 - val_loss: 0.2573\n",
      "Epoch 19/100\n",
      "148148/148148 [==============================] - 57s 386us/step - loss: 0.2245 - val_loss: 0.2472\n",
      "Epoch 20/100\n",
      "148148/148148 [==============================] - 57s 383us/step - loss: 0.2130 - val_loss: 0.3570\n",
      "Epoch 21/100\n",
      "148148/148148 [==============================] - 56s 381us/step - loss: 0.2100 - val_loss: 0.3780\n",
      "Epoch 22/100\n",
      "148148/148148 [==============================] - 56s 377us/step - loss: 0.2063 - val_loss: 0.2856\n",
      "Epoch 23/100\n",
      "148148/148148 [==============================] - 56s 378us/step - loss: 0.2006 - val_loss: 0.2593\n",
      "Epoch 24/100\n",
      "148148/148148 [==============================] - 57s 384us/step - loss: 0.1840 - val_loss: 0.2402\n",
      "Epoch 25/100\n",
      "148148/148148 [==============================] - 56s 380us/step - loss: 0.1928 - val_loss: 0.2684\n",
      "Epoch 26/100\n",
      "148148/148148 [==============================] - 56s 380us/step - loss: 0.1872 - val_loss: 0.2627\n",
      "Epoch 27/100\n",
      "148148/148148 [==============================] - 55s 368us/step - loss: 0.1863 - val_loss: 0.2502\n",
      "Epoch 28/100\n",
      "148148/148148 [==============================] - 55s 370us/step - loss: 0.1823 - val_loss: 0.2042\n",
      "Epoch 29/100\n",
      "148148/148148 [==============================] - 56s 377us/step - loss: 0.1723 - val_loss: 0.2382\n",
      "Epoch 30/100\n",
      "148148/148148 [==============================] - 56s 377us/step - loss: 0.1719 - val_loss: 0.2344\n",
      "Epoch 31/100\n",
      "148148/148148 [==============================] - 56s 379us/step - loss: 0.1667 - val_loss: 0.2149\n",
      "Epoch 32/100\n",
      "148148/148148 [==============================] - 56s 378us/step - loss: 0.1804 - val_loss: 0.3072\n",
      "Epoch 33/100\n",
      "148148/148148 [==============================] - 55s 370us/step - loss: 0.1627 - val_loss: 0.2509\n",
      "Epoch 34/100\n",
      "148148/148148 [==============================] - 55s 374us/step - loss: 0.1764 - val_loss: 0.2572\n",
      "Epoch 35/100\n",
      "148148/148148 [==============================] - 54s 362us/step - loss: 0.1622 - val_loss: 0.2116\n",
      "Epoch 36/100\n",
      "148148/148148 [==============================] - 55s 374us/step - loss: 0.1570 - val_loss: 0.4609\n",
      "Epoch 37/100\n",
      "148148/148148 [==============================] - 53s 359us/step - loss: 0.1531 - val_loss: 0.1820\n",
      "Epoch 38/100\n",
      "148148/148148 [==============================] - 54s 364us/step - loss: 0.1611 - val_loss: 0.3581\n",
      "Epoch 39/100\n",
      "148148/148148 [==============================] - 54s 367us/step - loss: 0.1544 - val_loss: 0.2077\n",
      "Epoch 40/100\n",
      "148148/148148 [==============================] - 56s 378us/step - loss: 0.1508 - val_loss: 0.2108\n",
      "Epoch 41/100\n",
      "148148/148148 [==============================] - 55s 371us/step - loss: 0.1526 - val_loss: 0.2179\n",
      "Epoch 42/100\n",
      "148148/148148 [==============================] - 53s 355us/step - loss: 0.1554 - val_loss: 0.2235\n",
      "Epoch 43/100\n",
      "148148/148148 [==============================] - 54s 364us/step - loss: 0.1384 - val_loss: 0.2679\n",
      "Epoch 44/100\n",
      "148148/148148 [==============================] - 53s 359us/step - loss: 0.1451 - val_loss: 0.1874\n",
      "Epoch 45/100\n",
      "148148/148148 [==============================] - 54s 367us/step - loss: 0.1455 - val_loss: 0.1992\n",
      "Epoch 46/100\n",
      "148148/148148 [==============================] - 53s 357us/step - loss: 0.1552 - val_loss: 0.2143\n",
      "Epoch 47/100\n",
      "148148/148148 [==============================] - 53s 357us/step - loss: 0.1416 - val_loss: 0.1720\n",
      "Epoch 48/100\n",
      "148148/148148 [==============================] - 54s 363us/step - loss: 0.1396 - val_loss: 0.2150\n",
      "Epoch 49/100\n",
      "148148/148148 [==============================] - 54s 366us/step - loss: 0.1379 - val_loss: 0.1850\n",
      "Epoch 50/100\n",
      "148148/148148 [==============================] - 52s 349us/step - loss: 0.1343 - val_loss: 0.2046\n",
      "Epoch 51/100\n",
      "148148/148148 [==============================] - 55s 369us/step - loss: 0.1339 - val_loss: 0.1744\n",
      "Epoch 52/100\n",
      "148148/148148 [==============================] - 52s 354us/step - loss: 0.1322 - val_loss: 0.2235\n",
      "Epoch 53/100\n",
      "148148/148148 [==============================] - 54s 364us/step - loss: 0.1349 - val_loss: 0.1783\n",
      "Epoch 54/100\n",
      "148148/148148 [==============================] - 53s 359us/step - loss: 0.1327 - val_loss: 0.2136\n",
      "Epoch 55/100\n",
      "148148/148148 [==============================] - 53s 360us/step - loss: 0.1346 - val_loss: 0.2008\n",
      "Epoch 56/100\n",
      "148148/148148 [==============================] - 54s 363us/step - loss: 0.1385 - val_loss: 0.1644\n",
      "Epoch 57/100\n",
      "148148/148148 [==============================] - 56s 377us/step - loss: 0.1231 - val_loss: 0.1550\n",
      "Epoch 58/100\n",
      "148148/148148 [==============================] - 56s 377us/step - loss: 0.1330 - val_loss: 0.2620\n",
      "Epoch 59/100\n",
      "148148/148148 [==============================] - 55s 373us/step - loss: 0.1292 - val_loss: 0.1831\n",
      "Epoch 60/100\n",
      "148148/148148 [==============================] - 55s 369us/step - loss: 0.1341 - val_loss: 0.2643\n",
      "Epoch 61/100\n",
      "148148/148148 [==============================] - 56s 376us/step - loss: 0.1284 - val_loss: 0.1699\n",
      "Epoch 62/100\n",
      "148148/148148 [==============================] - 56s 376us/step - loss: 0.1258 - val_loss: 0.1976\n",
      "Epoch 63/100\n",
      "148148/148148 [==============================] - 54s 367us/step - loss: 0.1257 - val_loss: 0.1671\n",
      "Epoch 64/100\n",
      "148148/148148 [==============================] - 55s 374us/step - loss: 0.1299 - val_loss: 0.1799\n",
      "Epoch 65/100\n",
      "148148/148148 [==============================] - 54s 367us/step - loss: 0.1237 - val_loss: 0.1826\n",
      "Epoch 66/100\n",
      "148148/148148 [==============================] - 55s 372us/step - loss: 0.1193 - val_loss: 0.1967\n",
      "Epoch 67/100\n",
      "148148/148148 [==============================] - 54s 366us/step - loss: 0.1241 - val_loss: 0.2996\n",
      "Epoch 68/100\n",
      "148148/148148 [==============================] - 54s 365us/step - loss: 0.1184 - val_loss: 0.2471\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 69/100\n",
      "148148/148148 [==============================] - 54s 366us/step - loss: 0.0725 - val_loss: 0.1658\n",
      "Epoch 70/100\n",
      "148148/148148 [==============================] - 54s 362us/step - loss: 0.0725 - val_loss: 0.1449\n",
      "Epoch 71/100\n",
      "148148/148148 [==============================] - 55s 369us/step - loss: 0.0740 - val_loss: 0.1366\n",
      "Epoch 72/100\n",
      "148148/148148 [==============================] - 55s 368us/step - loss: 0.0721 - val_loss: 0.1464\n",
      "Epoch 73/100\n",
      "148148/148148 [==============================] - 55s 374us/step - loss: 0.0730 - val_loss: 0.1530\n",
      "Epoch 74/100\n",
      "148148/148148 [==============================] - 55s 373us/step - loss: 0.0682 - val_loss: 0.1518\n",
      "Epoch 75/100\n",
      "148148/148148 [==============================] - 53s 357us/step - loss: 0.0706 - val_loss: 0.1420\n",
      "Epoch 76/100\n",
      "148148/148148 [==============================] - 53s 359us/step - loss: 0.0731 - val_loss: 0.1340\n",
      "Epoch 77/100\n",
      "148148/148148 [==============================] - 54s 367us/step - loss: 0.0652 - val_loss: 0.1667\n",
      "Epoch 78/100\n",
      "148148/148148 [==============================] - 55s 373us/step - loss: 0.0671 - val_loss: 0.1766\n",
      "Epoch 79/100\n",
      "148148/148148 [==============================] - 55s 370us/step - loss: 0.0686 - val_loss: 0.1568\n",
      "Epoch 80/100\n",
      "148148/148148 [==============================] - 55s 373us/step - loss: 0.0682 - val_loss: 0.1331\n",
      "Epoch 81/100\n",
      "148148/148148 [==============================] - 55s 374us/step - loss: 0.0675 - val_loss: 0.1310\n",
      "Epoch 82/100\n",
      "148148/148148 [==============================] - 56s 378us/step - loss: 0.0655 - val_loss: 0.1665\n",
      "Epoch 83/100\n",
      "148148/148148 [==============================] - 56s 375us/step - loss: 0.0671 - val_loss: 0.1486\n",
      "Epoch 84/100\n",
      "148148/148148 [==============================] - 54s 362us/step - loss: 0.0683 - val_loss: 0.1652\n",
      "Epoch 85/100\n",
      "148148/148148 [==============================] - 55s 369us/step - loss: 0.0680 - val_loss: 0.1744\n",
      "Epoch 86/100\n",
      "148148/148148 [==============================] - 55s 370us/step - loss: 0.0636 - val_loss: 0.1458\n",
      "Epoch 87/100\n",
      "148148/148148 [==============================] - 54s 366us/step - loss: 0.0638 - val_loss: 0.1391\n",
      "Epoch 88/100\n",
      "148148/148148 [==============================] - 54s 363us/step - loss: 0.0669 - val_loss: 0.1356\n",
      "Epoch 89/100\n",
      "148148/148148 [==============================] - 55s 373us/step - loss: 0.0671 - val_loss: 0.1525\n",
      "Epoch 90/100\n",
      "148148/148148 [==============================] - 54s 367us/step - loss: 0.0645 - val_loss: 0.1582\n",
      "Epoch 91/100\n",
      "148148/148148 [==============================] - 55s 374us/step - loss: 0.0638 - val_loss: 0.1268\n",
      "Epoch 92/100\n",
      "148148/148148 [==============================] - 56s 377us/step - loss: 0.0656 - val_loss: 0.1417\n",
      "Epoch 93/100\n",
      "148148/148148 [==============================] - 56s 376us/step - loss: 0.0657 - val_loss: 0.1714\n",
      "Epoch 94/100\n",
      "148148/148148 [==============================] - 54s 365us/step - loss: 0.0639 - val_loss: 0.1329\n",
      "Epoch 95/100\n",
      "148148/148148 [==============================] - 56s 376us/step - loss: 0.0647 - val_loss: 0.1770\n",
      "Epoch 96/100\n",
      "148148/148148 [==============================] - 56s 376us/step - loss: 0.0644 - val_loss: 0.1218\n",
      "Epoch 97/100\n",
      "148148/148148 [==============================] - 55s 373us/step - loss: 0.0640 - val_loss: 0.1436\n",
      "Epoch 98/100\n",
      "148148/148148 [==============================] - 55s 368us/step - loss: 0.0633 - val_loss: 0.1370\n",
      "Epoch 99/100\n",
      "148148/148148 [==============================] - 55s 374us/step - loss: 0.0610 - val_loss: 0.1546\n",
      "Epoch 100/100\n",
      "148148/148148 [==============================] - 55s 370us/step - loss: 0.0615 - val_loss: 0.1518\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, verbose=1, patience=10, min_lr=0.000001)\n",
    "\n",
    "model.fit(X, sum_X, epochs=100, batch_size=128, # Fewer iterations, because each iteration is much more costlier\n",
    "        shuffle=True, validation_split=0.0123456789,\n",
    "        callbacks=[reduce_lr])\n",
    "\n",
    "# save weights\n",
    "lstm_we = []\n",
    "for i in [2,3,4,5,6]:\n",
    "    w = model.get_layer(index=i).get_weights()\n",
    "    lstm_we.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"560pt\" viewBox=\"0.00 0.00 328.00 560.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 556)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-556 324,-556 324,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140713891526808 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140713891526808</title>\n",
       "<polygon fill=\"none\" points=\"32,-505 32,-551 288,-551 288,-505 32,-505\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-524.3\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"157,-505 157,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-535.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157,-528 212,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-512.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"212,-505 212,-551 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-535.8\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"212,-528 288,-528 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-512.8\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 140713891525352 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140713891525352</title>\n",
       "<polygon fill=\"none\" points=\"0,-421 0,-467 320,-467 320,-421 0,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-440.3\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-421 161,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-444 216,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-421 216,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-451.8\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"216,-444 320,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-428.8\">(None, 10, 784)</text>\n",
       "</g>\n",
       "<!-- 140713891526808&#45;&gt;140713891525352 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140713891526808-&gt;140713891525352</title>\n",
       "<path d=\"M160,-504.593C160,-496.118 160,-486.297 160,-477.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-477.096 160,-467.096 156.5,-477.096 163.5,-477.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140713891524680 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140713891524680</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-337 29.5,-383 290.5,-383 290.5,-337 29.5,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-356.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-337 131.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-360 186.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-337 186.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-367.8\">(None, 10, 784)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-360 290.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-344.8\">(None, 10, 300)</text>\n",
       "</g>\n",
       "<!-- 140713891525352&#45;&gt;140713891524680 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140713891525352-&gt;140713891524680</title>\n",
       "<path d=\"M160,-420.593C160,-412.118 160,-402.297 160,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-393.096 160,-383.096 156.5,-393.096 163.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140714160077736 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140714160077736</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-253 29.5,-299 290.5,-299 290.5,-253 29.5,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-272.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-253 131.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131.5,-276 186.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-253 186.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-283.8\">(None, 10, 300)</text>\n",
       "<polyline fill=\"none\" points=\"186.5,-276 290.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-260.8\">(None, 10, 100)</text>\n",
       "</g>\n",
       "<!-- 140713891524680&#45;&gt;140714160077736 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140713891524680-&gt;140714160077736</title>\n",
       "<path d=\"M160,-336.593C160,-328.118 160,-318.297 160,-309.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-309.096 160,-299.096 156.5,-309.096 163.5,-309.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140710142024560 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140710142024560</title>\n",
       "<polygon fill=\"none\" points=\"38.5,-169 38.5,-215 281.5,-215 281.5,-169 38.5,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-188.3\">gru_1: GRU</text>\n",
       "<polyline fill=\"none\" points=\"122.5,-169 122.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"122.5,-192 177.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"177.5,-169 177.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-199.8\">(None, 10, 100)</text>\n",
       "<polyline fill=\"none\" points=\"177.5,-192 281.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-176.8\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 140714160077736&#45;&gt;140710142024560 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140714160077736-&gt;140710142024560</title>\n",
       "<path d=\"M160,-252.593C160,-244.118 160,-234.297 160,-225.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-225.096 160,-215.096 156.5,-225.096 163.5,-225.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140714159006216 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140714159006216</title>\n",
       "<polygon fill=\"none\" points=\"43.5,-85 43.5,-131 276.5,-131 276.5,-85 43.5,-85\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-104.3\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-85 145.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-115.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-108 200.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-92.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-85 200.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-115.8\">(None, 50)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-108 276.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-92.8\">(None, 30)</text>\n",
       "</g>\n",
       "<!-- 140710142024560&#45;&gt;140714159006216 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140710142024560-&gt;140714159006216</title>\n",
       "<path d=\"M160,-168.593C160,-160.118 160,-150.297 160,-141.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-141.096 160,-131.096 156.5,-141.096 163.5,-141.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140714159173528 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140714159173528</title>\n",
       "<polygon fill=\"none\" points=\"43.5,-1 43.5,-47 276.5,-47 276.5,-1 43.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-20.3\">dense_4: Dense</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-1 145.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-31.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"145.5,-24 200.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173\" y=\"-8.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-1 200.5,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-31.8\">(None, 30)</text>\n",
       "<polyline fill=\"none\" points=\"200.5,-24 276.5,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-8.8\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140714159006216&#45;&gt;140714159173528 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140714159006216-&gt;140714159173528</title>\n",
       "<path d=\"M160,-84.5931C160,-76.1177 160,-66.2974 160,-57.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-57.0958 160,-47.0959 156.5,-57.0959 163.5,-57.0958\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "K.clear_session()\n",
    "model = get_gru_model(img, max_train_length)\n",
    "\n",
    "# visualize\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 148148 samples, validate on 1852 samples\n",
      "Epoch 1/100\n",
      "148148/148148 [==============================] - 48s 325us/step - loss: 8.7294 - val_loss: 3.1632\n",
      "Epoch 2/100\n",
      "148148/148148 [==============================] - 48s 321us/step - loss: 1.8614 - val_loss: 1.2922\n",
      "Epoch 3/100\n",
      "148148/148148 [==============================] - 49s 333us/step - loss: 0.9580 - val_loss: 0.8394\n",
      "Epoch 4/100\n",
      "148148/148148 [==============================] - 50s 336us/step - loss: 0.6991 - val_loss: 0.9716\n",
      "Epoch 5/100\n",
      "148148/148148 [==============================] - 47s 320us/step - loss: 0.5808 - val_loss: 0.5831\n",
      "Epoch 6/100\n",
      "148148/148148 [==============================] - 48s 321us/step - loss: 0.4906 - val_loss: 0.6009\n",
      "Epoch 7/100\n",
      "148148/148148 [==============================] - 47s 317us/step - loss: 0.4418 - val_loss: 0.4104\n",
      "Epoch 8/100\n",
      "148148/148148 [==============================] - 46s 313us/step - loss: 0.4017 - val_loss: 0.4339\n",
      "Epoch 9/100\n",
      "148148/148148 [==============================] - 46s 309us/step - loss: 0.3584 - val_loss: 0.4026\n",
      "Epoch 10/100\n",
      "148148/148148 [==============================] - 45s 303us/step - loss: 0.3323 - val_loss: 0.3695\n",
      "Epoch 11/100\n",
      "148148/148148 [==============================] - 46s 307us/step - loss: 0.3177 - val_loss: 0.3335\n",
      "Epoch 12/100\n",
      "148148/148148 [==============================] - 47s 315us/step - loss: 0.2993 - val_loss: 0.4430\n",
      "Epoch 13/100\n",
      "148148/148148 [==============================] - 47s 318us/step - loss: 0.2843 - val_loss: 0.3253\n",
      "Epoch 14/100\n",
      "148148/148148 [==============================] - 48s 325us/step - loss: 0.2801 - val_loss: 0.3007\n",
      "Epoch 15/100\n",
      "148148/148148 [==============================] - 45s 305us/step - loss: 0.2562 - val_loss: 0.3073\n",
      "Epoch 16/100\n",
      "148148/148148 [==============================] - 46s 313us/step - loss: 0.2416 - val_loss: 0.4806\n",
      "Epoch 17/100\n",
      "148148/148148 [==============================] - 46s 311us/step - loss: 0.2372 - val_loss: 0.2879\n",
      "Epoch 18/100\n",
      "148148/148148 [==============================] - 48s 322us/step - loss: 0.2336 - val_loss: 0.2866\n",
      "Epoch 19/100\n",
      "148148/148148 [==============================] - 48s 321us/step - loss: 0.2340 - val_loss: 0.2941\n",
      "Epoch 20/100\n",
      "148148/148148 [==============================] - 47s 319us/step - loss: 0.2120 - val_loss: 0.2392\n",
      "Epoch 21/100\n",
      "148148/148148 [==============================] - 46s 313us/step - loss: 0.2196 - val_loss: 0.2627\n",
      "Epoch 22/100\n",
      "148148/148148 [==============================] - 46s 309us/step - loss: 0.2025 - val_loss: 0.2399\n",
      "Epoch 23/100\n",
      "148148/148148 [==============================] - 47s 317us/step - loss: 0.1992 - val_loss: 0.2629\n",
      "Epoch 24/100\n",
      "148148/148148 [==============================] - 47s 315us/step - loss: 0.2027 - val_loss: 0.2649\n",
      "Epoch 25/100\n",
      "148148/148148 [==============================] - 48s 323us/step - loss: 0.1886 - val_loss: 0.2442\n",
      "Epoch 26/100\n",
      "148148/148148 [==============================] - 47s 316us/step - loss: 0.1856 - val_loss: 0.2451\n",
      "Epoch 27/100\n",
      "148148/148148 [==============================] - 46s 311us/step - loss: 0.1807 - val_loss: 0.2616\n",
      "Epoch 28/100\n",
      "148148/148148 [==============================] - 45s 306us/step - loss: 0.1919 - val_loss: 0.2360\n",
      "Epoch 29/100\n",
      "148148/148148 [==============================] - 47s 316us/step - loss: 0.1727 - val_loss: 0.2030\n",
      "Epoch 30/100\n",
      "148148/148148 [==============================] - 47s 318us/step - loss: 0.1804 - val_loss: 0.1995\n",
      "Epoch 31/100\n",
      "148148/148148 [==============================] - 47s 320us/step - loss: 0.1820 - val_loss: 0.2635\n",
      "Epoch 32/100\n",
      "148148/148148 [==============================] - 49s 332us/step - loss: 0.1757 - val_loss: 0.2198\n",
      "Epoch 33/100\n",
      "148148/148148 [==============================] - 49s 334us/step - loss: 0.1710 - val_loss: 0.6316\n",
      "Epoch 34/100\n",
      "148148/148148 [==============================] - 49s 332us/step - loss: 0.1693 - val_loss: 0.3093\n",
      "Epoch 35/100\n",
      "148148/148148 [==============================] - 49s 331us/step - loss: 0.1626 - val_loss: 0.2939\n",
      "Epoch 36/100\n",
      "148148/148148 [==============================] - 49s 331us/step - loss: 0.1629 - val_loss: 0.1954\n",
      "Epoch 37/100\n",
      "148148/148148 [==============================] - 49s 331us/step - loss: 0.1605 - val_loss: 0.1993\n",
      "Epoch 38/100\n",
      "148148/148148 [==============================] - 49s 333us/step - loss: 0.1616 - val_loss: 0.2724\n",
      "Epoch 39/100\n",
      "148148/148148 [==============================] - 49s 328us/step - loss: 0.1671 - val_loss: 0.2485\n",
      "Epoch 40/100\n",
      "148148/148148 [==============================] - 49s 334us/step - loss: 0.1513 - val_loss: 0.1905\n",
      "Epoch 41/100\n",
      "148148/148148 [==============================] - 49s 329us/step - loss: 0.1546 - val_loss: 0.1918\n",
      "Epoch 42/100\n",
      "148148/148148 [==============================] - 49s 333us/step - loss: 0.1610 - val_loss: 0.3659\n",
      "Epoch 43/100\n",
      "148148/148148 [==============================] - 49s 330us/step - loss: 0.1566 - val_loss: 0.2045\n",
      "Epoch 44/100\n",
      "148148/148148 [==============================] - 49s 333us/step - loss: 0.1549 - val_loss: 0.2511\n",
      "Epoch 45/100\n",
      "148148/148148 [==============================] - 49s 332us/step - loss: 0.1560 - val_loss: 0.2607\n",
      "Epoch 46/100\n",
      "148148/148148 [==============================] - 49s 331us/step - loss: 0.1510 - val_loss: 0.2136\n",
      "Epoch 47/100\n",
      "148148/148148 [==============================] - 49s 334us/step - loss: 0.1551 - val_loss: 0.2364\n",
      "Epoch 48/100\n",
      "148148/148148 [==============================] - 46s 309us/step - loss: 0.1395 - val_loss: 0.2844\n",
      "Epoch 49/100\n",
      "148148/148148 [==============================] - 48s 321us/step - loss: 0.1572 - val_loss: 0.3262\n",
      "Epoch 50/100\n",
      "148148/148148 [==============================] - 48s 324us/step - loss: 0.1451 - val_loss: 0.2127\n",
      "Epoch 51/100\n",
      "148148/148148 [==============================] - 48s 324us/step - loss: 0.1464 - val_loss: 0.2607\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 52/100\n",
      "148148/148148 [==============================] - 50s 335us/step - loss: 0.0857 - val_loss: 0.1595\n",
      "Epoch 53/100\n",
      "148148/148148 [==============================] - 50s 334us/step - loss: 0.0891 - val_loss: 0.1549\n",
      "Epoch 54/100\n",
      "148148/148148 [==============================] - 49s 331us/step - loss: 0.0886 - val_loss: 0.1582\n",
      "Epoch 55/100\n",
      "148148/148148 [==============================] - 48s 322us/step - loss: 0.0894 - val_loss: 0.1896\n",
      "Epoch 56/100\n",
      "148148/148148 [==============================] - 47s 316us/step - loss: 0.0853 - val_loss: 0.1694\n",
      "Epoch 57/100\n",
      "148148/148148 [==============================] - 47s 315us/step - loss: 0.0871 - val_loss: 0.1643\n",
      "Epoch 58/100\n",
      "148148/148148 [==============================] - 48s 321us/step - loss: 0.0819 - val_loss: 0.2357\n",
      "Epoch 59/100\n",
      "148148/148148 [==============================] - 47s 319us/step - loss: 0.0889 - val_loss: 0.1863\n",
      "Epoch 60/100\n",
      "148148/148148 [==============================] - 47s 318us/step - loss: 0.0863 - val_loss: 0.1545\n",
      "Epoch 61/100\n",
      "148148/148148 [==============================] - 47s 314us/step - loss: 0.0835 - val_loss: 0.1977\n",
      "Epoch 62/100\n",
      "148148/148148 [==============================] - 46s 311us/step - loss: 0.0822 - val_loss: 0.2196\n",
      "Epoch 63/100\n",
      "148148/148148 [==============================] - 47s 319us/step - loss: 0.0819 - val_loss: 0.1653\n",
      "Epoch 64/100\n",
      "148148/148148 [==============================] - 46s 311us/step - loss: 0.0831 - val_loss: 0.1916\n",
      "Epoch 65/100\n",
      "148148/148148 [==============================] - 47s 319us/step - loss: 0.0809 - val_loss: 0.2300\n",
      "Epoch 66/100\n",
      "148148/148148 [==============================] - 46s 308us/step - loss: 0.0778 - val_loss: 0.1746\n",
      "Epoch 67/100\n",
      "148148/148148 [==============================] - 46s 310us/step - loss: 0.0815 - val_loss: 0.1678\n",
      "Epoch 68/100\n",
      "148148/148148 [==============================] - 46s 313us/step - loss: 0.0787 - val_loss: 0.1924\n",
      "Epoch 69/100\n",
      "148148/148148 [==============================] - 48s 323us/step - loss: 0.0790 - val_loss: 0.1616\n",
      "Epoch 70/100\n",
      "148148/148148 [==============================] - 46s 310us/step - loss: 0.0758 - val_loss: 0.1724\n",
      "Epoch 71/100\n",
      "148148/148148 [==============================] - 46s 313us/step - loss: 0.0783 - val_loss: 0.1750\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 72/100\n",
      "148148/148148 [==============================] - 46s 308us/step - loss: 0.0572 - val_loss: 0.1503\n",
      "Epoch 73/100\n",
      "148148/148148 [==============================] - 47s 320us/step - loss: 0.0565 - val_loss: 0.1476\n",
      "Epoch 74/100\n",
      "148148/148148 [==============================] - 46s 312us/step - loss: 0.0570 - val_loss: 0.1459\n",
      "Epoch 75/100\n",
      "148148/148148 [==============================] - 47s 318us/step - loss: 0.0559 - val_loss: 0.1452\n",
      "Epoch 76/100\n",
      "148148/148148 [==============================] - 47s 315us/step - loss: 0.0562 - val_loss: 0.1602\n",
      "Epoch 77/100\n",
      "148148/148148 [==============================] - 44s 300us/step - loss: 0.0549 - val_loss: 0.1466\n",
      "Epoch 78/100\n",
      "148148/148148 [==============================] - 46s 313us/step - loss: 0.0563 - val_loss: 0.1469\n",
      "Epoch 79/100\n",
      "148148/148148 [==============================] - 46s 307us/step - loss: 0.0545 - val_loss: 0.1481\n",
      "Epoch 80/100\n",
      "148148/148148 [==============================] - 48s 322us/step - loss: 0.0541 - val_loss: 0.1373\n",
      "Epoch 81/100\n",
      "148148/148148 [==============================] - 47s 319us/step - loss: 0.0551 - val_loss: 0.1617\n",
      "Epoch 82/100\n",
      "148148/148148 [==============================] - 47s 314us/step - loss: 0.0541 - val_loss: 0.1489\n",
      "Epoch 83/100\n",
      "148148/148148 [==============================] - 46s 310us/step - loss: 0.0541 - val_loss: 0.1422\n",
      "Epoch 84/100\n",
      "148148/148148 [==============================] - 48s 322us/step - loss: 0.0534 - val_loss: 0.1528\n",
      "Epoch 85/100\n",
      "148148/148148 [==============================] - 46s 311us/step - loss: 0.0527 - val_loss: 0.1451\n",
      "Epoch 86/100\n",
      "148148/148148 [==============================] - 46s 314us/step - loss: 0.0525 - val_loss: 0.1437\n",
      "Epoch 87/100\n",
      "148148/148148 [==============================] - 45s 305us/step - loss: 0.0531 - val_loss: 0.1645\n",
      "Epoch 88/100\n",
      "148148/148148 [==============================] - 46s 314us/step - loss: 0.0542 - val_loss: 0.1663\n",
      "Epoch 89/100\n",
      "148148/148148 [==============================] - 47s 317us/step - loss: 0.0518 - val_loss: 0.1398\n",
      "Epoch 90/100\n",
      "148148/148148 [==============================] - 46s 307us/step - loss: 0.0530 - val_loss: 0.1461\n",
      "Epoch 91/100\n",
      "148148/148148 [==============================] - 47s 318us/step - loss: 0.0520 - val_loss: 0.1495\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 92/100\n",
      "148148/148148 [==============================] - 47s 318us/step - loss: 0.0430 - val_loss: 0.1393\n",
      "Epoch 93/100\n",
      "148148/148148 [==============================] - 47s 319us/step - loss: 0.0428 - val_loss: 0.1393\n",
      "Epoch 94/100\n",
      "148148/148148 [==============================] - 49s 328us/step - loss: 0.0428 - val_loss: 0.1353\n",
      "Epoch 95/100\n",
      "148148/148148 [==============================] - 49s 333us/step - loss: 0.0430 - val_loss: 0.1347\n",
      "Epoch 96/100\n",
      "148148/148148 [==============================] - 49s 332us/step - loss: 0.0421 - val_loss: 0.1441\n",
      "Epoch 97/100\n",
      "148148/148148 [==============================] - 49s 334us/step - loss: 0.0425 - val_loss: 0.1383\n",
      "Epoch 98/100\n",
      "148148/148148 [==============================] - 49s 329us/step - loss: 0.0419 - val_loss: 0.1382\n",
      "Epoch 99/100\n",
      "148148/148148 [==============================] - 49s 327us/step - loss: 0.0418 - val_loss: 0.1369\n",
      "Epoch 100/100\n",
      "148148/148148 [==============================] - 50s 334us/step - loss: 0.0418 - val_loss: 0.1395\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, verbose=1, patience=10, min_lr=0.000001)\n",
    "\n",
    "model.fit(X, sum_X, epochs=100, batch_size=128, # Fewer iterations, because each iteration is much more costlier\n",
    "        shuffle=True, validation_split=0.0123456789,\n",
    "        callbacks=[reduce_lr])\n",
    "\n",
    "# save weights\n",
    "gru_we = []\n",
    "for i in [2,3,4,5,6]:\n",
    "    w = model.get_layer(index=i).get_weights()\n",
    "    gru_we.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  5\n",
      "10000/10000 [==============================] - 0s 14us/step\n",
      "10000/10000 [==============================] - 1s 65us/step\n",
      "10000/10000 [==============================] - 1s 55us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:40<06:06, 40.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  10\n",
      "10000/10000 [==============================] - 0s 15us/step\n",
      "10000/10000 [==============================] - 1s 99us/step\n",
      "10000/10000 [==============================] - 1s 88us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:37<06:31, 48.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  15\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "10000/10000 [==============================] - 1s 136us/step\n",
      "10000/10000 [==============================] - 1s 122us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [02:17<05:20, 45.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  20\n",
      "10000/10000 [==============================] - 0s 19us/step\n",
      "10000/10000 [==============================] - 2s 178us/step\n",
      "10000/10000 [==============================] - 2s 154us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [03:21<05:02, 50.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  25\n",
      "10000/10000 [==============================] - 0s 22us/step\n",
      "10000/10000 [==============================] - 2s 219us/step\n",
      "10000/10000 [==============================] - 2s 184us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [04:22<04:22, 52.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  30\n",
      "10000/10000 [==============================] - 0s 23us/step\n",
      "10000/10000 [==============================] - 3s 253us/step\n",
      "10000/10000 [==============================] - 2s 223us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [04:46<03:10, 47.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  35\n",
      "10000/10000 [==============================] - 0s 24us/step\n",
      "10000/10000 [==============================] - 3s 290us/step\n",
      "10000/10000 [==============================] - 3s 263us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [05:19<02:17, 45.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  40\n",
      "10000/10000 [==============================] - 0s 25us/step\n",
      "10000/10000 [==============================] - 3s 339us/step\n",
      "10000/10000 [==============================] - 3s 296us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [06:39<01:39, 49.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  45\n",
      "10000/10000 [==============================] - 0s 28us/step\n",
      "10000/10000 [==============================] - 4s 374us/step\n",
      "10000/10000 [==============================] - 3s 327us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [07:57<00:53, 53.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating at length:  50\n",
      "10000/10000 [==============================] - 0s 30us/step\n",
      "10000/10000 [==============================] - 4s 404us/step\n",
      "10000/10000 [==============================] - 3s 336us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:39<00:00, 51.92s/it]\n"
     ]
    }
   ],
   "source": [
    "metrics = {'deepsets': {'acc':[], 'mae':[], 'mse':[]}, 'lstm': {'acc':[],'mae':[], 'mse':[]}, 'gru': {'acc':[],'mae':[], 'mse':[]}}\n",
    "\n",
    "lengths = range(min_test_length, max_test_length, step_test_length)\n",
    "for l in tqdm(lengths):\n",
    "    print('Evaluating at length: ', l)\n",
    "    # generate test data\n",
    "    img, Y, sum_Y = gen_test_data(num_test_examples, l)\n",
    "\n",
    "    # model\n",
    "    K.clear_session()\n",
    "    model = get_deepset_model(img, l)\n",
    "\n",
    "    # load weights\n",
    "    for i, idx in enumerate([2,3,4,6]):\n",
    "        model.get_layer(index=idx).set_weights(deep_we[i])\n",
    "\n",
    "    # prediction\n",
    "    preds = model.predict(Y, batch_size=128, verbose=1)\n",
    "    metrics['deepsets']['acc'].append(1.0*np.sum(np.squeeze(np.round(preds))==sum_Y)/len(sum_Y))\n",
    "    metrics['deepsets']['mae'].append(1.0*np.sum(np.abs(np.squeeze(preds)-sum_Y))/len(sum_Y))\n",
    "    metrics['deepsets']['mse'].append(np.dot(np.squeeze(preds)-sum_Y, np.squeeze(preds)-sum_Y)/len(sum_Y))\n",
    "    \n",
    "    # model\n",
    "    K.clear_session()\n",
    "    model = get_lstm_model(img, l)\n",
    "\n",
    "    # load weights\n",
    "    for i, idx in enumerate([2,3,4,5,6]):\n",
    "        model.get_layer(index=idx).set_weights(lstm_we[i])\n",
    "\n",
    "    # prediction\n",
    "    preds = model.predict(Y, batch_size=128, verbose=1)\n",
    "    metrics['lstm']['acc'].append(1.0*np.sum(np.squeeze(np.round(preds))==sum_Y)/len(sum_Y))\n",
    "    metrics['lstm']['mae'].append(1.0*np.sum(np.abs(np.squeeze(preds)-sum_Y))/len(sum_Y))\n",
    "    metrics['lstm']['mse'].append(np.dot(np.squeeze(preds)-sum_Y, np.squeeze(preds)-sum_Y)/len(sum_Y))\n",
    "    \n",
    "    # model\n",
    "    K.clear_session()\n",
    "    model = get_gru_model(img, l)\n",
    "\n",
    "    # load weights\n",
    "    for i, idx in enumerate([2,3,4,5,6]):\n",
    "        model.get_layer(index=idx).set_weights(gru_we[i])\n",
    "\n",
    "    # prediction\n",
    "    preds = model.predict(Y, batch_size=128, verbose=1)\n",
    "    metrics['gru']['acc'].append(1.0*np.sum(np.squeeze(np.round(preds))==sum_Y)/len(sum_Y))\n",
    "    metrics['gru']['mae'].append(1.0*np.sum(np.abs(np.squeeze(preds)-sum_Y))/len(sum_Y))\n",
    "    metrics['gru']['mse'].append(np.dot(np.squeeze(preds)-sum_Y, np.squeeze(preds)-sum_Y)/len(sum_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9a1c55c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "scale = 0.5\n",
    "plt.figure(figsize=(10*scale, 8*scale))\n",
    "\n",
    "plt.plot(lengths, metrics['deepsets']['acc'], 'o-')\n",
    "plt.plot(lengths, metrics['lstm']['acc'], 'o-')\n",
    "plt.plot(lengths, metrics['gru']['acc'], 'o-')\n",
    "plt.xlabel('Number of digits to add')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim( 0, 1.1 )\n",
    "plt.xlim( 5, 50 )\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['Deepsets', 'LSTM', 'GRU'], fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa75ffcba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "scale = 0.5\n",
    "plt.figure(figsize=(10*scale, 8*scale))\n",
    "\n",
    "plt.plot(lengths, np.array(metrics['deepsets']['mae'])/1e2, 'x-')\n",
    "plt.plot(lengths, np.array(metrics['lstm']['mae'])/1e2, 'x-')\n",
    "plt.plot(lengths, np.array(metrics['gru']['mae'])/1e2, 'x-')\n",
    "plt.xlabel('Number of digits to add')\n",
    "plt.ylabel('Mean absolute error/1e4')\n",
    "plt.title('MAE')\n",
    "plt.legend(['Deepsets', 'LSTM', 'GRU'], fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa915f82e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "font = {'size': 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "scale = 0.5\n",
    "plt.figure(figsize=(10*scale, 8*scale))\n",
    "\n",
    "plt.plot(lengths, np.array(metrics['deepsets']['mse'])/1e4, 'x-')\n",
    "plt.plot(lengths, np.array(metrics['lstm']['mse'])/1e4, 'x-')\n",
    "plt.plot(lengths, np.array(metrics['gru']['mse'])/1e4, 'x-')\n",
    "plt.xlabel('Number of digits to add')\n",
    "plt.ylabel('Mean square error/1e4')\n",
    "plt.title('MSE')\n",
    "plt.legend(['Deepsets', 'LSTM', 'GRU'], fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}