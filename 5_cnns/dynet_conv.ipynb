{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import dynet as dy\n",
    "\n",
    "LENGTH = 8\n",
    "PATTERN = np.array([1,0,1])\n",
    "FILTER_LENGTH = len(PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 2 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 1 1 2 2 1 2 1 1 0 0 0 0 1 2 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 1 1 1 1 2 3 2 2 1 1 2 2 1 2 1 1 0 0 0 0 0 1 0 0 1 1 2 2 1 2 1\n",
      " 1 0 0 0 0 1 2 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0\n",
      " 1 2 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 2 1 1 2 2 3 3 2 3 2 2 1 1 1 1 2 3 2 2 1\n",
      " 1 2 2 1 2 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 2 3 2 2 1 1 2 2 1 2\n",
      " 1 1 0 0 0 0 0 1 0 0 1 1 2 2 1 2 1 1 0 0 0 0 1 2 1 1 0 0 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "binary_arrays = np.array(list(itertools.product([0,1], repeat=LENGTH)))\n",
    "\n",
    "get_number_of_occur = lambda test_list: len([PATTERN for idx in range(len(test_list)-len(PATTERN)+1) if (test_list[idx : idx + len(PATTERN)] == PATTERN).all()])\n",
    "occurences_arrays = np.array(list(map(get_number_of_occur, binary_arrays)))\n",
    "print(occurences_arrays)\n",
    "\n",
    "# print(''.join(list(map(str,binary_arrays[0]))))\n",
    "# replace_101_202 = lambda test_list: list(map(int, re.sub('101', '909', ''.join(list(map(str, test_list))))))\n",
    "# binary_arrays = np.array(list(map(replace_101_202, binary_arrays))) / 9\n",
    "# print(binary_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 0, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 1, 0, 1, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero_arrays = binary_arrays[occurences_arrays == 0]\n",
    "display(zero_arrays[:10])\n",
    "display((occurences_arrays == 0).sum())\n",
    "one_arrays = binary_arrays[occurences_arrays == 1]\n",
    "display(one_arrays[:10])\n",
    "display((occurences_arrays == 1).sum())\n",
    "two_arrays = binary_arrays[occurences_arrays == 2]\n",
    "display(two_arrays[:10])\n",
    "display((occurences_arrays == 2).sum())\n",
    "three_arrays = binary_arrays[occurences_arrays == 3]\n",
    "display((occurences_arrays == 3).sum())\n",
    "four_arrays = binary_arrays[occurences_arrays == 4]\n",
    "display((occurences_arrays == 4).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_X_train, zero_X_test, zero_y_train, zero_y_test = train_test_split(zero_arrays, np.zeros((len(zero_arrays),)), test_size=0.3, random_state=42)\n",
    "# one_X_train, one_X_test, one_y_train, one_y_test = train_test_split(one_arrays, np.ones((len(one_arrays))), test_size=0.3, random_state=42)\n",
    "# two_X_train, two_X_test, two_y_train, two_y_test = train_test_split(two_arrays, np.ones((len(two_arrays))), test_size=0.3, random_state=42)\n",
    "# three_X_train, three_X_test, three_y_train, three_y_test = train_test_split(three_arrays, np.ones((len(three_arrays))), test_size=0.3, random_state=42)\n",
    "zero_X_train = zero_X_test = zero_arrays\n",
    "zero_y_train = zero_y_test = np.zeros((len(zero_X_train)), dtype=int)\n",
    "one_X_train = one_X_test = one_arrays\n",
    "one_y_train = one_y_test = np.ones((len(one_X_train)), dtype=int)\n",
    "two_X_train = two_X_test = two_arrays\n",
    "two_y_train = two_y_test = np.ones((len(two_arrays)), dtype=int)\n",
    "\n",
    "X_train = np.concatenate((zero_X_train, one_X_train), axis=0)\n",
    "y_train = np.concatenate((zero_y_train, one_y_train), axis=0)\n",
    "# X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "\n",
    "X_test = np.concatenate((zero_X_test, one_X_test), axis=0)\n",
    "y_test = np.concatenate((zero_y_test, one_y_test), axis=0)\n",
    "# X_test, y_test = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,0,0,0,1,0,1,0],\n",
    "        [1,1,0,1,0,0,0,0],\n",
    "        [1,0,0,0,0,0,1,0],\n",
    "        [0,1,0,0,0,1,0,0],\n",
    "        [0,0,1,0,1,0,1,0],\n",
    "        [0,0,0,0,0,0,1,0],\n",
    "        [0,1,0,1,0,0,0,1],\n",
    "        [1,0,0,0,0,0,0,1],\n",
    "        [1,1,0,0,1,0,1,0],\n",
    "        [1,1,0,1,0,0,1,1],\n",
    "        [1,0,0,0,0,0,1,1],\n",
    "        [0,1,0,0,0,1,1,0],\n",
    "        [0,0,1,0,1,0,1,0],\n",
    "        [0,1,0,0,0,1,0,0],\n",
    "        [0,1,0,1,0,1,0,0],\n",
    "        [1,0,0,0,0,0,1,1]]\n",
    "labels = [1,1,0,0,1,0,1,0,1,1,0,0,1,0,1,0]\n",
    "\n",
    "X_train = X_test = np.array(data)\n",
    "y_train = y_test = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[0.8,0.2,0.1,0.05,1,0,1,0.05],\n",
    "        [0.23,0.98,0,0.99,0.1,0.2,0.15,0.02],\n",
    "        [0.7,0.1,0.2,0.3,0.21,0.1,0.8,0.2],\n",
    "        [0.2,0.8,0.1,0.1,0,0.9,0.15,0.12],\n",
    "        [0,0.2,0.95,0.05,1,0,1,0.05],\n",
    "        [0.2,0.2,0.2,0.2,0.01,0.2,0.8,0.1],\n",
    "        [0.1,1,0,1,0.1,0.15,0.2,1],\n",
    "        [1,0.11,0.32,0.1,0.001,0.02,0.05,0.85],\n",
    "        [0.2,0.68,0.02,0.08,1,0,1,0.02],\n",
    "        [0.98,1,0,1,0.01,0.02,0.75,0.1],\n",
    "        [0.32,0.2,0.1,0.2,0.15,0.01,0.25,0.36],\n",
    "        [0.08,0.5,0.12,0.01,0.1,0.05,0.76,0.2],\n",
    "        [0.12,0.32,0.34,0.12,0.68,0.64,0.55,0.44],\n",
    "        [0.01,0.97,0.01,0.98,0.1,0.2,0.1,0.01],\n",
    "        [0,1,0.12,0.98,0.01,0.96,0.01,0.02],\n",
    "        [0.88,0.2,0.2,0.1,0.01,0.01,0.7,0.7]]\n",
    "labels = [1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,0]\n",
    "\n",
    "X_train = X_test = np.array(data)\n",
    "y_train = y_test = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8  , 0.2  , 0.1  , 0.05 , 1.   , 0.   , 1.   , 0.05 ],\n",
       "       [0.23 , 0.98 , 0.   , 0.99 , 0.1  , 0.2  , 0.15 , 0.02 ],\n",
       "       [0.7  , 0.1  , 0.2  , 0.3  , 0.21 , 0.1  , 0.8  , 0.2  ],\n",
       "       [0.2  , 0.8  , 0.1  , 0.1  , 0.   , 0.9  , 0.15 , 0.12 ],\n",
       "       [0.   , 0.2  , 0.95 , 0.05 , 1.   , 0.   , 1.   , 0.05 ],\n",
       "       [0.2  , 0.2  , 0.2  , 0.2  , 0.01 , 0.2  , 0.8  , 0.1  ],\n",
       "       [0.1  , 1.   , 0.   , 1.   , 0.1  , 0.15 , 0.2  , 1.   ],\n",
       "       [1.   , 0.11 , 0.32 , 0.1  , 0.001, 0.02 , 0.05 , 0.85 ],\n",
       "       [0.2  , 0.68 , 0.02 , 0.08 , 1.   , 0.   , 1.   , 0.02 ],\n",
       "       [0.98 , 1.   , 0.   , 1.   , 0.01 , 0.02 , 0.75 , 0.1  ],\n",
       "       [0.32 , 0.2  , 0.1  , 0.2  , 0.15 , 0.01 , 0.25 , 0.36 ],\n",
       "       [0.08 , 0.5  , 0.12 , 0.01 , 0.1  , 0.05 , 0.76 , 0.2  ],\n",
       "       [0.12 , 0.32 , 0.34 , 0.12 , 0.68 , 0.64 , 0.55 , 0.44 ],\n",
       "       [0.01 , 0.97 , 0.01 , 0.98 , 0.1  , 0.2  , 0.1  , 0.01 ],\n",
       "       [0.   , 1.   , 0.12 , 0.98 , 0.01 , 0.96 , 0.01 , 0.02 ],\n",
       "       [0.88 , 0.2  , 0.2  , 0.1  , 0.01 , 0.01 , 0.7  , 0.7  ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVOLUTION_OUTPUT_LEN = LENGTH - FILTER_LENGTH + 1\n",
    "POOLING_SIZE = 4\n",
    "POOLING_OUTPUT_LEN = math.ceil(CONVOLUTION_OUTPUT_LEN / POOLING_SIZE)\n",
    "\n",
    "model = dy.ParameterCollection()\n",
    "conv_filter = model.add_parameters(FILTER_LENGTH)\n",
    "conv_bias = model.add_parameters(1)\n",
    "# conv_filter = model.add_parameters(FILTER_LENGTH, init='uniform', scale=1)\n",
    "\n",
    "dense_params = model.add_parameters(POOLING_OUTPUT_LEN)\n",
    "dense_bias = model.add_parameters(1)\n",
    "trainer = dy.AdamTrainer(model, alpha=0.01)\n",
    "\n",
    "\n",
    "def renew():\n",
    "    dy.renew_cg()\n",
    "\n",
    "    # trainer = dy.SimpleSGDTrainer(model, learning_rate=0.001)\n",
    "    x = dy.vecInput(LENGTH)\n",
    "    y = dy.scalarInput(0)\n",
    "\n",
    "    convoluted = [0 for _ in range(CONVOLUTION_OUTPUT_LEN)]\n",
    "    for i in range(CONVOLUTION_OUTPUT_LEN):\n",
    "        convoluted[i] = (dy.transpose(conv_filter) * x[i:i+FILTER_LENGTH])[0] + conv_bias\n",
    "\n",
    "    pooled = [0 for _ in range(POOLING_OUTPUT_LEN)]\n",
    "    for i in range(POOLING_OUTPUT_LEN):\n",
    "        pooled[i] = np.mean(convoluted[POOLING_SIZE*i:POOLING_SIZE*(i+1)])\n",
    "    y_pred = dy.tanh(np.dot(pooled, dense_params.as_array())\n",
    "                         + dense_bias)\n",
    "\n",
    "    pooled = np.mean(convoluted)\n",
    "    y_pred = dy.logistic(pooled)\n",
    "\n",
    "    loss = dy.binary_log_loss(y_pred, y)\n",
    "    \n",
    "    return trainer, x, y, convoluted, pooled, y_pred, loss\n",
    "\n",
    "\n",
    "def train(iters: int):\n",
    "    predicted = []\n",
    "    activations = []\n",
    "    misclass = 0\n",
    "    mloss = 0.0\n",
    "    perfect_iteration = None\n",
    "\n",
    "    for i in range(iters):\n",
    "        trainer, x, y, convoluted, pooled, y_pred, loss = renew()\n",
    "        mloss = 0.0\n",
    "        misclass = 0\n",
    "        for j in range(len(X_train)):\n",
    "            x.set(X_train[j])\n",
    "            y.set(y_train[j])\n",
    "            pred = 1 if y_pred.value() > 0.5 else 0\n",
    "            \n",
    "            if (i + 1) % iters == 0:\n",
    "                predicted.append(pred)\n",
    "                activations.append(y_pred.value())\n",
    "\n",
    "            # print(loss.scalar_value())\n",
    "            if pred != int(y.value()):\n",
    "                misclass += 1\n",
    "                \n",
    "\n",
    "            mloss += loss.scalar_value()\n",
    "            loss.backward()\n",
    "            trainer.update()\n",
    "            \n",
    "        mloss /= len(X_train)\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print(conv_filter.value())\n",
    "            print(conv_bias.value())\n",
    "            print(f'{i+1}/{iters}, loss: {mloss}, misclassified: {misclass}/{len(X_train)}')\n",
    "        \n",
    "        if perfect_iteration is None and misclass == 0:\n",
    "            perfect_iteration = i + 1\n",
    "        if (i + 1) % iters == 0:\n",
    "            print(conv_filter.value())\n",
    "            print(\"loss: %0.9f\" % mloss)\n",
    "            print(f'{misclass}/{len(X_train)} Missclassified')\n",
    "            print('perfect_iteration', perfect_iteration)\n",
    "\n",
    "\n",
    "    filter_weights = conv_filter.value()\n",
    "    return misclass, predicted, filter_weights, mloss, activations, perfect_iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8180980682373047, 4.259247779846191, 0.8648182153701782]\n",
      "-2.5686323642730713\n",
      "200/10000, loss: 0.44698005449026823, misclassified: 2/16\n",
      "[5.432982444763184, 6.911345481872559, 0.4804040491580963]\n",
      "-4.320301055908203\n",
      "400/10000, loss: 0.3530684425495565, misclassified: 2/16\n",
      "[7.3145952224731445, 8.800163269042969, -0.08903441578149796]\n",
      "-5.500290393829346\n",
      "600/10000, loss: 0.31126625067554414, misclassified: 2/16\n",
      "[8.738015174865723, 10.251307487487793, -0.7078465223312378]\n",
      "-6.352838039398193\n",
      "800/10000, loss: 0.2883445991901681, misclassified: 2/16\n",
      "[9.868326187133789, 11.438785552978516, -1.3192758560180664]\n",
      "-7.011061191558838\n",
      "1000/10000, loss: 0.27377153385896236, misclassified: 2/16\n",
      "[10.799363136291504, 12.45518970489502, -1.9012492895126343]\n",
      "-7.546363830566406\n",
      "1200/10000, loss: 0.2635598561610095, misclassified: 2/16\n",
      "[11.58694076538086, 13.352766036987305, -2.446089744567871]\n",
      "-7.999035358428955\n",
      "1400/10000, loss: 0.2559232509229332, misclassified: 2/16\n",
      "[12.266558647155762, 14.16314697265625, -2.952380418777466]\n",
      "-8.393321990966797\n",
      "1600/10000, loss: 0.24994566850364208, misclassified: 2/16\n",
      "[12.862146377563477, 14.906525611877441, -3.4214391708374023]\n",
      "-8.744575500488281\n",
      "1800/10000, loss: 0.2451078159501776, misclassified: 2/16\n",
      "[13.390631675720215, 15.596614837646484, -3.8558216094970703]\n",
      "-9.063010215759277\n",
      "2000/10000, loss: 0.24109055023291148, misclassified: 2/16\n",
      "[13.86451244354248, 16.242992401123047, -4.258533000946045]\n",
      "-9.355631828308105\n",
      "2200/10000, loss: 0.2376863232057076, misclassified: 2/16\n",
      "[14.293182373046875, 16.852767944335938, -4.632556915283203]\n",
      "-9.627445220947266\n",
      "2400/10000, loss: 0.23475374258123338, misclassified: 2/16\n",
      "[14.684016227722168, 17.431034088134766, -4.980828762054443]\n",
      "-9.882085800170898\n",
      "2600/10000, loss: 0.23219249532849062, misclassified: 2/16\n",
      "[15.042889595031738, 17.981775283813477, -5.305952548980713]\n",
      "-10.122264862060547\n",
      "2800/10000, loss: 0.22993028642667923, misclassified: 2/16\n",
      "[15.374408721923828, 18.508508682250977, -5.610436916351318]\n",
      "-10.350126266479492\n",
      "3000/10000, loss: 0.22791152347053867, misclassified: 2/16\n",
      "[15.682369232177734, 19.013574600219727, -5.896432399749756]\n",
      "-10.567233085632324\n",
      "3200/10000, loss: 0.22609536738309544, misclassified: 2/16\n",
      "[15.970030784606934, 19.499095916748047, -6.165812969207764]\n",
      "-10.774916648864746\n",
      "3400/10000, loss: 0.22444923976581777, misclassified: 2/16\n",
      "[16.240083694458008, 19.966720581054688, -6.4202961921691895]\n",
      "-10.974214553833008\n",
      "3600/10000, loss: 0.22294782465178287, misclassified: 2/16\n",
      "[16.494558334350586, 20.41800308227539, -6.66138219833374]\n",
      "-11.165940284729004\n",
      "3800/10000, loss: 0.22157083630008856, misclassified: 2/16\n",
      "[16.735326766967773, 20.854339599609375, -6.890371799468994]\n",
      "-11.350897789001465\n",
      "4000/10000, loss: 0.22030132662621327, misclassified: 2/16\n",
      "[16.963964462280273, 21.276683807373047, -7.108413219451904]\n",
      "-11.529597282409668\n",
      "4200/10000, loss: 0.2191259636747418, misclassified: 2/16\n",
      "[17.1817626953125, 21.685972213745117, -7.316531658172607]\n",
      "-11.70255184173584\n",
      "4400/10000, loss: 0.21803371285204776, misclassified: 2/16\n",
      "[17.389848709106445, 22.083171844482422, -7.515561103820801]\n",
      "-11.870256423950195\n",
      "4600/10000, loss: 0.21701487097379868, misclassified: 2/16\n",
      "[17.589670181274414, 22.46882438659668, -7.706419944763184]\n",
      "-12.03309440612793\n",
      "4800/10000, loss: 0.2160614975982753, misclassified: 2/16\n",
      "[17.781478881835938, 22.843597412109375, -7.889689922332764]\n",
      "-12.19129467010498\n",
      "5000/10000, loss: 0.2151672023901483, misclassified: 2/16\n",
      "[17.96648406982422, 23.208433151245117, -8.06607437133789]\n",
      "-12.345353126525879\n",
      "5200/10000, loss: 0.2143253243448271, misclassified: 2/16\n",
      "[18.14533042907715, 23.563419342041016, -8.2358980178833]\n",
      "-12.49547004699707\n",
      "5400/10000, loss: 0.21353166881090146, misclassified: 2/16\n",
      "[18.318452835083008, 23.9094181060791, -8.399951934814453]\n",
      "-12.64186954498291\n",
      "5600/10000, loss: 0.21278135654210928, misclassified: 2/16\n",
      "[18.486522674560547, 24.24645233154297, -8.558515548706055]\n",
      "-12.78467845916748\n",
      "5800/10000, loss: 0.2120711947172822, misclassified: 2/16\n",
      "[18.649580001831055, 24.575510025024414, -8.71183967590332]\n",
      "-12.924273490905762\n",
      "6000/10000, loss: 0.21139714976743562, misclassified: 2/16\n",
      "[18.808670043945312, 24.89638900756836, -8.860506057739258]\n",
      "-13.060678482055664\n",
      "6200/10000, loss: 0.21075670987920603, misclassified: 2/16\n",
      "[18.963783264160156, 25.209928512573242, -9.00477409362793]\n",
      "-13.194197654724121\n",
      "6400/10000, loss: 0.21014680813641462, misclassified: 2/16\n",
      "[19.115352630615234, 25.515966415405273, -9.14486026763916]\n",
      "-13.324824333190918\n",
      "6600/10000, loss: 0.20956566706263402, misclassified: 1/16\n",
      "[19.263425827026367, 25.815322875976562, -9.28100299835205]\n",
      "-13.452844619750977\n",
      "6800/10000, loss: 0.20901090028200997, misclassified: 1/16\n",
      "[19.408639907836914, 26.107847213745117, -9.413582801818848]\n",
      "-13.578265190124512\n",
      "7000/10000, loss: 0.20848052055407607, misclassified: 1/16\n",
      "[19.55098533630371, 26.393972396850586, -9.542561531066895]\n",
      "-13.701260566711426\n",
      "7200/10000, loss: 0.20797320017118182, misclassified: 1/16\n",
      "[19.69049644470215, 26.674047470092773, -9.66837215423584]\n",
      "-13.82188606262207\n",
      "7400/10000, loss: 0.20748719894618262, misclassified: 1/16\n",
      "[19.827932357788086, 26.948036193847656, -9.791037559509277]\n",
      "-13.94035530090332\n",
      "7600/10000, loss: 0.20702087401241442, misclassified: 1/16\n",
      "[19.96328353881836, 27.216243743896484, -9.910698890686035]\n",
      "-14.056772232055664\n",
      "7800/10000, loss: 0.20657330123412976, misclassified: 1/16\n",
      "[20.09622573852539, 27.47939109802246, -10.027647018432617]\n",
      "-14.1712007522583\n",
      "8000/10000, loss: 0.20614297871998133, misclassified: 1/16\n",
      "[20.22731590270996, 27.736888885498047, -10.141881942749023]\n",
      "-14.283560752868652\n",
      "8200/10000, loss: 0.2057292822837553, misclassified: 1/16\n",
      "[20.356435775756836, 27.989320755004883, -10.253495216369629]\n",
      "-14.394037246704102\n",
      "8400/10000, loss: 0.2053311216259317, misclassified: 1/16\n",
      "[20.484132766723633, 28.236818313598633, -10.362751007080078]\n",
      "-14.502819061279297\n",
      "8600/10000, loss: 0.20494725362823374, misclassified: 1/16\n",
      "[20.61029815673828, 28.479703903198242, -10.469758033752441]\n",
      "-14.6099271774292\n",
      "8800/10000, loss: 0.20457687171801808, misclassified: 1/16\n",
      "[20.734800338745117, 28.7175350189209, -10.574503898620605]\n",
      "-14.715201377868652\n",
      "9000/10000, loss: 0.20422011303708132, misclassified: 1/16\n",
      "[20.857807159423828, 28.95108413696289, -10.677058219909668]\n",
      "-14.818916320800781\n",
      "9200/10000, loss: 0.20387541008130938, misclassified: 1/16\n",
      "[20.979469299316406, 29.180273056030273, -10.777596473693848]\n",
      "-14.921045303344727\n",
      "9400/10000, loss: 0.20354236220009625, misclassified: 1/16\n",
      "[21.099964141845703, 29.405359268188477, -10.876235961914062]\n",
      "-15.021753311157227\n",
      "9600/10000, loss: 0.20322009176970823, misclassified: 1/16\n",
      "[21.21916961669922, 29.62625503540039, -10.973018646240234]\n",
      "-15.120929718017578\n",
      "9800/10000, loss: 0.20290849469211025, misclassified: 1/16\n",
      "[21.337261199951172, 29.843252182006836, -11.067924499511719]\n",
      "-15.218768119812012\n",
      "10000/10000, loss: 0.20260671745882064, misclassified: 1/16\n",
      "[21.337261199951172, 29.843252182006836, -11.067924499511719]\n",
      "loss: 0.202606717\n",
      "1/16 Missclassified\n",
      "perfect_iteration None\n"
     ]
    }
   ],
   "source": [
    "m, pr, fw, l, act, pit = train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12 0.32 0.34 0.12 0.68 0.64 0.55 0.44]\n",
      "1 0.0\n"
     ]
    }
   ],
   "source": [
    "test_predicted = []\n",
    "misclass = 0\n",
    "for j in range(len(X_test)):\n",
    "    trainer, x, y, convoluted, pooled, y_pred, loss = renew()\n",
    "    x.set(X_test[j])\n",
    "    y.set(y_test[j])\n",
    "    pred = 1 if y_pred.value() > 0.5 else 0\n",
    "\n",
    "    if pred != int(y.value()):\n",
    "        print(X_test[j])\n",
    "        print(pred, y.value())\n",
    "    test_predicted.append(pred)\n",
    "\n",
    "    if pred != int(y.value()):\n",
    "        misclass += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "bakalarka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
