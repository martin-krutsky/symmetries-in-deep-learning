# Symmetries-in-Neural-Networks
This is a repository for my Bachelor thesis called Exploring Symmetries in Deep Learning.

## Chapter 1: Functions Invariant to Input Permutations

### 1.1 Binary Logic Functions

#### [1.1.1 Baseline with Vanilla NNs](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/1_binlogic_baseline)

#### [1.1.2 NNs with Weight Sharing](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/1_binlogic_weightsharing)


### 1.2 N-Dimensional Logic Functions

#### [1.2.1 Baseline with Vanilla NNs](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/1_ndimlogic_baseline)

#### [1.2.2 NNs with Weight Sharing](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/1_ndimlogic_weightsharing)


### 1.3 Set Summation

#### [1.3.1 Deep Sets](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/4_deepsets)


## Chapter 2: Functions Invariant to Translations

### [2.1 Convolutional Neural Networks](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/5_cnns)


## Chapter 3: Graph Isomorphisms

### [3.1 Graph Neural Networks](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/6_gnns)

## Chapter 4: Rubik's Cube State Classification

### [3.1 GNNs for Rubik's Cube State Classification](https://github.com/martin-krutsky/symmetries-in-deep-learning/tree/main/6_nontrivial)




