{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv, GINConv, GINEConv, GraphConv, GENConv\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool, global_add_pool, global_sort_pool\n",
    "\n",
    "from all_2_states import incidence_matrix, all_goal_states_ls, all_nongoal_states_ls, all_goal_states_np, all_nongoal_states_np, edge_tps_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5]\n",
      "[2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0, 4, 4, 4, 4, 5, 5, 5, 5]\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2, 2, 4, 4, 4, 4, 5, 5, 5, 5]\n",
      "[3, 3, 3, 3, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 4, 4, 4, 4, 5, 5, 5, 5]\n",
      "[0, 0, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2, 5, 5, 5, 5, 4, 4, 4, 4]\n",
      "[3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4]\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3, 5, 5, 5, 5, 4, 4, 4, 4]\n",
      "[2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 1, 1, 1, 1, 5, 5, 5, 5, 4, 4, 4, 4]\n",
      "[0, 0, 0, 0, 1, 1, 1, 1, 5, 5, 5, 5, 4, 4, 4, 4, 2, 2, 2, 2, 3, 3, 3, 3]\n",
      "[5, 5, 5, 5, 4, 4, 4, 4, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 3, 3, 3, 3]\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 4, 4, 4, 4, 5, 5, 5, 5, 2, 2, 2, 2, 3, 3, 3, 3]\n",
      "[4, 4, 4, 4, 5, 5, 5, 5, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n",
      "[0, 0, 0, 0, 1, 1, 1, 1, 4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 2, 2, 2, 2]\n",
      "[4, 4, 4, 4, 5, 5, 5, 5, 1, 1, 1, 1, 0, 0, 0, 0, 3, 3, 3, 3, 2, 2, 2, 2]\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2]\n",
      "[5, 5, 5, 5, 4, 4, 4, 4, 0, 0, 0, 0, 1, 1, 1, 1, 3, 3, 3, 3, 2, 2, 2, 2]\n",
      "[5, 5, 5, 5, 4, 4, 4, 4, 2, 2, 2, 2, 3, 3, 3, 3, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "[2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "[4, 4, 4, 4, 5, 5, 5, 5, 3, 3, 3, 3, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "[3, 3, 3, 3, 2, 2, 2, 2, 5, 5, 5, 5, 4, 4, 4, 4, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "[5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "[3, 3, 3, 3, 2, 2, 2, 2, 4, 4, 4, 4, 5, 5, 5, 5, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "[4, 4, 4, 4, 5, 5, 5, 5, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "[2, 2, 2, 2, 3, 3, 3, 3, 5, 5, 5, 5, 4, 4, 4, 4, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "====================================================================================================\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5]\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3, 2, 3, 4, 5, 2, 3, 4, 5]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "[0, 1, 4, 5, 0, 1, 4, 5, 2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n",
      "[2, 3, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 0, 1, 4, 5, 0, 1, 2, 3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "for state in all_goal_states_ls:\n",
    "    print(state)\n",
    "    \n",
    "print(100*'=')\n",
    "\n",
    "for state in all_nongoal_states_ls:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_tps_torch = F.one_hot(torch.tensor(edge_tps_np).long(), 3)\n",
    "# print(edge_tps_np)\n",
    "# print(np.repeat(np.expand_dims(edge_tps_np, axis=1), 6, axis=1))\n",
    "edge_tps_torch = torch.tensor(np.repeat(np.expand_dims(edge_tps_np, axis=1), 6, axis=1), dtype=torch.long)\n",
    "# edge_tps_torch = torch.tensor(edge_tps_np, dtype=torch.long)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "dataset_fc = []\n",
    "y_fc = []\n",
    "\n",
    "for x in all_goal_states_ls:\n",
    "    features = torch.tensor(x, dtype=torch.long)\n",
    "    features = F.one_hot(features, 6)\n",
    "    dataset_fc.append(features.detach().cpu().numpy())\n",
    "    y_fc.append(1)\n",
    "    edge_index = torch.tensor(incidence_matrix, dtype=torch.long)\n",
    "    print(edge_tps_torch.type())\n",
    "    data_obj = Data(x=features, edge_index=edge_index, edge_attr=edge_tps_torch, y=1)\n",
    "    dataset.append(data_obj)\n",
    "\n",
    "\n",
    "for x in all_nongoal_states_ls:\n",
    "    features = torch.tensor(x, dtype=torch.long)\n",
    "    features = F.one_hot(features, 6)\n",
    "    dataset_fc.append(features.detach().cpu().numpy())\n",
    "    y_fc.append(0)\n",
    "    edge_index = torch.tensor(incidence_matrix, dtype=torch.long)\n",
    "    data_obj = Data(x=features, edge_index=edge_index, edge_attr=edge_tps_torch, y=0)\n",
    "    dataset.append(data_obj)\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[0])\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=48, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset[:12] + dataset[24:36]\n",
    "dataset_fc2 = dataset_fc[:12] + dataset_fc[24:36]\n",
    "y_fc2 = y_fc[:12] + y_fc[24:36]\n",
    "\n",
    "half_loader = DataLoader(dataset_2, batch_size=24, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCModel(nn.Module):\n",
    "    def __init__(self, state_dim: int, one_hot_depth: int, fc1_dim: int, fc2_dim: int):\n",
    "        super().__init__()\n",
    "        self.one_hot_depth: int = one_hot_depth\n",
    "        self.state_dim: int = state_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(self.state_dim * self.one_hot_depth, fc1_dim)\n",
    "        self.fc2 = nn.Linear(fc1_dim, fc2_dim)\n",
    "        self.fc_out = nn.Linear(fc2_dim, 1)\n",
    "\n",
    "    def forward(self, states_nnet, training=False):\n",
    "        x = states_nnet\n",
    "\n",
    "        # preprocess input\n",
    "        x = torch.tensor(x).float()\n",
    "        x = x.view(-1, self.state_dim * self.one_hot_depth)\n",
    "\n",
    "        # first two hidden layers\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        # output\n",
    "        x = self.fc_out(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNModel, self).__init__()\n",
    "        # torch.manual_seed(12345)\n",
    "#         self.conv1 = GINEConv(nn.Linear(6, hidden_channels))\n",
    "#         self.conv2 = GINEConv(nn.Linear(hidden_channels, hidden_channels))\n",
    "#         self.conv3 = GINEConv(nn.Linear(hidden_channels, hidden_channels))\n",
    "#         self.conv1 = GraphConv(6, hidden_channels)\n",
    "#         self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "#         self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv1 = GENConv(6, hidden_channels, aggr='softmax', t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "        self.conv2 = GENConv(hidden_channels, hidden_channels, aggr='softmax', t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "        self.conv3 = GENConv(hidden_channels, hidden_channels, aggr='softmax', t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "        self.lin = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "#         print(x[0].size(-1))\n",
    "#         print(edge_attr.size(-1))\n",
    "        assert edge_attr.size(-1) == x[0].size(-1)\n",
    "#         print(edge_attr)\n",
    "#         print(edge_attr.type())\n",
    "        x = self.conv1(x.float(), edge_index=edge_index, edge_attr=edge_attr)\n",
    "        x = F.relu(x)\n",
    "        edge_attr = torch.tensor(np.repeat(edge_attr, 4, axis=1), dtype=torch.long)\n",
    "#         print(x[0].size(-1))\n",
    "#         print(edge_attr.size(-1))\n",
    "        x = self.conv2(x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv3(x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_add_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "#         print(x.size())\n",
    "#         print(x[0:24])\n",
    "# #         print(x[1])\n",
    "#         print(x[24:])\n",
    "#         print(x[25])\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        # x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNModel(hidden_channels=24)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch_geometric.data.dataloader.DataLoader object at 0x000001BC38DDB7C0>\n"
     ]
    }
   ],
   "source": [
    "def run_train(loader):\n",
    "    model.train()\n",
    "\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)  # Perform a single forward pass.\n",
    "#         print(out.squeeze())\n",
    "#         print(data.y)\n",
    "        print(data.y.type())\n",
    "        loss = criterion(out.squeeze(), data.y.float())  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    print(loss.item())\n",
    "\n",
    "def run_test(loader):\n",
    "    model.eval()\n",
    "    misclass = []\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "#         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        result = []\n",
    "        for output in out:\n",
    "            if output > 0.5:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        pred = torch.tensor(result)\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        misclass += list(data[pred != data.y])\n",
    "    return correct / len(loader.dataset), misclass  # Derive ratio of correct predictions.\n",
    "\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-658-79d9e753907c>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_attr = torch.tensor(np.repeat(edge_attr, 4, axis=1), dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "4.718338489532471\n",
      "Epoch: 001, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "3.544243097305298\n",
      "Epoch: 002, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "2.392704486846924\n",
      "Epoch: 003, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.3189719915390015\n",
      "Epoch: 004, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6886625289916992\n",
      "Epoch: 005, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.993502676486969\n",
      "Epoch: 006, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.4493776559829712\n",
      "Epoch: 007, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.6396570205688477\n",
      "Epoch: 008, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.5916765928268433\n",
      "Epoch: 009, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.382279872894287\n",
      "Epoch: 010, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.077668309211731\n",
      "Epoch: 011, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7963201403617859\n",
      "Epoch: 012, Train Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    run_train(train_loader)\n",
    "    train_acc, trM = run_test(train_loader)\n",
    "#     print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if train_acc == 1.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-662-aaa2af9e224a>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_fc = torch.tensor(dataset_fc, dtype=torch.long)\n",
      "<ipython-input-662-aaa2af9e224a>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_fc = torch.tensor(y_fc, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "model2 = FCModel(24, 6, 24, 24)\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "dataset_fc = torch.tensor(dataset_fc, dtype=torch.long)\n",
    "y_fc = torch.tensor(y_fc, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fc_train():\n",
    "    model2.train()\n",
    "\n",
    "    out = model2(dataset_fc)  # Perform a single forward pass.\\\n",
    "    print(len(out))\n",
    "    print(len(y_fc))\n",
    "    loss = criterion(out.squeeze(), y_fc)  # Compute the loss.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    print(loss.item())\n",
    "\n",
    "def run_fc_test():\n",
    "    model2.eval()\n",
    "    misclass = []\n",
    "\n",
    "    correct = 0\n",
    "    out = model2(dataset_fc)\n",
    "#     pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    result = []\n",
    "    for output in out:\n",
    "        if output > 0.5:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    pred = torch.tensor(result)\n",
    "    correct += int((pred == y_fc).sum())  # Check against ground-truth labels.\n",
    "    misclass += list(dataset_fc[pred != y_fc])\n",
    "    return correct / len(dataset_fc), misclass  # Derive ratio of correct predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-594-e4f1a6919e56>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "48\n",
      "0.69993656873703\n",
      "Epoch: 001, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6951406002044678\n",
      "Epoch: 002, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6905686259269714\n",
      "Epoch: 003, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6861886382102966\n",
      "Epoch: 004, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6819456219673157\n",
      "Epoch: 005, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6777820587158203\n",
      "Epoch: 006, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6736657023429871\n",
      "Epoch: 007, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6695994734764099\n",
      "Epoch: 008, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6654258370399475\n",
      "Epoch: 009, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6609951853752136\n",
      "Epoch: 010, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6562570929527283\n",
      "Epoch: 011, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.651249349117279\n",
      "Epoch: 012, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.646018385887146\n",
      "Epoch: 013, Train Acc: 0.5000\n",
      "48\n",
      "48\n",
      "0.6404486894607544\n",
      "Epoch: 014, Train Acc: 0.5625\n",
      "48\n",
      "48\n",
      "0.6344786286354065\n",
      "Epoch: 015, Train Acc: 0.5833\n",
      "48\n",
      "48\n",
      "0.6280642151832581\n",
      "Epoch: 016, Train Acc: 0.6458\n",
      "48\n",
      "48\n",
      "0.6213086843490601\n",
      "Epoch: 017, Train Acc: 0.7083\n",
      "48\n",
      "48\n",
      "0.6142169833183289\n",
      "Epoch: 018, Train Acc: 0.7292\n",
      "48\n",
      "48\n",
      "0.6068134903907776\n",
      "Epoch: 019, Train Acc: 0.7917\n",
      "48\n",
      "48\n",
      "0.5990715622901917\n",
      "Epoch: 020, Train Acc: 0.9167\n",
      "48\n",
      "48\n",
      "0.5908307433128357\n",
      "Epoch: 021, Train Acc: 0.9167\n",
      "48\n",
      "48\n",
      "0.582096517086029\n",
      "Epoch: 022, Train Acc: 0.9375\n",
      "48\n",
      "48\n",
      "0.5727890133857727\n",
      "Epoch: 023, Train Acc: 0.9583\n",
      "48\n",
      "48\n",
      "0.5628855228424072\n",
      "Epoch: 024, Train Acc: 0.9583\n",
      "48\n",
      "48\n",
      "0.5523697733879089\n",
      "Epoch: 025, Train Acc: 0.9583\n",
      "48\n",
      "48\n",
      "0.5413395762443542\n",
      "Epoch: 026, Train Acc: 0.9792\n",
      "48\n",
      "48\n",
      "0.5298465490341187\n",
      "Epoch: 027, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.517848551273346\n",
      "Epoch: 028, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.5054827332496643\n",
      "Epoch: 029, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.4926300048828125\n",
      "Epoch: 030, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.4792819321155548\n",
      "Epoch: 031, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.46541011333465576\n",
      "Epoch: 032, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.451063871383667\n",
      "Epoch: 033, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.43645191192626953\n",
      "Epoch: 034, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.4214555025100708\n",
      "Epoch: 035, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.406159371137619\n",
      "Epoch: 036, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.39061757922172546\n",
      "Epoch: 037, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.3748529255390167\n",
      "Epoch: 038, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.3589273989200592\n",
      "Epoch: 039, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.34286758303642273\n",
      "Epoch: 040, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.32681864500045776\n",
      "Epoch: 041, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.31079134345054626\n",
      "Epoch: 042, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.2948480248451233\n",
      "Epoch: 043, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.2790692150592804\n",
      "Epoch: 044, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.26348376274108887\n",
      "Epoch: 045, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.24814485013484955\n",
      "Epoch: 046, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.23305000364780426\n",
      "Epoch: 047, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.21836984157562256\n",
      "Epoch: 048, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.20415693521499634\n",
      "Epoch: 049, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.19044606387615204\n",
      "Epoch: 050, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.17727512121200562\n",
      "Epoch: 051, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.16470368206501007\n",
      "Epoch: 052, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.15275752544403076\n",
      "Epoch: 053, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.14138393104076385\n",
      "Epoch: 054, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.13062717020511627\n",
      "Epoch: 055, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.12050846964120865\n",
      "Epoch: 056, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.11104175448417664\n",
      "Epoch: 057, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.10218662023544312\n",
      "Epoch: 058, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.09394550323486328\n",
      "Epoch: 059, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.08630529046058655\n",
      "Epoch: 060, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.07923399657011032\n",
      "Epoch: 061, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.07272180169820786\n",
      "Epoch: 062, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.06675077974796295\n",
      "Epoch: 063, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.06128948554396629\n",
      "Epoch: 064, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.05630381405353546\n",
      "Epoch: 065, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.05177008733153343\n",
      "Epoch: 066, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.04764384403824806\n",
      "Epoch: 067, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.04389357566833496\n",
      "Epoch: 068, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.040493566542863846\n",
      "Epoch: 069, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.03741089999675751\n",
      "Epoch: 070, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.03461477532982826\n",
      "Epoch: 071, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.03207945078611374\n",
      "Epoch: 072, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.0297811571508646\n",
      "Epoch: 073, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.027700206264853477\n",
      "Epoch: 074, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.02581137977540493\n",
      "Epoch: 075, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.024096375331282616\n",
      "Epoch: 076, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.022534621879458427\n",
      "Epoch: 077, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.021114831790328026\n",
      "Epoch: 078, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.01982220634818077\n",
      "Epoch: 079, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.018644019961357117\n",
      "Epoch: 080, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.0175692867487669\n",
      "Epoch: 081, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.01658683829009533\n",
      "Epoch: 082, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.01568875089287758\n",
      "Epoch: 083, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.01486495602875948\n",
      "Epoch: 084, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.014108795672655106\n",
      "Epoch: 085, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.013413511216640472\n",
      "Epoch: 086, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.012773096561431885\n",
      "Epoch: 087, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.01218271255493164\n",
      "Epoch: 088, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.011637910269200802\n",
      "Epoch: 089, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.0111337685957551\n",
      "Epoch: 090, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.010666906833648682\n",
      "Epoch: 091, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.010233225300908089\n",
      "Epoch: 092, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.009829912334680557\n",
      "Epoch: 093, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.009454476647078991\n",
      "Epoch: 094, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.009103749878704548\n",
      "Epoch: 095, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.008776064962148666\n",
      "Epoch: 096, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.008469712920486927\n",
      "Epoch: 097, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.00818310584872961\n",
      "Epoch: 098, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.007914273999631405\n",
      "Epoch: 099, Train Acc: 1.0000\n",
      "48\n",
      "48\n",
      "0.007661040872335434\n",
      "Epoch: 100, Train Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    run_fc_train()\n",
    "    train_acc, trM = run_fc_test()\n",
    "#     print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_model = GNModel(hidden_channels=24)\n",
    "optimizer = torch.optim.Adam(half_model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch_geometric.data.dataloader.DataLoader object at 0x000001BC38DDB7C0>\n"
     ]
    }
   ],
   "source": [
    "def run_train2(loader):\n",
    "    half_model.train()\n",
    "\n",
    "    for data in loader:  # Iterate in batches over the training dataset.\n",
    "        out = half_model(data.x, data.edge_index, data.edge_attr, data.batch)  # Perform a single forward pass.\n",
    "#         print(out.squeeze())\n",
    "#         print(data.y)\n",
    "        print(data.y.type())\n",
    "        loss = criterion(out.squeeze(), data.y.float())  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "    print(loss.item())\n",
    "\n",
    "def run_test2(loader):\n",
    "    half_model.eval()\n",
    "    misclass = []\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = half_model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "#         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        result = []\n",
    "        for output in out:\n",
    "            if output > 0.5:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        pred = torch.tensor(result)\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        misclass += list(data[pred != data.y])\n",
    "    return correct / len(loader.dataset), misclass  # Derive ratio of correct predictions.\n",
    "\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-658-79d9e753907c>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  edge_attr = torch.tensor(np.repeat(edge_attr, 4, axis=1), dtype=torch.long)\n",
      "C:\\Users\\marti\\Anaconda3\\envs\\bakalarka\\lib\\site-packages\\torch\\nn\\functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "5.825967788696289\n",
      "Epoch: 001, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "4.74454927444458\n",
      "Epoch: 002, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "3.6753222942352295\n",
      "Epoch: 003, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "2.621415376663208\n",
      "Epoch: 004, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.5980180501937866\n",
      "Epoch: 005, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.8157267570495605\n",
      "Epoch: 006, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.8089656829833984\n",
      "Epoch: 007, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.2864556312561035\n",
      "Epoch: 008, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.6204530000686646\n",
      "Epoch: 009, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.7289608716964722\n",
      "Epoch: 010, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.648837685585022\n",
      "Epoch: 011, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.4391480684280396\n",
      "Epoch: 012, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.1575590372085571\n",
      "Epoch: 013, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.8795127272605896\n",
      "Epoch: 014, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7084309458732605\n",
      "Epoch: 015, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7152235507965088\n",
      "Epoch: 016, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.8381690979003906\n",
      "Epoch: 017, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.9638509750366211\n",
      "Epoch: 018, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.0280094146728516\n",
      "Epoch: 019, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "1.0171934366226196\n",
      "Epoch: 020, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.9452665448188782\n",
      "Epoch: 021, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.8417882323265076\n",
      "Epoch: 022, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7455470561981201\n",
      "Epoch: 023, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6932773590087891\n",
      "Epoch: 024, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6993492245674133\n",
      "Epoch: 025, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7401547431945801\n",
      "Epoch: 026, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7795558571815491\n",
      "Epoch: 027, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7935120463371277\n",
      "Epoch: 028, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7776017785072327\n",
      "Epoch: 029, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7423892617225647\n",
      "Epoch: 030, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7064784169197083\n",
      "Epoch: 031, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6874088644981384\n",
      "Epoch: 032, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6916158199310303\n",
      "Epoch: 033, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.710669219493866\n",
      "Epoch: 034, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7277520298957825\n",
      "Epoch: 035, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7310371994972229\n",
      "Epoch: 036, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.719916820526123\n",
      "Epoch: 037, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7023652195930481\n",
      "Epoch: 038, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6888278126716614\n",
      "Epoch: 039, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6856233477592468\n",
      "Epoch: 040, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6916865706443787\n",
      "Epoch: 041, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.700746476650238\n",
      "Epoch: 042, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7059273719787598\n",
      "Epoch: 043, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.7039548754692078\n",
      "Epoch: 044, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.69667649269104\n",
      "Epoch: 045, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6888143420219421\n",
      "Epoch: 046, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6847301125526428\n",
      "Epoch: 047, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.685856819152832\n",
      "Epoch: 048, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6900166869163513\n",
      "Epoch: 049, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6934976577758789\n",
      "Epoch: 050, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6936120390892029\n",
      "Epoch: 051, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6903088688850403\n",
      "Epoch: 052, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6858928799629211\n",
      "Epoch: 053, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6835959553718567\n",
      "Epoch: 054, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.684108555316925\n",
      "Epoch: 055, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.685984194278717\n",
      "Epoch: 056, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6876416802406311\n",
      "Epoch: 057, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6876492500305176\n",
      "Epoch: 058, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6858541965484619\n",
      "Epoch: 059, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6838975548744202\n",
      "Epoch: 060, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6830045580863953\n",
      "Epoch: 061, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6832051277160645\n",
      "Epoch: 062, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6840168833732605\n",
      "Epoch: 063, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6843926310539246\n",
      "Epoch: 064, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6838118433952332\n",
      "Epoch: 065, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6831693053245544\n",
      "Epoch: 066, Train Acc: 0.5000\n",
      "torch.LongTensor\n",
      "0.6826710104942322\n",
      "Epoch: 067, Train Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    run_train2(half_loader)\n",
    "    train_acc, trM = run_test2(train_loader)\n",
    "#     print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if train_acc == 1.0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-691-75d2b1c6678d>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_fc2 = torch.tensor(dataset_fc2, dtype=torch.long)\n",
      "<ipython-input-691-75d2b1c6678d>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_fc2 = torch.tensor(y_fc2, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "half_model2 = FCModel(24, 6, 24, 24)\n",
    "optimizer = torch.optim.Adam(half_model2.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "dataset_fc2 = torch.tensor(dataset_fc2, dtype=torch.long)\n",
    "y_fc2 = torch.tensor(y_fc2, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fc_train2():\n",
    "    half_model2.train()\n",
    "\n",
    "    out = half_model2(dataset_fc2)  # Perform a single forward pass.\\\n",
    "    print(len(out))\n",
    "    print(len(y_fc))\n",
    "    loss = criterion(out.squeeze(), y_fc2)  # Compute the loss.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    print(loss.item())\n",
    "\n",
    "def run_fc_test2(dataset, labels):\n",
    "    half_model2.eval()\n",
    "    misclass = []\n",
    "\n",
    "    correct = 0\n",
    "    out = half_model2(dataset)\n",
    "#     pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    result = []\n",
    "    for output in out:\n",
    "        if output > 0.5:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    pred = torch.tensor(result)\n",
    "    correct += int((pred == labels).sum())  # Check against ground-truth labels.\n",
    "    misclass += list(dataset[pred != labels])\n",
    "    return correct / len(dataset), misclass  # Derive ratio of correct predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-594-e4f1a6919e56>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "48\n",
      "0.6614223122596741\n",
      "12\n",
      "48\n",
      "0.6481271386146545\n",
      "12\n",
      "48\n",
      "0.6353236436843872\n",
      "12\n",
      "48\n",
      "0.6222890019416809\n",
      "12\n",
      "48\n",
      "0.6090385913848877\n",
      "12\n",
      "48\n",
      "0.5947416424751282\n",
      "12\n",
      "48\n",
      "0.5800952911376953\n",
      "12\n",
      "48\n",
      "0.5652318596839905\n",
      "12\n",
      "48\n",
      "0.5496399998664856\n",
      "12\n",
      "48\n",
      "0.5332184433937073\n",
      "Epoch: 010, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.5159369707107544\n",
      "12\n",
      "48\n",
      "0.4978337585926056\n",
      "12\n",
      "48\n",
      "0.4790693521499634\n",
      "12\n",
      "48\n",
      "0.45961353182792664\n",
      "12\n",
      "48\n",
      "0.43954285979270935\n",
      "12\n",
      "48\n",
      "0.41893115639686584\n",
      "12\n",
      "48\n",
      "0.39783307909965515\n",
      "12\n",
      "48\n",
      "0.3762528598308563\n",
      "12\n",
      "48\n",
      "0.3543708324432373\n",
      "12\n",
      "48\n",
      "0.3322574198246002\n",
      "Epoch: 020, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.30979660153388977\n",
      "12\n",
      "48\n",
      "0.28721755743026733\n",
      "12\n",
      "48\n",
      "0.2647142708301544\n",
      "12\n",
      "48\n",
      "0.2423819899559021\n",
      "12\n",
      "48\n",
      "0.22067975997924805\n",
      "12\n",
      "48\n",
      "0.19975578784942627\n",
      "12\n",
      "48\n",
      "0.17981944978237152\n",
      "12\n",
      "48\n",
      "0.16109125316143036\n",
      "12\n",
      "48\n",
      "0.1435948759317398\n",
      "12\n",
      "48\n",
      "0.12747400999069214\n",
      "Epoch: 030, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.11266370862722397\n",
      "12\n",
      "48\n",
      "0.09926370531320572\n",
      "12\n",
      "48\n",
      "0.08721210807561874\n",
      "12\n",
      "48\n",
      "0.07640323787927628\n",
      "12\n",
      "48\n",
      "0.06683267652988434\n",
      "12\n",
      "48\n",
      "0.05840057134628296\n",
      "12\n",
      "48\n",
      "0.050993312150239944\n",
      "12\n",
      "48\n",
      "0.044529274106025696\n",
      "12\n",
      "48\n",
      "0.03891922906041145\n",
      "12\n",
      "48\n",
      "0.03406621515750885\n",
      "Epoch: 040, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.029877126216888428\n",
      "12\n",
      "48\n",
      "0.02626645565032959\n",
      "12\n",
      "48\n",
      "0.02315708063542843\n",
      "12\n",
      "48\n",
      "0.020480027422308922\n",
      "12\n",
      "48\n",
      "0.018174560740590096\n",
      "12\n",
      "48\n",
      "0.01618746854364872\n",
      "12\n",
      "48\n",
      "0.01447271928191185\n",
      "12\n",
      "48\n",
      "0.012990585528314114\n",
      "12\n",
      "48\n",
      "0.0117070646956563\n",
      "12\n",
      "48\n",
      "0.010593128390610218\n",
      "Epoch: 050, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.009623993188142776\n",
      "12\n",
      "48\n",
      "0.00877873320132494\n",
      "12\n",
      "48\n",
      "0.008039428852498531\n",
      "12\n",
      "48\n",
      "0.007391035091131926\n",
      "12\n",
      "48\n",
      "0.006820697337388992\n",
      "12\n",
      "48\n",
      "0.006317539606243372\n",
      "12\n",
      "48\n",
      "0.0058723334223032\n",
      "12\n",
      "48\n",
      "0.005477197468280792\n",
      "12\n",
      "48\n",
      "0.005125442054122686\n",
      "12\n",
      "48\n",
      "0.00481138052418828\n",
      "Epoch: 060, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.004530181176960468\n",
      "12\n",
      "48\n",
      "0.004277581814676523\n",
      "12\n",
      "48\n",
      "0.00405006343498826\n",
      "12\n",
      "48\n",
      "0.003844531951472163\n",
      "12\n",
      "48\n",
      "0.003658333094790578\n",
      "12\n",
      "48\n",
      "0.0034891648683696985\n",
      "12\n",
      "48\n",
      "0.003335127839818597\n",
      "12\n",
      "48\n",
      "0.0031943342182785273\n",
      "12\n",
      "48\n",
      "0.00306547898799181\n",
      "12\n",
      "48\n",
      "0.002947132335975766\n",
      "Epoch: 070, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.002838199958205223\n",
      "12\n",
      "48\n",
      "0.002737646922469139\n",
      "12\n",
      "48\n",
      "0.0026446490082889795\n",
      "12\n",
      "48\n",
      "0.002558378269895911\n",
      "12\n",
      "48\n",
      "0.0024782544933259487\n",
      "12\n",
      "48\n",
      "0.002403574762865901\n",
      "12\n",
      "48\n",
      "0.002333809155970812\n",
      "12\n",
      "48\n",
      "0.0022685546427965164\n",
      "12\n",
      "48\n",
      "0.0022073311265558004\n",
      "12\n",
      "48\n",
      "0.0021497805137187243\n",
      "Epoch: 080, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0020956031512469053\n",
      "12\n",
      "48\n",
      "0.0020444595720618963\n",
      "12\n",
      "48\n",
      "0.0019961108919233084\n",
      "12\n",
      "48\n",
      "0.0019503128714859486\n",
      "12\n",
      "48\n",
      "0.0019068458350375295\n",
      "12\n",
      "48\n",
      "0.0018655256135389209\n",
      "12\n",
      "48\n",
      "0.0018262177472934127\n",
      "12\n",
      "48\n",
      "0.0017886677524074912\n",
      "12\n",
      "48\n",
      "0.0017528306925669312\n",
      "12\n",
      "48\n",
      "0.0017185477772727609\n",
      "Epoch: 090, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.001685658935457468\n",
      "12\n",
      "48\n",
      "0.0016541593940928578\n",
      "12\n",
      "48\n",
      "0.0016238597454503179\n",
      "12\n",
      "48\n",
      "0.0015947750071063638\n",
      "12\n",
      "48\n",
      "0.001566736027598381\n",
      "12\n",
      "48\n",
      "0.0015397026436403394\n",
      "12\n",
      "48\n",
      "0.0015136002330109477\n",
      "12\n",
      "48\n",
      "0.0014883690746501088\n",
      "12\n",
      "48\n",
      "0.001463979366235435\n",
      "12\n",
      "48\n",
      "0.0014403661480173469\n",
      "Epoch: 100, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0014174795942381024\n",
      "12\n",
      "48\n",
      "0.0013952801236882806\n",
      "12\n",
      "48\n",
      "0.001373747712932527\n",
      "12\n",
      "48\n",
      "0.0013528075069189072\n",
      "12\n",
      "48\n",
      "0.001332454732619226\n",
      "12\n",
      "48\n",
      "0.0013126643607392907\n",
      "12\n",
      "48\n",
      "0.0012934065889567137\n",
      "12\n",
      "48\n",
      "0.0012746513821184635\n",
      "12\n",
      "48\n",
      "0.00125638407189399\n",
      "12\n",
      "48\n",
      "0.0012385697336867452\n",
      "Epoch: 110, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0012211882276460528\n",
      "12\n",
      "48\n",
      "0.001204199972562492\n",
      "12\n",
      "48\n",
      "0.0011876147473230958\n",
      "12\n",
      "48\n",
      "0.001171422773040831\n",
      "12\n",
      "48\n",
      "0.0011555891251191497\n",
      "12\n",
      "48\n",
      "0.001140148495323956\n",
      "12\n",
      "48\n",
      "0.0011250014649704099\n",
      "12\n",
      "48\n",
      "0.00111020274925977\n",
      "12\n",
      "48\n",
      "0.0010956827318295836\n",
      "12\n",
      "48\n",
      "0.0010815062560141087\n",
      "Epoch: 120, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0010676082456484437\n",
      "12\n",
      "48\n",
      "0.001053983811289072\n",
      "12\n",
      "48\n",
      "0.0010406778892502189\n",
      "12\n",
      "48\n",
      "0.0010276009561493993\n",
      "12\n",
      "48\n",
      "0.0010147577850148082\n",
      "12\n",
      "48\n",
      "0.0010022131027653813\n",
      "12\n",
      "48\n",
      "0.0009898674907162786\n",
      "12\n",
      "48\n",
      "0.000977795571088791\n",
      "12\n",
      "48\n",
      "0.0009659077040851116\n",
      "12\n",
      "48\n",
      "0.0009542735642753541\n",
      "Epoch: 130, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0009428532212041318\n",
      "12\n",
      "48\n",
      "0.0009316318319179118\n",
      "12\n",
      "48\n",
      "0.000920604623388499\n",
      "12\n",
      "48\n",
      "0.0009097714792005718\n",
      "12\n",
      "48\n",
      "0.0008991620852611959\n",
      "12\n",
      "48\n",
      "0.0008887119474820793\n",
      "12\n",
      "48\n",
      "0.0008784506935626268\n",
      "12\n",
      "48\n",
      "0.0008684034110046923\n",
      "12\n",
      "48\n",
      "0.0008584855240769684\n",
      "12\n",
      "48\n",
      "0.0008487566374242306\n",
      "Epoch: 140, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0008392066811211407\n",
      "12\n",
      "48\n",
      "0.0008297812310047448\n",
      "12\n",
      "48\n",
      "0.0008205348276533186\n",
      "12\n",
      "48\n",
      "0.0008114574593491852\n",
      "12\n",
      "48\n",
      "0.0008024995331652462\n",
      "12\n",
      "48\n",
      "0.0007937007467262447\n",
      "12\n",
      "48\n",
      "0.0007850662223063409\n",
      "12\n",
      "48\n",
      "0.0007765358895994723\n",
      "12\n",
      "48\n",
      "0.0007681599818170071\n",
      "12\n",
      "48\n",
      "0.0007599430973641574\n",
      "Epoch: 150, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0007518206839449704\n",
      "12\n",
      "48\n",
      "0.000743827607948333\n",
      "12\n",
      "48\n",
      "0.000735993729904294\n",
      "12\n",
      "48\n",
      "0.000728249317035079\n",
      "12\n",
      "48\n",
      "0.0007206590380519629\n",
      "12\n",
      "48\n",
      "0.0007131583406589925\n",
      "12\n",
      "48\n",
      "0.000705786922480911\n",
      "12\n",
      "48\n",
      "0.000698524818290025\n",
      "12\n",
      "48\n",
      "0.0006913424585945904\n",
      "12\n",
      "48\n",
      "0.0006842942093499005\n",
      "Epoch: 160, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.000677365402225405\n",
      "12\n",
      "48\n",
      "0.0006705360137857497\n",
      "12\n",
      "48\n",
      "0.0006638010963797569\n",
      "12\n",
      "48\n",
      "0.0006571607082150877\n",
      "12\n",
      "48\n",
      "0.0006506545469164848\n",
      "12\n",
      "48\n",
      "0.0006442031008191407\n",
      "12\n",
      "48\n",
      "0.0006378659745678306\n",
      "12\n",
      "48\n",
      "0.0006316035287454724\n",
      "12\n",
      "48\n",
      "0.0006254453910514712\n",
      "12\n",
      "48\n",
      "0.0006193569279275835\n",
      "Epoch: 170, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0006133927381597459\n",
      "12\n",
      "48\n",
      "0.0006074882694520056\n",
      "12\n",
      "48\n",
      "0.0006016632542014122\n",
      "12\n",
      "48\n",
      "0.0005959427799098194\n",
      "12\n",
      "48\n",
      "0.0005902868579141796\n",
      "12\n",
      "48\n",
      "0.0005847204593010247\n",
      "12\n",
      "48\n",
      "0.0005792236770503223\n",
      "12\n",
      "48\n",
      "0.0005738014006055892\n",
      "12\n",
      "48\n",
      "0.0005684488569386303\n",
      "12\n",
      "48\n",
      "0.0005631907260976732\n",
      "Epoch: 180, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.0005579922581091523\n",
      "12\n",
      "48\n",
      "0.0005528832552954555\n",
      "12\n",
      "48\n",
      "0.000547819014173001\n",
      "12\n",
      "48\n",
      "0.0005428193835541606\n",
      "12\n",
      "48\n",
      "0.0005378992646001279\n",
      "12\n",
      "48\n",
      "0.0005330339190550148\n",
      "12\n",
      "48\n",
      "0.0005282629863359034\n",
      "12\n",
      "48\n",
      "0.0005235516582615674\n",
      "12\n",
      "48\n",
      "0.0005188752547837794\n",
      "12\n",
      "48\n",
      "0.0005142733571119606\n",
      "Epoch: 190, Train Acc: 1.0000, Test Acc: 0.5000\n",
      "12\n",
      "48\n",
      "0.000509746081661433\n",
      "12\n",
      "48\n",
      "0.0005052585620433092\n",
      "12\n",
      "48\n",
      "0.0005008355947211385\n",
      "12\n",
      "48\n",
      "0.000496472290251404\n",
      "12\n",
      "48\n",
      "0.0004921636427752674\n",
      "12\n",
      "48\n",
      "0.00048790485016070306\n",
      "12\n",
      "48\n",
      "0.0004837006563320756\n",
      "12\n",
      "48\n",
      "0.00047959087532944977\n",
      "12\n",
      "48\n",
      "0.0004754612746182829\n",
      "12\n",
      "48\n",
      "0.0004714161332231015\n",
      "Epoch: 200, Train Acc: 1.0000, Test Acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    run_fc_train2()\n",
    "    train_acc, trM = run_fc_test2(dataset_fc2, y_fc2)\n",
    "    test_acc, testM = run_fc_test2(dataset_fc, y_fc)\n",
    "#     print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       " tensor([[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       " tensor([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]])]"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakalarka",
   "language": "python",
   "name": "bakalarka"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
